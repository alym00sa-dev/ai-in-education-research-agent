{
  "started_at": "2026-01-08T12:56:44.319883",
  "total_papers": 254,
  "papers": [
    {
      "index": 1,
      "paper_id": "paper_98393",
      "finding_id": "finding_98393",
      "title": "A Review of Virtual Tutoring Systems and Student Performance Analysis Using GPT-3",
      "url": "https://files.eric.ed.gov/fulltext/EJ1465349.pdf",
      "processed_at": "2026-01-08T12:56:44.319899",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined six studies on GPT-3-based virtual tutoring systems and their effectiveness in enhancing student performance and feedback in virtual learning environments. The review synthesized literature from 2017-2024 across multiple databases including IEEE, Science Direct, Springer, and SCOPUS. The studies reviewed encompassed K-12 and higher education contexts, examining AI integration in personalized learning, adaptive tutoring, and automated assessment. The findings underscore GPT-3's potential for personalizing learning experiences and improving student outcomes, though the review notes limitations regarding scalability, accessibility, ethical considerations, and the need for human oversight in AI-driven education.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 2,
      "paper_id": "paper_7204",
      "finding_id": "finding_7204",
      "title": "The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring systems",
      "url": "https://asu.elsevierpure.com/en/publications/the-relative-effectiveness-of-human-tutoring-intelligent-tutoring/",
      "processed_at": "2026-01-08T12:56:57.376367",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis reviewed experiments comparing the effectiveness of human tutoring, intelligent tutoring systems (ITS), and no tutoring conditions across multiple studies. The review categorized computer tutoring systems by their granularity of user interface interaction into answer-based, step-based, and substep-based systems. Contrary to widely held beliefs that human tutoring achieves effect sizes of d = 2.0 and ITS achieves d = 1.0, the review found human tutoring effect size was d = 0.79 and ITS effect size was d = 0.76 compared to no tutoring. The findings demonstrate that intelligent tutoring systems are nearly as effective as human tutoring, challenging previous assumptions about the superiority of human tutors over computer-based instruction.",
        "measure": "Effect size (Cohen's d) comparing tutoring conditions to no tutoring",
        "study_size": "not_reported",
        "effect_size": 0.76,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 3,
      "paper_id": "paper_64071",
      "finding_id": "finding_64071",
      "title": "The Case for Human Tutoring in the Age of AI",
      "url": "https://studyville.com/the-case-for-human-tutoring-in-the-age-of-ai/",
      "processed_at": "2026-01-08T12:57:14.093423",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is an opinion/advocacy piece from a tutoring company blog, not an empirical research study. The article argues for the continued importance of human tutoring over AI-based alternatives, citing concerns about screen fatigue, lack of human connection, and the limitations of AI in providing emotional support and relationship-building. The piece references external research from the Annenberg Institute at Brown University on high-dosage tutoring effectiveness but does not present original empirical findings. No specific intervention was tested, and no measurable outcomes were directly reported in this article.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 4,
      "paper_id": "paper_1967",
      "finding_id": "finding_1967",
      "title": "Examining the Academic Effects of Cross-age Tutoring",
      "url": "https://tipsforteachers.substack.com/p/research-bite-43-examining-the-academic",
      "processed_at": "2026-01-08T12:57:25.025733",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis synthesized 32 studies examining cross-age tutoring, an educational model pairing older tutors (grades 5-12, university students, or community volunteers) with younger tutees (primarily grades 1-3). The combined sample size across all studies was 5,500 participants. The study design was a systematic meta-analysis using Hedges' g as the effect size measure. Results showed a small to moderate positive effect on academic outcomes for both tutees (g=0.33) and tutors (g=0.39), with an overall effect size of 0.34. No significant differences in effectiveness were found based on number of sessions, tutor type, tutee risk status, or subject area.",
        "measure": "Academic outcomes measured through standardized assessments in reading and mathematics",
        "study_size": 5500,
        "effect_size": 0.34,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Tutees primarily grades 1-3; Tutors grades 5-12, university students, or community volunteers",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 5,
      "paper_id": "paper_86458",
      "finding_id": "finding_86458",
      "title": "More than a chatbot: Human-centered AI for student engagement and academic efficiency",
      "url": "https://iacis.org/iis/2025/1_iis_2025_324-337.pdf",
      "processed_at": "2026-01-08T12:57:45.812307",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined peer-reviewed literature from 2015 to 2025 on anthropomorphic AI tutors in higher education settings. The review synthesized findings across multiple studies focusing on student engagement, retention, and faculty workload outcomes. Key findings indicate that AI tutors can improve student retention by up to 21% and reduce faculty grading time by more than 30% through personalized, adaptive feedback mechanisms. However, the review also identified challenges including algorithmic bias, data privacy concerns, and risks of student over-reliance on AI-generated content at the expense of critical thinking. The authors propose the AI-Pedagogy Integration Model (APIM) as a governance framework for ethical AI adoption in educational institutions.",
        "measure": "Retention rates, grading time reduction, student engagement metrics",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "mixed",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 6,
      "paper_id": "paper_16412",
      "finding_id": "finding_16412",
      "title": "Learning Acceleration vs. Remediation: Evidence from Zearn Math Platform",
      "url": "https://tntp.org/wp-content/uploads/2023/02/TNTP_Accelerate_Dont_Remediate_FINAL.pdf",
      "processed_at": "2026-01-08T12:58:06.040156",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study compared learning acceleration versus remediation approaches using Zearn's online math platform with over 2 million elementary students (grades 3-5) across more than 100,000 classrooms during the 2020-21 school year. The study leveraged a natural experiment where some teachers followed revised scope and sequences emphasizing acceleration while others used traditional remediation. Students who experienced learning acceleration completed 27% more grade-level lessons and struggled significantly less on grade-level content compared to remediated students. The benefits were particularly pronounced for students of color and those in high-poverty schools, with accelerated classrooms in majority-minority schools completing 49% more grade-level lessons. The findings demonstrate that acceleration is more effective than remediation for addressing pandemic-related learning loss, especially for historically underserved populations.",
        "measure": "Grade-level lesson completion rates and repeated struggle alerts (automatically generated when students repeatedly answer questions incorrectly)",
        "study_size": 2000000,
        "effect_size": "not_reported",
        "student_racial_makeup": "Includes majority white schools, majority Black schools, majority Latinx schools, and majority American Indian schools; students of color were more likely to experience remediation",
        "student_socioeconomic_makeup": "High poverty schools (75%+ FRL eligible), mid-poverty schools, and low poverty schools (<40% FRL eligible); Title I schools included",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grades K-5, with focused analysis on grades 3-5 (approximately ages 8-11)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "title_i",
        "ses_indicator": "mixed",
        "ses_numeric": "75% FRL threshold for high-poverty classification",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 7,
      "paper_id": "paper_24078",
      "finding_id": "finding_24078",
      "title": "Accelerate, Don't Remediate: New Evidence from Elementary Math Classrooms",
      "url": "https://eric.ed.gov/?id=ED615462",
      "processed_at": "2026-01-08T12:58:39.610727",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study compared learning acceleration versus remediation approaches for elementary math students using the Zearn online math platform, which serves one in four elementary students nationwide. The quasi-experimental design compared students who started at similar levels but received different instructional approaches. Key findings showed that students who experienced learning acceleration struggled less and learned more than students who received remediation. The study also found that students of color and those from low-income backgrounds were disproportionately placed in remediation even when they had demonstrated success on grade-level content. Learning acceleration was particularly effective for students of color and those from low-income families, suggesting this approach could help address longstanding academic inequities.",
        "measure": "Student performance and struggle metrics on Zearn online math platform",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Includes students of color and white students with comparative analysis",
        "student_socioeconomic_makeup": "Includes low-income students and wealthier peers with comparative analysis",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 8,
      "paper_id": "paper_29032",
      "finding_id": "finding_29032",
      "title": "Accelerate, Don't Remediate: Learning Acceleration Research",
      "url": "https://about.zearn.org/insights/publications-learning-acceleration",
      "processed_at": "2026-01-08T12:58:48.653118",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study compared learning acceleration versus remediation approaches across 6,000 elementary classrooms during the 2020-21 school year using the Zearn Math platform. The research employed a quasi-experimental design comparing students who started at similar levels but received different instructional approaches. Students experiencing learning acceleration completed 27% more grade-level math lessons than students who received remediation. The effect was particularly pronounced for students of color and those from low-income families, who completed 49% more grade-level lessons with acceleration compared to remediation. Additionally, the study found that students from high-poverty schools were nearly twice as likely to be placed in remediation even when they had demonstrated success on grade-level content.",
        "measure": "Grade-level math lesson completion",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Includes students of color as a subgroup analysis",
        "student_socioeconomic_makeup": "Includes students from low-income families and high-poverty schools",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 9,
      "paper_id": "paper_45000",
      "finding_id": "finding_45000",
      "title": "Analysis: Acceleration vs. remediation, closing the achievement gap, keeping academic growth going \u2014 insights from math learning in the pandemic",
      "url": "https://www.laschoolreport.com/analysis-acceleration-vs-remediation-closing-the-achievement-gap-keeping-academic-growth-going-insights-from-math-learning-in-the-pandemic/",
      "processed_at": "2026-01-08T12:58:57.338074",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This analysis examined the effectiveness of learning acceleration versus remediation approaches using data from the Zearn math platform during the COVID-19 pandemic. The study analyzed over 6,000 third-, fourth-, and fifth-grade classrooms serving more than 50,000 students who missed critical math content during the 2019-20 school year. Students who experienced acceleration (starting with grade-level content and filling gaps as needed) completed 27 percent more grade-level lessons than those who received traditional remediation. The acceleration strategy was even more effective for students of color (49 percent more grade-level lessons) and students from low-income households (28 percent more grade-level lessons). Additionally, schools with high Zearn usage in Louisiana showed 1.5 to 2.5 times higher growth than non-Zearn schools.",
        "measure": "Grade-level lesson completion rates and student progress measured by lessons completed demonstrating mastery",
        "study_size": 50000,
        "effect_size": "not_reported",
        "student_racial_makeup": "Includes students of color, Black and Latino students mentioned as subgroups with larger gains",
        "student_socioeconomic_makeup": "Includes students from low-income households and schools; comparison between high-income and low-income areas",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "3rd, 4th, and 5th grade students (approximately ages 8-11)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 10,
      "paper_id": "paper_20862",
      "finding_id": "finding_20862",
      "title": "A Systematic Review of Mathematics Interventions for Middle-School Students Experiencing Mathematics Difficulty",
      "url": "https://experts.illinois.edu/en/publications/a-systematic-review-of-mathematics-interventions-for-middle-schoo/",
      "processed_at": "2026-01-08T12:59:13.751684",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined mathematics interventions for middle school students (Grades 6-8) experiencing mathematics difficulty, including those with identified learning disabilities in mathematics. The review included 72 single-subject and group comparison studies that met inclusion criteria. Of these studies, 59 demonstrated positive effects on student-level mathematics outcomes. The majority of interventions focused on foundational, prealgebraic skills such as operations and problem solving related to algebraic reasoning. Six instructional components were identified as effective: explicit instruction, multiple representations, problem-solving instruction, mathematical language, mnemonics, and graphic organizers.",
        "measure": "Student-level mathematics outcomes",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grades 6, 7, and 8",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 11,
      "paper_id": "paper_61851",
      "finding_id": "finding_61851",
      "title": "Study of Strategies to Address Unfinished Learning in Math",
      "url": "https://ies.ed.gov/use-work/evaluations/study-strategies-address-unfinished-learning-math",
      "processed_at": "2026-01-08T12:59:22.287445",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This study was designed as a randomized control trial comparing two catch-up instructional strategies\u2014'just-in-time skill building' and 'broad foundation skill building'\u2014delivered through adaptive math technology products (i-Ready and Freckle) in elementary schools. The study targeted struggling students in approximately 75 elementary schools across 9 districts and 7 states during the 2024-25 school year, with a pilot of 12 schools in 2 districts during 2023-24. Students were randomly assigned to use their district's chosen product in one of the two skill-building modes. However, the contract for this study was canceled in February 2025, and no findings or publications have been released as of the available information.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 12,
      "paper_id": "paper_19250",
      "finding_id": "finding_19250",
      "title": "Acceleration vs. Remediation: What Works for My Students",
      "url": "https://www.esc7.net/apps/news/article/1732904",
      "processed_at": "2026-01-08T12:59:36.189938",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 13,
      "paper_id": "paper_65896",
      "finding_id": "finding_65896",
      "title": "Accelerated Learning vs. Remediation: How School Leaders Can Improve Student Outcomes with Learning Acceleration",
      "url": "https://www.insighteducationgroup.com/blog/accelerated-learning-vs.-remediation",
      "processed_at": "2026-01-08T12:59:48.887658",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This article synthesizes evidence on accelerated learning versus remediation approaches in K-12 education, drawing on data from a Zearn report covering over two million students in more than 100,000 elementary classrooms. The intervention involves accelerated learning strategies that provide students access to grade-level content while addressing learning gaps, rather than delaying new content through remediation. The study population includes elementary students, with particular attention to English language learners and underserved populations. Key findings indicate that students in accelerated learning classrooms complete 27 percent more grade-level assignments than peers without access to the method. The evidence suggests positive outcomes for learning acceleration even among the most disadvantaged student populations.",
        "measure": "Grade-level assignment completion rate",
        "study_size": 2000000,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Includes underserved and disadvantaged student populations",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary school students (kindergarten through 5th grade)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 14,
      "paper_id": "paper_95579",
      "finding_id": "finding_95579",
      "title": "A Comparative Study of Student Achievement in Remedial Math Courses Through Online and Traditional Delivery Modes at Northwest Mississippi Community College",
      "url": "https://arch.astate.edu/cgi/viewcontent.cgi?article=1541&context=all-etd",
      "processed_at": "2026-01-08T12:59:58.254884",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 15,
      "paper_id": "paper_32890",
      "finding_id": "finding_32890",
      "title": "Accelerating Opportunity: The Effects of Instructionally Supported Detracking",
      "url": "https://files.eric.ed.gov/fulltext/ED660950.pdf",
      "processed_at": "2026-01-08T13:00:03.809697",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized control trial examined the Algebra I Initiative, which placed 9th-grade students with prior math scores well below grade level into Algebra I classes with teacher training instead of remedial pre-Algebra courses. The study was conducted in a diverse suburban California school district with 1,039 students across four comprehensive high schools. Using random assignment, the study found that the reform significantly increased grade-11 math achievement with an effect size of 0.19-0.20 standard deviations for below-grade-level students without lowering achievement of classroom peers. The initiative also improved attendance, district retention by 13 percentage points, and overall math credits for the lowest-performing students, demonstrating that higher expectations coupled with aligned teacher supports can realize students' mathematical potential.",
        "measure": "Smarter Balanced Assessment Consortium (SBAC) standardized math test scores in 11th grade",
        "study_size": 1039,
        "effect_size": 0.2,
        "student_racial_makeup": "54% Hispanic, 30% White, 12% Asian or Pacific Islander, 4% Black, 1% Native American or Alaska Native",
        "student_socioeconomic_makeup": "49% eligible for free-or-reduced-price meals (FRPM)",
        "student_gender_makeup": "51% female, 49% male",
        "student_age_distribution": "9th grade entry (approximately ages 14-15)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "49% FRPM, 40% socioeconomically disadvantaged district-wide",
        "special_education_services": "no",
        "urban_type": "suburban",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 16,
      "paper_id": "paper_23910",
      "finding_id": "finding_23910",
      "title": "Educators' Perceptions Of Large Language Models As Tutors: Comparing Human And Ai Tutors In A Blind Text-Only Setting",
      "url": "https://scale.stanford.edu/ai/repository/educators-perceptions-large-language-models-tutors-comparing-human-and-ai-tutors",
      "processed_at": "2026-01-08T13:00:26.355216",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study compared human tutors with LLM tutors in teaching grade-school math word problems through a blind text-only evaluation. Human tutors with teaching experience served as annotators who assessed both tutor types on engagement, empathy, scaffolding, and conciseness. The study found that annotators perceived LLMs as showing higher performance than human tutors across all four metrics. The most substantial advantage was in empathy, where 80% of annotators preferred the LLM tutor more often than human tutors. The findings suggest LLMs can potentially reduce the workload on human teachers in tutoring contexts.",
        "measure": "Annotator ratings on engagement, empathy, scaffolding, and conciseness",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 17,
      "paper_id": "paper_81362",
      "finding_id": "finding_81362",
      "title": "Human vs. AI Tutor: A Comparative Dialogue Analysis in an Educational Setting",
      "url": "https://www.cambridgeassessment.org.uk/Images/742460-human-vs.-ai-tutor-a-comparative-dialogue-analysis-in-an-educational-setting.pdf",
      "processed_at": "2026-01-08T13:00:34.149582",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This small-scale exploratory study compared dialogues between A-level Mathematics students and either a human tutor or an AI tutor (OpenAI's Tutor Me) during probability problem-solving tasks. Eight students from a school in England participated, completing two tasks of intermediate difficulty via Microsoft Teams chat with a human tutor and separately with the AI tutor. The study employed Sociocultural Discourse Analysis to examine thematic, turn-level, and word-level characteristics of dialogue, scaffolding, and feedback effectiveness. As this is a conference abstract, the specific findings and direction of results are not yet reported, with the authors indicating that findings will highlight similarities and differences in interaction dynamics and learning outcomes.",
        "measure": "Sociocultural Discourse Analysis examining dialogue characteristics, scaffolding, and feedback effectiveness",
        "study_size": 8,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "A-level students (approximately ages 16-18)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 18,
      "paper_id": "paper_98799",
      "finding_id": "finding_98799",
      "title": "AI Tutor vs Human Tutor: Which Delivers Better Personalized Learning in 2025?",
      "url": "https://blog.afficienta.com/ai-tutor-vs-human-tutor-which-delivers-better-personalized-learning-in-2025/",
      "processed_at": "2026-01-08T13:00:44.584166",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog article discusses the comparative effectiveness of AI tutoring versus human tutoring for personalized learning. The article references research from 2024 claiming students using advanced AI tutoring systems achieved approximately double the learning gains compared to those in active learning classrooms. Additionally, it cites that students in hybrid programs (combining AI and human tutoring) improved 0.36 grade levels more than those using AI alone. The article is not a primary research study but rather a promotional piece for Afficient Academy that synthesizes claims about AI tutoring effectiveness. The overall finding direction is positive toward hybrid AI-human tutoring approaches.",
        "measure": "Learning gains and grade level improvement",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 19,
      "paper_id": "paper_6844",
      "finding_id": "finding_6844",
      "title": "Technology-enabled social-emotional learning for University educators: a systematic review",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1655634/full",
      "processed_at": "2026-01-08T13:00:55.386911",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review synthesized 22 empirical studies examining technology-enabled social-emotional learning (SEL) interventions for university educators across diverse higher education contexts. The review followed PRISMA guidelines and searched five academic databases, screening 2,296 initial records to identify eligible studies. Thematic analysis revealed three central domains: development of SEL competencies (emotional regulation, self-awareness, responsible decision-making), integration of digital tools (online platforms, virtual simulations, mobile applications), and adaptation to cultural diversity and educator readiness. Findings highlight the potential of technology to foster SEL among university educators while underscoring persistent challenges related to scalability, long-term effectiveness, and cultural responsiveness.",
        "measure": "SEL competency development, teaching practices, educator well-being, inclusive learning environments",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 20,
      "paper_id": "paper_13492",
      "finding_id": "finding_13492",
      "title": "Using Artificial Intelligence to Enhance Social-Emotional Learning in Kindergarten",
      "url": "https://isrgpublishers.com/wp-content/uploads/2025/04/ISRGJAHSS9542025.pdf",
      "processed_at": "2026-01-08T13:01:08.659846",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This qualitative study explored the role of AI in enhancing social-emotional learning (SEL) in Palestinian kindergartens through thematic analysis of existing literature. The study focused on preschool-aged children in Palestinian educational contexts, examining AI-powered tools such as emotion recognition software, virtual assistants, and social robots. The research design involved comprehensive literature review and thematic analysis of peer-reviewed studies on AI applications in early childhood SEL. Key outcomes examined included emotional regulation, empathy development, and social interaction skills. The main finding indicates that AI has significant potential to enhance SEL in Palestinian kindergartens by supporting emotional regulation, empathy, and social interaction, though implementation faces challenges related to infrastructure, teacher training, and cultural adaptation.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "kindergarten-aged children (preschool)",
        "school_type": "K-12",
        "public_private_status": "mixed",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 21,
      "paper_id": "paper_24886",
      "finding_id": "finding_24886",
      "title": "Digital companions in early childhood education: a scoping review on the potential of chatbots for supporting social-emotional learning",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1634668/full",
      "processed_at": "2026-01-08T13:01:32.070257",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This scoping review synthesized 13 peer-reviewed studies examining AI-powered chatbots for supporting social-emotional learning (SEL) in early childhood education (ages 0-8). The review followed PRISMA-ScR guidelines and searched five academic databases for studies published between 2019-2025. Findings indicated that chatbot technologies showed promise for supporting self-awareness and self-management competencies through features like natural language processing, emotion recognition, and adaptive learning, but relationship skills and responsible decision-making were underexplored. The review concluded that while chatbots demonstrate potential for SEL support, significant gaps remain in empirical validation, theoretical grounding, ethical safeguards, and the role of adult mediation in these interventions.",
        "measure": "Thematic synthesis of SEL competencies (self-awareness, self-management, social awareness, relationship skills, responsible decision-making) across included studies",
        "study_size": 13,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 0-8",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 22,
      "paper_id": "paper_35378",
      "finding_id": "finding_35378",
      "title": "From Personalized Learning To Social-Emotional Development: Applications for AI in Education",
      "url": "https://www.jwel.mit.edu/ideas/articles/from-personalized-learning-to-social-emotional-development-applications-for-ai-in-education",
      "processed_at": "2026-01-08T13:01:47.004882",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This article describes four AI-powered educational research projects funded by MIT Jameel World Education Lab grants. The projects include SIDAI (a web-based active learning platform with chatbot teaching assistant), NeuroChat (an adaptive learning platform using brain-sensing biofeedback), a speech-based LLM conversational tutor for vocabulary development in third and fourth graders, and a social robot platform for Arabic-speaking refugee children. Preliminary findings from NeuroChat indicate positive impacts on engagement and learning outcomes. The projects target diverse populations including undergraduate STEM students, young children from various socioeconomic backgrounds, and refugee children, with study designs ranging from pilot studies to planned experimental deployments.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "diverse socioeconomic backgrounds including children from disadvantaged backgrounds and refugee children",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "third and fourth graders for vocabulary project; undergraduate students for SIDAI",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 2,
        "decision_making_complexity": 3,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 23,
      "paper_id": "paper_16434",
      "finding_id": "finding_16434",
      "title": "What the Research Says: Emotions as the Foundation for Self-Directed Learning in an AI-Enhanced World",
      "url": "https://www.educateventures.com/what-the-research-says",
      "processed_at": "2026-01-08T13:02:06.381293",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This synthesis examines the intersection of emotions, self-directed learning (SDL), and AI in education, drawing on meta-analyses and multiple empirical studies. The review covers diverse populations including undergraduate students across multiple countries (Ghana, Korea, and others) and various educational contexts. Using a systematic review methodology, the synthesis integrates findings from RCTs, quasi-experiments, and correlational studies. Key outcomes include academic performance, critical thinking, emotional engagement, and AI dependency measures. The findings are mixed: while AI tools can reduce learning anxiety, provide personalized scaffolding, and enhance creative output, they also risk creating over-reliance, diminishing critical thinking, reducing brain engagement, and weakening metacognitive awareness.",
        "measure": "Academic performance, critical thinking scores, brain engagement (EEG), self-regulation measures, AI dependency scales",
        "study_size": "not_reported",
        "effect_size": 0.24,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 24,
      "paper_id": "paper_47851",
      "finding_id": "finding_47851",
      "title": "Mapping the feedback landscape: a systematic review of research on feedback sources, methods, and technologies in preservice teacher education",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1657737/full",
      "processed_at": "2026-01-08T13:02:22.051897",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic literature review analyzed 45 peer-reviewed empirical studies published between 2014 and early 2025 examining feedback practices for preservice teachers in North American teacher education programs. The review found that instructor-provided feedback was the most commonly studied source (n=25), followed by peer feedback (n=8) and mixed-source feedback (n=8), with technology-only feedback appearing in only 2 studies. Written feedback was the most prevalent delivery method (n=24), followed by oral (n=13) and mixed methods (n=8). Despite the availability of advanced technologies such as video annotations, AI simulations, and real-time coaching tools, over half of the reviewed studies (n=26) did not report using any specific technology to support feedback delivery, suggesting continued research emphasis on traditional feedback methods.",
        "measure": "Categorization and synthesis of feedback sources, methods, and technologies across included studies",
        "study_size": 45,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 25,
      "paper_id": "paper_35213",
      "finding_id": "finding_35213",
      "title": "Delayed Versus Immediate Feedback in an Independent Study High School Setting",
      "url": "https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1335&context=etd",
      "processed_at": "2026-01-08T13:02:48.196047",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 26,
      "paper_id": "paper_60951",
      "finding_id": "finding_60951",
      "title": "Focus on Formative Feedback",
      "url": "https://myweb.fsu.edu/vshute/pdf/shute%202008_b.pdf",
      "processed_at": "2026-01-08T13:02:55.427116",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This comprehensive literature review and meta-analysis examined formative feedback research across multiple decades, synthesizing findings from over 100 studies on feedback types, timing, and learner characteristics. The review found that feedback generally improves learning with effect sizes ranging from 0.40 to 0.80 SD compared to control conditions, but approximately one-third of studies showed negative effects on learning. Key findings indicate that feedback specificity, timing, and learner characteristics interact in complex ways, with immediate feedback benefiting procedural learning and low-achieving students, while delayed feedback may promote transfer. The review concludes that effective formative feedback should be task-focused, specific, and adapted to learner needs, while avoiding normative comparisons and praise that direct attention to self rather than task.",
        "measure": "Learning outcomes, performance, retention, and transfer across various cognitive and procedural tasks",
        "study_size": "not_reported",
        "effect_size": 0.8,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 27,
      "paper_id": "paper_70397",
      "finding_id": "finding_70397",
      "title": "Assistance and Feedback Mechanism in an Intelligent Tutoring System for Teaching Conversion of Natural Language into Logic",
      "url": "https://link.springer.com/article/10.1007/s40593-017-0139-y",
      "processed_at": "2026-01-08T13:03:16.241077",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study evaluated the NLtoFOL intelligent tutoring system designed to teach undergraduate computer science students how to convert natural language sentences into first-order logic formulas. The first experiment (n=226) used a quasi-experimental design comparing students receiving full feedback sequences (flag feedback, error-specific feedback, procedural hints, and bottom-out hints) versus students receiving only flag feedback and bottom-out hints. Results showed that students receiving full feedback achieved significantly higher post-test scores (adjusted mean 7.50 vs 5.72, p<0.001, partial eta squared=0.063) and made fewer errors. A second experiment (n=120) compared system-generated template-based feedback to tutor-authored feedback, finding no significant difference in learning outcomes between groups, suggesting automated feedback was comparable to human-generated feedback.",
        "measure": "Post-test scores on natural language to first-order logic conversion exercises (10 exercises, max score 10 points)",
        "study_size": 346,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "male and female students (specific percentages not reported)",
        "student_age_distribution": "ages 21-23, 4th year undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 28,
      "paper_id": "paper_27693",
      "finding_id": "finding_27693",
      "title": "The Effects of Artificial Intelligence on Student Learning Outcomes in Secondary Mathematics Education",
      "url": "https://scholarworks.uni.edu/cgi/viewcontent.cgi?article=2762&context=grp",
      "processed_at": "2026-01-08T13:03:32.032618",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 29,
      "paper_id": "paper_37691",
      "finding_id": "finding_37691",
      "title": "Comparing the Effects of Choice and Performance Feedback on the Writing Fluency Outcomes of Elementary Students",
      "url": "https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=2425&context=etds",
      "processed_at": "2026-01-08T13:03:37.839256",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 30,
      "paper_id": "paper_69453",
      "finding_id": "finding_69453",
      "title": "An Empirical Study on the Impact of Using an Adaptive E-Learning Environment Based on Learner's Personality and Emotion",
      "url": "https://files.eric.ed.gov/fulltext/ED590286.pdf",
      "processed_at": "2026-01-08T13:03:43.823044",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study compared an adaptive e-learning environment based on learner personality (MBTI) and emotion (OCC model) with a simple e-learning environment among undergraduate computer engineering students at the University of Tehran. The experimental group (n=16 ISTJ students) used the adaptive system while the control group (n=27 with other personality types) used a non-adaptive version. Both groups completed pre- and post-quizzes on 'Pointers and Arrays' content. Results showed the experimental group's quiz score improvement rate was approximately 4.6 times greater than the control group, and students rated the adaptive system higher on measures of interest, personality fit, emotional understanding, appropriate system reactions, and learning rate improvement.",
        "measure": "Quiz scores (pre-quiz and post-quiz) and evaluation questionnaire ratings",
        "study_size": 43,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "first year undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 31,
      "paper_id": "paper_78346",
      "finding_id": "finding_78346",
      "title": "The Effects of the Timing of Feedback on Long-Term Knowledge Retention in PSI Courses",
      "url": "https://files.eric.ed.gov/fulltext/ED230183.pdf",
      "processed_at": "2026-01-08T13:03:59.393101",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This series of three experiments examined the effects of immediate versus delayed feedback on long-term knowledge retention in undergraduate courses taught using the Personalized System of Instruction (PSI). Experiment I used short-answer essay tests in an anthropology course, while Experiments II and III used multiple-choice and fill-in items in psychology research methodology courses. The studies employed randomized controlled designs with students assigned to immediate feedback (within 20 minutes) or delayed feedback (24-48 hours) conditions. Results consistently showed no significant differences in long-term knowledge retention between immediate and delayed feedback groups, regardless of feedback quality or test item type, suggesting that the frequent repeatable-quizzing aspect of PSI may make feedback timing a less potent variable than in conventional instructional settings.",
        "measure": "Performance on review tests and final examinations measuring knowledge retention",
        "study_size": 121,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 32,
      "paper_id": "paper_7942",
      "finding_id": "finding_7942",
      "title": "How Feedback Timing Impacts Skill Learning",
      "url": "https://replayitapp.com/how-feedback-timing-impacts-skill-learning/",
      "processed_at": "2026-01-08T13:04:14.266706",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This article synthesizes research on feedback timing in skill learning, comparing immediate versus delayed feedback approaches. The content draws on neuroscience and motor learning studies to examine how feedback timing affects learners at different skill levels. Key findings indicate that immediate feedback shows a 0.43 effect size on early learning outcomes, while delayed feedback has a 0.39 effect size. In competitive swimming, athletes using delayed feedback protocols improved technique retention by 18% after eight weeks compared to those receiving immediate corrections. The article concludes that beginners benefit most from immediate feedback while advanced learners thrive with delayed feedback for deeper skill refinement.",
        "measure": "Effect size on learning outcomes and technique retention percentage",
        "study_size": "not_reported",
        "effect_size": 0.43,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 33,
      "paper_id": "paper_24373",
      "finding_id": "finding_24373",
      "title": "Learning from Feedback: Spacing and the Delay-Retention Effect",
      "url": "https://www.ou.edu/memorylab/pdfs/SmithKimball_2010_LearningFromFeedback_ms.pdf",
      "processed_at": "2026-01-08T13:04:29.675777",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined the effects of feedback timing on learning trivia facts among undergraduate students using a within-subjects experimental design with cued recall tests. Experiment 1 (N=103) found that delayed feedback led to significantly better retention test performance after a 7-day interval compared to immediate feedback, with the effect primarily driven by increased correct response perseveration rather than error correction. Experiment 2 (N=73) demonstrated a non-monotonic relationship between inter-trial lag and retention, with optimal performance at 1-day lag (approximately 15-20% of retention interval). Results supported the spacing hypothesis, showing that delayed feedback functions as distributed practice that strengthens initially correct responses, rather than the interference perseveration hypothesis which predicted reduced error perseveration with delayed feedback.",
        "measure": "Proportion correct on cued recall retention test after 7-day delay",
        "study_size": 176,
        "effect_size": 0.11,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 34,
      "paper_id": "paper_27510",
      "finding_id": "finding_27510",
      "title": "The current landscape of formative assessment and feedback in graduate studies: a systematic literature review",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1509983/full",
      "processed_at": "2026-01-08T13:04:45.817547",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic literature review analyzed 19 empirical studies from 2014-2024 examining formative assessment and feedback in graduate education. The review synthesized evidence from Scopus and Web of Science databases focusing on graduate student populations across various disciplines. Using PRISMA methodology, the authors examined how formative feedback influences learning and motivation. Key findings indicate that immediate and specific feedback enhances academic performance and promotes self-regulation, technological tools facilitate personalized and accessible feedback, and feedback strategies considering individual differences contribute to greater equity and effectiveness in graduate education.",
        "measure": "Academic performance, self-regulation, motivation, and engagement outcomes synthesized across 19 studies",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 35,
      "paper_id": "paper_44764",
      "finding_id": "finding_44764",
      "title": "Effects of adaptive feedback through a digital tool \u2013 a mixed-methods study on the course of self-regulated learning",
      "url": "https://link.springer.com/article/10.1007/s10639-024-12510-8",
      "processed_at": "2026-01-08T13:05:00.422381",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This mixed-methods study examined the effects of an adaptive learning technology called 'studybuddy' on university students' self-regulated learning (SRL) over a 9-week period. The study involved 33 undergraduate students in a methods course at a Swiss university, using hierarchical linear modeling for quantitative analysis and semi-structured interviews with 6 purposively selected students for qualitative analysis. Quantitative results showed significant increases in subjective competence but significant decreases in personal relevance and organization over time, with no significant effects for other SRL variables. Qualitative findings revealed that students had varying perceptions of the adaptive feedback and integrated it into their learning behaviors based on individual benefits, with interest in suggested strategies decreasing toward semester end. The overall findings were mixed, with some positive effects on self-efficacy but declining task relevance and organization.",
        "measure": "Self-reported measures of metacognitive activity (planning, monitoring, organization), motivation (self-efficacy, task value, goal orientation), and emotional states (enjoyment, anger) using single items from established questionnaires",
        "study_size": 33,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "87.9% female, 12.1% male",
        "student_age_distribution": "mean age 26.3 (SD = 3.89)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 36,
      "paper_id": "paper_27056",
      "finding_id": "finding_27056",
      "title": "Does Immediate Feedback While Doing Homework Improve Learning?",
      "url": "https://eric.ed.gov/?id=ED615325",
      "processed_at": "2026-01-08T13:05:17.738770",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined whether immediate correctness feedback during homework improves learning compared to delayed feedback in a web-based homework system. Using a randomized controlled crossover within-subjects design, 61 seventh grade math students participated in both conditions. In the immediate feedback condition, students received correctness feedback while doing their homework, whereas in the delayed condition, the same feedback was provided the next day in class. The results demonstrated that students learned more when given immediate feedback compared to receiving the same feedback delayed. This finding supports the hypothesis that immediate feedback leads to better learning outcomes in the context of web-based homework systems that provide only correctness feedback.",
        "measure": "Learning outcomes (comparison of performance between immediate and delayed feedback conditions)",
        "study_size": 61,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "7th grade (approximately ages 12-13)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 37,
      "paper_id": "paper_99014",
      "finding_id": "finding_99014",
      "title": "The Influence of Feedback Content and Feedback Time on Multimedia Learning Achievement of College Students and Its Mechanism",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.706821/full",
      "processed_at": "2026-01-08T13:05:26.634777",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial investigated the effects of feedback content (adaptive, elaborated, and knowledge of correct response) and feedback timing (immediate vs. delayed) on multimedia learning among 157 undergraduate and graduate students at Northeast Normal University in China. Using a 2x3 between-subjects design, participants completed graphic reasoning tasks with different feedback conditions while eye movements were tracked. Results showed that immediate feedback significantly improved post-test scores compared to delayed feedback, and adaptive feedback (providing KCR for correct answers and elaborated feedback for incorrect answers) led to significantly higher scores than both elaborated feedback and knowledge of correct response feedback alone. The germane cognitive load was found to partially mediate the relationship between adaptive feedback and improved learning outcomes.",
        "measure": "Post-test scores on graphic reasoning questions, cognitive load scale, situational learning motivation scale, eye movement indices (fixation time, fixation count, regression count, pupil size)",
        "study_size": 157,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "38 men and 119 women (approximately 24% male, 76% female)",
        "student_age_distribution": "ages 17-26",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "East Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 38,
      "paper_id": "paper_34167",
      "finding_id": "finding_34167",
      "title": "Delayed versus immediate feedback in children's and adults' vocabulary learning",
      "url": "https://web.williams.edu/Psychology/Faculty/Kornell/Publications/Metcalfe.Kornell.Finn.2009.pdf",
      "processed_at": "2026-01-08T13:05:42.314041",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study investigated the effects of delayed versus immediate feedback on vocabulary learning using a computer-based program called Dragon Master. In Experiment 1, 27 Grade 6 students learned school-relevant vocabulary over four sessions in a classroom setting, with 18 participants included in final analyses. The quasi-experimental design compared delayed feedback, immediate feedback, and no feedback conditions while controlling for lag to test. Results showed that delayed feedback produced significantly better final test performance than immediate feedback, which in turn was better than no feedback, even when lag to test was controlled. In Experiment 2 with 20 college students learning GRE-level vocabulary, delayed feedback was superior only when lag to test was uncontrolled, with no difference between conditions when controlled.",
        "measure": "Proportion correct on final vocabulary test (word recall from definitions)",
        "study_size": 47,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "mixed (about half children of university faculty/staff, half from local neighborhoods of Morningside Heights and Harlem)",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grade 6 (approximately ages 11-12) for Experiment 1; college students for Experiment 2",
        "school_type": "K-12",
        "public_private_status": "private",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "independent",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 39,
      "paper_id": "paper_43480",
      "finding_id": "finding_43480",
      "title": "Effectiveness of Intelligent Tutoring Systems: A Meta-Analytic Review",
      "url": "https://www.ida.org/research-and-publications/publications/all/e/ef/effectiveness-of-intelligent-tutoring-systems-a-meta-analytic-review",
      "processed_at": "2026-01-08T13:05:58.376526",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 50 controlled evaluations of intelligent computer tutoring systems across various educational contexts. The study employed a meta-analytic design to synthesize findings from multiple controlled evaluations comparing intelligent tutoring systems to conventional instruction. The primary outcome measure was test score improvement, with results showing a median effect size of 0.66 standard deviations, raising performance from the 50th to the 75th percentile. The findings indicate that intelligent tutoring systems produce substantial positive effects on student learning, though the magnitude of effects varied significantly based on whether locally developed or standardized tests were used. Additional analyses of studies with nonconventional control groups or flawed implementations showed smaller effects, highlighting the importance of proper implementation and appropriate comparison conditions.",
        "measure": "Test scores (locally developed and standardized tests)",
        "study_size": "not_reported",
        "effect_size": 0.66,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 40,
      "paper_id": "paper_49654",
      "finding_id": "finding_49654",
      "title": "An Investigation of Differences in Student Success and Persistence Rates by Course Modality",
      "url": "https://www.scimath.net/article/an-investigation-of-differences-in-student-success-and-persistence-rates-by-course-modality-10976",
      "processed_at": "2026-01-08T13:06:07.749069",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study investigated differences in achievement and persistence in developmental mathematics by course modality (emporium, face-to-face, and online) at a suburban community college in the Northeast United States from fall 2015 through spring 2019. The study employed a quasi-experimental design comparing student outcomes across three developmental mathematics course levels. For upper two developmental mathematics courses, achievement measures in emporium courses were comparable to face-to-face courses, suggesting the emporium model with semi-structured schedules, prompt feedback, and frequent interactions is viable. However, the emporium modality did not benefit students in the lowest level course (pre-algebra), where grades and persistence rates were lower compared to face-to-face courses. Online course modality was not the best option across all course levels, indicating that course modality effectiveness varies by student placement level.",
        "measure": "Final exam scores, course grades, and persistence rates",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "suburban",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "community_college",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 41,
      "paper_id": "paper_36774",
      "finding_id": "finding_36774",
      "title": "Differences in students' mathematics knowledge in homogeneous and heterogeneous groups",
      "url": "https://files.eric.ed.gov/fulltext/EJ1376840.pdf",
      "processed_at": "2026-01-08T13:06:19.652790",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the effects of heterogeneous versus homogeneous ability grouping on mathematics achievement among 126 eighth-grade students (ages 13-14) in two Slovenian elementary schools over one academic year. Students in the experimental group worked in heterogeneous groups while the control group worked in homogeneous ability-based groups. Results from the post-test showed that students in heterogeneous groups had significantly better achievements in procedural knowledge and problem-solving compared to students in homogeneous groups, with effect sizes of r=.48 and r=.34 respectively. Qualitative observations revealed that teachers in homogeneous groups tended to assign lower taxonomic level tasks to lower-ability students and favored higher-ability groups, while such differential treatment was not observed in heterogeneous classrooms.",
        "measure": "21-item mathematics knowledge test assessing conceptual knowledge, procedural knowledge, and problem-solving based on Gagne's taxonomic levels",
        "study_size": 126,
        "effect_size": 0.48,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Controlled for SES using parents' education, computer access, dictionary access, number of books at home, and presence of study desk; no significant differences between groups",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "13-14 years old (8th grade)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "suburban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 42,
      "paper_id": "paper_62122",
      "finding_id": "finding_62122",
      "title": "Study on the quality of mathematics education in primary schools in Sindh province, Pakistan",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1526845/pdf",
      "processed_at": "2026-01-08T13:06:37.570149",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined factors influencing mathematics achievement among primary school students in Sindh province, Pakistan, using achievement tests and surveys of students, teachers, and headmasters/headmistresses. The study employed a mixed-methods design combining quantitative achievement testing with qualitative survey data from multiple stakeholders. Key outcomes measured included mathematics test scores across different grade levels and school contexts. Results showed significant gender gaps favoring boys, with urban schools outperforming rural schools, while teacher qualifications and school resources were identified as important factors affecting student performance.",
        "measure": "Mathematics achievement test scores",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "primary school students (grades 3-5)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "South Asia",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 43,
      "paper_id": "paper_51395",
      "finding_id": "finding_51395",
      "title": "Teachers' Conceptions of Mathematics and Intelligent Tutoring System Use",
      "url": "https://digitalcommons.usu.edu/cgi/viewcontent.cgi?params=/context/etd/article/8670/&path_info=2019_Glaze_Andrew.pdf",
      "processed_at": "2026-01-08T13:06:57.051385",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This mixed-methods study investigated the relationship between junior high school mathematics teachers' conceptions of mathematics and their use of intelligent tutoring systems (ITSs) for instruction. The participants were 93 junior high school mathematics teachers from three school districts in the Midwest. Data were collected using a two-part online survey containing questions about ITS use and the Conceptions of Mathematics Inventory. Quantitative analysis using 2x5 mixed ANOVAs revealed no statistically significant interactions between teachers' conception scores and ITS use or how ITSs were used. However, significant interactions were found between teachers' conceptions and their use of graphing calculators, Desmos, and dynamic geometry software. Qualitative analysis revealed that teachers primarily used ITSs for differentiation, procedural practice, and filling gaps in student knowledge.",
        "measure": "Conceptions of Mathematics Inventory (CMI) scores and self-reported technology use",
        "study_size": 93,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Urban district: 22% free/reduced lunch; Metropolitan district: 79% free/reduced lunch; Rural district: 20% free/reduced lunch",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "22% to 79% free/reduced lunch across districts",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 44,
      "paper_id": "paper_38090",
      "finding_id": "finding_38090",
      "title": "The Influence of Affective Feedback Adaptive Learning System on Learning Engagement and Self-Directed Learning",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.858411/full",
      "processed_at": "2026-01-08T13:07:17.608238",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study investigated the effects of an adaptive learning system with affective feedback mechanisms on university students' learning outcomes in a Technology and Art online course. A total of 70 undergraduate students from southern Taiwan were divided into experimental (n=35) and control (n=35) groups over a 6-week distance learning period. The experimental group used a system that detected facial and semantic emotions and provided adaptive feedback when negative emotions were detected. Results showed that students in the experimental group had significantly better learning achievement (M=83.28 vs M=73.14), lower learning anxiety, higher learning engagement, better learning attitudes, and improved self-directed learning compared to the control group, demonstrating positive effects of the affective feedback adaptive learning system.",
        "measure": "Learning achievement test scores, Achievement Emotions Questionnaire (AEQ), learning anxiety scale, learning engagement scale, learning attitude scale, and self-directed learning scale",
        "study_size": 70,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "university students",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "East Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 45,
      "paper_id": "paper_98700",
      "finding_id": "finding_98700",
      "title": "Taking adaptive learning in educational settings to the next level: leveraging natural language processing for improved personalization",
      "url": "https://link.springer.com/article/10.1007/s11423-024-10345-1",
      "processed_at": "2026-01-08T13:07:32.252800",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study explored the integration of Natural Language Processing (NLP) into an Adaptive Learning Technology (ALT) called 'studybuddy' to support self-regulated learning (SRL) among high school students. The research employed a one-year co-design process with a Swiss high school involving 69 students across three classes, with 6 students participating in individual interviews. Using a qualitative study design with opinion mining, part-of-speech tagging, and sentiment analysis, the researchers analyzed interview data to assess how NLP could enhance personalized adaptive support. The findings indicated that the digital tool was well-received and successfully implemented in practice, with NLP demonstrating substantial promise for capturing relevant learner information and providing more nuanced, context-aware feedback to support students' self-regulated learning strategies.",
        "measure": "Qualitative analysis of interview transcripts using NLP techniques including opinion mining, part-of-speech tagging, and sentiment analysis to assess SRL-related terminology and emotional disposition",
        "study_size": 69,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "2 female, 3 male, 1 without gender (for interview participants)",
        "student_age_distribution": "ages 16-17",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 46,
      "paper_id": "paper_82720",
      "finding_id": "finding_82720",
      "title": "Analyzing the Impact of Feedback on Student Development",
      "url": "https://www.ijset.in/wp-content/uploads/IJSET_V12_issue6_822.pdf",
      "processed_at": "2026-01-08T13:07:49.359397",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined the impact of feedback on student development through a survey-based qualitative approach across various educational levels including high school, undergraduate, and graduate students. The research investigated how feedback frequency, clarity, personalization, and detail affect students' understanding, academic performance, learning strategies, and confidence. Results indicated that most students reported feedback helped clarify complex issues, identify areas for improvement, and validate correct knowledge, with the majority stating feedback improved their assignment performance and confidence. However, some students reported minimal impact or decreased confidence when feedback was too vague, general, or overly critical, highlighting the importance of constructive, timely, and personalized feedback for optimal student development.",
        "measure": "Survey responses on feedback impact on understanding, performance, learning strategies, and confidence",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "high school, undergraduate, graduate students",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_reported",
        "region": "South Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 47,
      "paper_id": "paper_29991",
      "finding_id": "finding_29991",
      "title": "The Impact of Interaction between Timing of Feedback Provision in Distance E-Learning and Learning Styles on achieving Learning Outcomes among Arab Open University Students",
      "url": "https://www.ejmste.com/article/the-impact-of-interaction-between-timing-of-feedback-provision-in-distance-e-learning-and-learning-5491",
      "processed_at": "2026-01-08T13:08:07.504980",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the interaction between feedback timing (immediate vs. delayed) and learning styles (active vs. reflective) on developing e-blogging design and production skills among 67 Arab Open University students in Saudi Arabia. Participants were divided into four experimental groups using a 2x2 factorial design. The study measured practical skills performance and satisfaction with the e-learning environment using observation cards and satisfaction scales. Results showed statistically significant differences favoring immediate feedback for both skill acquisition and e-learning satisfaction. Additionally, students with active learning styles demonstrated superior performance on practical skills and higher satisfaction compared to reflective learners.",
        "measure": "Observation card for practical skills performance and satisfaction scale with e-learning environment",
        "study_size": 67,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 48,
      "paper_id": "paper_48465",
      "finding_id": "finding_48465",
      "title": "The Impact of Enhancing Students' Social and Emotional Learning: A Meta-Analysis of School-Based Universal Interventions",
      "url": "https://casel.s3.us-east-2.amazonaws.com/impact-enhancing-students-social-emotional-learning-meta-analysis-school-based-universal-interventions.pdf",
      "processed_at": "2026-01-08T13:08:19.984586",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 213 school-based universal social and emotional learning (SEL) programs involving 270,034 kindergarten through high school students. The intervention focused on developing social-emotional competencies through classroom curricula and multicomponent approaches. Using a meta-analytic design with both randomized and quasi-experimental studies, the review assessed outcomes across six categories: SEL skills, attitudes, positive social behavior, conduct problems, emotional distress, and academic performance. Compared to controls, SEL participants demonstrated significantly improved outcomes across all categories, with an 11-percentile-point gain in academic achievement. Programs conducted by classroom teachers were effective, and those following SAFE practices (Sequenced, Active, Focused, Explicit) showed stronger effects.",
        "measure": "Standardized achievement test scores, school grades, social-emotional skill assessments, behavioral ratings, and measures of emotional distress",
        "study_size": 270034,
        "effect_size": 0.27,
        "student_racial_makeup": "35% mixed ethnicity, 31% not reported, with some studies involving Caucasian, African American, and other ethnic groups",
        "student_socioeconomic_makeup": "25% mixed SES, 32% not reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "56% elementary (K-5), 31% middle school (6-8), 13% high school (9-12)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 49,
      "paper_id": "paper_83033",
      "finding_id": "finding_83033",
      "title": "Evidence for Social and Emotional Learning in Schools",
      "url": "https://learningpolicyinstitute.org/product/evidence-social-emotional-learning-schools-brief",
      "processed_at": "2026-01-08T13:08:39.115588",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This brief synthesizes findings from 12 independent meta-analyses examining school-based social and emotional learning (SEL) programs across PreK-12th grade students worldwide. The meta-analyses included hundreds of studies, most using randomized controlled trials and controlled comparison group designs meeting ESSA Tier 1 and 2 evidence criteria. Results consistently demonstrated medium to large effect sizes on students' social-emotional competencies, prosocial behaviors, academic engagement and performance, while reducing disruptive behavior problems and emotional distress. These positive effects were found across all grade levels and demographic variables including gender, ethnicity, race, and income, with two meta-analyses showing sustained long-term positive impacts.",
        "measure": "Social and emotional competencies, prosocial behaviors, academic performance, behavior problems, emotional distress",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "PreK-12th grade",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 50,
      "paper_id": "paper_23597",
      "finding_id": "finding_23597",
      "title": "What Does the Research Say?",
      "url": "https://casel.org/fundamentals-of-sel/what-does-the-research-say/",
      "processed_at": "2026-01-08T13:08:51.600343",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This CASEL summary synthesizes hundreds of independent studies involving more than 1 million students worldwide across PreK-12 examining social and emotional learning (SEL) interventions. The meta-analytic findings demonstrate that SEL programs addressing five core competencies increased students' academic performance by 11 percentile points compared to non-participants, with long-term effects showing 13 percentile points higher academic performance years later. The research spans diverse demographic groups, socioeconomic backgrounds, and urban, suburban, and rural communities both inside and outside the United States. Additional outcomes include decreased emotional distress, reduced bullying and aggression, improved school climate, and positive lifetime outcomes including higher rates of high school graduation, postsecondary enrollment, and stable employment up to 18 years later.",
        "measure": "Academic performance (grades, test scores, attendance, homework completion), social and emotional skills, emotional distress, school climate indicators",
        "study_size": 1000000,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "diverse socioeconomic backgrounds",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "PreK-12",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 51,
      "paper_id": "paper_60452",
      "finding_id": "finding_60452",
      "title": "Impact of Social-Emotional Learning (SEL) Programmes on Emotional Intelligence and Academic Achievements of Students",
      "url": "https://rsisinternational.org/journals/ijriss/articles/impact-of-social-emotional-learning-sel-programmes-on-emotional-intelligence-and-academic-achievements-of-students/",
      "processed_at": "2026-01-08T13:09:03.430498",
      "status": "skipped",
      "extracted_fields": {},
      "error": "insufficient content"
    },
    {
      "index": 52,
      "paper_id": "paper_82178",
      "finding_id": "finding_82178",
      "title": "Social and Emotional Learning (SEL) Systematic Review",
      "url": "https://dexisonline.com/wp-content/uploads/2023/05/Attachment-1-Systematic-Review-Report.pdf",
      "processed_at": "2026-01-08T13:09:05.031196",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic review examined 136 studies of 110 unique SEL interventions targeting primary school-age children and youth in development and humanitarian contexts globally. The review found that targeted, explicit SEL instruction is associated with positive effects on social, emotional, and other outcomes, reinforcing evidence from the Global North. However, effects varied significantly by context, population, and implementation factors. Studies that integrated SEL often saw positive effects on academic, workforce, and health outcomes even when SEL outcomes showed no improvement. Mental health interventions did not necessarily build SEL skills, and SEL programs did not consistently improve mental health outcomes. The review identified critical gaps in research on teacher outcomes, implementation fidelity, and long-term effects.",
        "measure": "Multiple measures including Strengths and Difficulties Questionnaire (SDQ), Developmental Assets Profile (DAP), Rosenberg Self-Esteem Scale, Children's Hope Scale, GRIT Scale, and over 100 other context-specific measures",
        "study_size": 136,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Primarily low-income populations in development and humanitarian contexts; some studies targeted orphans and vulnerable children, refugees, and internally displaced populations",
        "student_gender_makeup": "Studies included both male and female participants; 27 studies involved gender-responsive or gender-targeted programming with 14 targeting females only",
        "student_age_distribution": "Primary school-age children (ages 6-14) and youth (ages 15-29); 79 interventions targeted primary school-age, 69 targeted youth",
        "school_type": "K-12",
        "public_private_status": "mixed",
        "title_i_status": "not_applicable",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 4
      },
      "error": null
    },
    {
      "index": 53,
      "paper_id": "paper_91481",
      "finding_id": "finding_91481",
      "title": "Program support matters: A systematic review on teacher- and school related contextual factors facilitating the implementation of social-emotional learning programs",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2022.965538/full",
      "processed_at": "2026-01-08T13:09:25.813212",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined 20 articles investigating the relationship between contextual factors and SEL program implementation quality in K-12 schools. The review identified four categories of contextual factors: program support, school, teacher, and student factors. Program support factors, particularly coaching activities like modeling program activities (80% significant relationships) and teacher-coach working relationships (60% significant relationships), demonstrated the highest frequency of statistically significant relationships with implementation quality indicators. Teacher burnout was consistently negatively related to program dosage across multiple studies, and student baseline self-regulation emerged as a potentially important contextual factor influencing implementation quality.",
        "measure": "Implementation quality indicators (adherence, dosage, quality of delivery, participant responsiveness)",
        "study_size": 20,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "grades 1-12",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 54,
      "paper_id": "paper_67257",
      "finding_id": "finding_67257",
      "title": "Pilot evaluation of a socio-emotional learning program on executive functions in elementary school students: a cluster-randomized controlled trial",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1554001/full",
      "processed_at": "2026-01-08T13:09:40.473646",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This cluster-randomized controlled trial evaluated 'The Intergalactic World' social-emotional learning (SEL) program's effects on executive functions in 96 Portuguese elementary students (1st-4th grade). The intervention group (n=60) received eight weekly 60-minute sessions incorporating breathing exercises, relaxation techniques, guided imagery, and cognitive-behavioral strategies, while the control group (n=36) was placed on a waiting list. Executive functions were assessed using the BRIEF questionnaire completed by teachers and caregivers at pre- and post-intervention. Results showed a significant time \u00d7 group interaction for caregiver ratings (\u03b7\u00b2\u209a = 0.108, p = 0.001), with the intervention group demonstrating improved executive functioning compared to controls, but teacher ratings showed no significant differences between groups.",
        "measure": "Behavior Rating Inventory of Executive Function (BRIEF) Global Executive Composite scores",
        "study_size": 96,
        "effect_size": 0.108,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "45 girls, 51 boys (47% female, 53% male)",
        "student_age_distribution": "Mean age 101.20 months (SD=15.26), 1st-4th grade, ages approximately 6-10 years",
        "school_type": "K-12",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 55,
      "paper_id": "paper_86627",
      "finding_id": "finding_86627",
      "title": "Examining the effectiveness of Second Step Early Learning versus free play on socio-emotional learning in kindergarten: a cluster randomized controlled trial protocol",
      "url": "https://link.springer.com/article/10.1186/s13063-025-09047-7",
      "processed_at": "2026-01-08T13:09:56.159827",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is a study protocol for a cluster randomized controlled trial comparing the Norwegian version of Second Step Early Learning (Nor-SSEL) to free play in kindergartens. The study will allocate 990 children aged 4-5 years across 66 kindergartens in Norway, with the intervention lasting 28 weeks. The primary outcome is child psychosocial adjustment measured using the Strengths and Difficulties Questionnaire (SDQ), with secondary outcomes including empathy measured via the Empathy Questionnaire for Children (EmQue). As this is a protocol paper, no empirical results have been reported yet; the study is registered but not yet recruiting participants.",
        "measure": "Strengths and Difficulties Questionnaire (SDQ), Empathy Questionnaire for Children (EmQue)",
        "study_size": 990,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 4-5",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 56,
      "paper_id": "paper_11858",
      "finding_id": "finding_11858",
      "title": "AI+Human Tutors Match Quality Of Human-Only Tutors",
      "url": "https://www.forbes.com/sites/dereknewton/2025/11/11/research-aihuman-tutors-match-quality-of-human-only-tutors/",
      "processed_at": "2026-01-08T13:10:09.491165",
      "status": "skipped",
      "extracted_fields": {},
      "error": "insufficient content"
    },
    {
      "index": 57,
      "paper_id": "paper_47977",
      "finding_id": "finding_47977",
      "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
      "url": "https://danmeyer.substack.com/p/research-review-aihuman-tutors-match",
      "processed_at": "2026-01-08T13:10:09.831269",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial compared three types of tutoring support embedded in the Eedi math platform: static pre-written hints, human tutors via chat, and AI (LearnLM) tutors with human supervision via chat. The study was conducted in UK classrooms over seven weeks (one hour per week) with students working on math problems. Both dynamic tutoring conditions (human and human+AI) significantly outperformed static hints on mistake remediation and misconception resolution. The key finding was that the human+AI condition showed a 5.5% improvement in knowledge transfer compared to human tutors alone, with 93.6% probability that this effect was genuine, though the confidence interval included zero.",
        "measure": "Knowledge transfer (performance on questions in different units the following week), mistake remediation, misconception resolution",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 58,
      "paper_id": "paper_47977",
      "finding_id": "finding_70503",
      "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
      "url": "https://danmeyer.substack.com/p/research-review-aihuman-tutors-match",
      "processed_at": "2026-01-08T13:10:20.160832",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial compared three types of tutoring support embedded in the Eedi math platform: static pre-written hints, human tutors via chat, and AI (LearnLM) tutors with human supervision via chat. The study was conducted in UK classrooms over seven weeks (one hour per week) with students working on math problems. Both dynamic tutoring conditions (human and human+AI) significantly outperformed static hints on mistake remediation and misconception resolution. The key finding was that the human+AI condition showed a 5.5% improvement in knowledge transfer compared to human tutors alone, with 93.6% probability that this effect was genuine, though the confidence interval included zero.",
        "measure": "Knowledge transfer (performance on questions in different units the following week), mistake remediation, misconception resolution",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 59,
      "paper_id": "paper_580",
      "finding_id": "finding_580",
      "title": "AI Tutors, With a Little Human Help, Offer 'Reliable' Instruction, Study Finds",
      "url": "https://www.the74million.org/article/ai-tutors-with-a-little-human-help-offer-reliable-instruction-study-finds/",
      "processed_at": "2026-01-08T13:10:29.901948",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial examined the effectiveness of AI-powered math tutoring supervised by human tutors compared to human-only tutoring among 165 British secondary school students ages 13-15. The intervention used Google's LearnLM large language model integrated with Eedi's platform, where AI drafted responses that human tutors could revise before sending to students. Students using the supervised AI tutor successfully solved new problems on subsequent topics 66.2% of the time compared to 60.7% for human-only tutoring. The AI demonstrated high reliability with only 0.1% hallucination rate (5 errors in 3,617 messages) and no safety concerns, while students corrected misconceptions over 90% of the time with the AI/human combination versus 65% with static pre-written responses.",
        "measure": "Problem-solving success rate on subsequent math topics and misconception correction rate",
        "study_size": 165,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 13-15",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 60,
      "paper_id": "paper_49808",
      "finding_id": "finding_49808",
      "title": "Educators' Perceptions of Large Language Models as Tutors: Comparing Human and AI Tutors in a Blind Text-only Setting",
      "url": "https://aclanthology.org/2025.bea-1.28.pdf",
      "processed_at": "2026-01-08T13:10:44.909385",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study compared human tutors with LLM-based tutors (MWPTutor using GPT-4) on grade-school math word problems through blind pairwise preference selection by 35 educators with teaching experience recruited via Prolific. The study used a mixed-methods design analyzing 210 annotated dialog pairs across four metrics: engagement, empathy, scaffolding, and conciseness. Results showed that annotators perceived LLM tutors as significantly outperforming human tutors on empathy (80% preference), scaffolding, and conciseness, with engagement showing a positive but non-significant trend. The findings suggest LLMs can effectively perform certain tutoring roles in text-only settings, potentially reducing teacher workload.",
        "measure": "Pairwise preference selection scores on engagement, empathy, scaffolding, and conciseness metrics",
        "study_size": 35,
        "effect_size": "not_reported",
        "student_racial_makeup": "Black (20 annotators), White (11 annotators), other ethnicities",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "14 male, 21 female",
        "student_age_distribution": "ages 20-74, median age 34",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 61,
      "paper_id": "paper_64111",
      "finding_id": "finding_64111",
      "title": "AI Tutors: Bridging the Gap Between Students and Academic Success",
      "url": "https://www.quadc.io/blog/bridging-the-gap-between-students-and-academic-success",
      "processed_at": "2026-01-08T13:11:03.293348",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is a promotional blog post from QuadC describing their AI Tutor product rather than an empirical research study. The post discusses theoretical benefits of AI tutors including 24/7 availability, adaptable learning experiences, judgment-free support, and enhanced engagement. No specific intervention was tested, no study design was employed, and no measurable outcomes were reported. The article makes general claims about improved engagement and success rates but provides no empirical data or research methodology.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 62,
      "paper_id": "paper_96251",
      "finding_id": "finding_96251",
      "title": "An Experimental Study of the Effect of AI Course Assistants on Student Grade Outcomes",
      "url": "https://openpraxis.org/articles/10.55982/openpraxis.17.2.772",
      "processed_at": "2026-01-08T13:11:14.719374",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the impact of Spark, an AI course assistant using Socratic methods, on student GPA outcomes at Los Angeles Pacific University, a fully online asynchronous institution. The study analyzed 2,090 student-course combinations from 1,338 unique undergraduate and graduate students across 99 courses. Using propensity score matching to control for age, gender, and ethnicity, along with Mann-Whitney U-tests and Wilcoxon signed-rank tests, researchers found that students who engaged with Spark three or more times achieved significantly higher GPAs (mean 3.28) compared to non-users (mean 3.05). The effect size ranged from moderate-to-strong (0.553 before PSM) to small-to-moderate (0.262 after PSM), with a mean GPA difference of 0.377 points after matching, demonstrating a positive relationship between AI course assistant utilization and improved academic performance.",
        "measure": "Grade Point Average (GPA)",
        "study_size": 1338,
        "effect_size": 0.262,
        "student_racial_makeup": "46% Hispanic of any race, 20% White, 17% Black or African American, 7% Asian, 5% two or more races, 2% race and ethnicity unknown, 1% Native Hawaiian or Other Pacific Islander, <1% American Indian or Alaska Native",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "81% female, 17.4% male, 1.5% chose not to state",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "independent",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 63,
      "paper_id": "paper_17171",
      "finding_id": "finding_17171",
      "title": "Intelligent Tutoring Systems, Generative Artificial Intelligence (AI), and Healthcare Agents: A Proof of Concept and Dual-Layer Approach",
      "url": "https://www.cureus.com/articles/297820-intelligent-tutoring-systems-generative-artificial-intelligence-ai-and-healthcare-agents-a-proof-of-concept-and-dual-layer-approach",
      "processed_at": "2026-01-08T13:11:30.210904",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This paper appears to be a proof of concept study examining the integration of intelligent tutoring systems with generative AI and healthcare agents using a dual-layer approach. The full content of the paper was not provided, only the journal webpage metadata and navigation elements. Without access to the actual paper content, specific details about the intervention, population, study design, outcomes, and findings cannot be determined. The study appears to focus on healthcare education applications based on the title and journal context.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_reported",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 64,
      "paper_id": "paper_40958",
      "finding_id": "finding_40958",
      "title": "Self-Regulated Learning and Academic Achievement in Higher Education: A Decade Systematic Review",
      "url": "https://rsisinternational.org/journals/ijriss/articles/self-regulated-learning-and-academic-achievement-in-higher-education-a-decade-systematic-review/",
      "processed_at": "2026-01-08T13:11:38.756069",
      "status": "skipped",
      "extracted_fields": {},
      "error": "insufficient content"
    },
    {
      "index": 65,
      "paper_id": "paper_62899",
      "finding_id": "finding_62899",
      "title": "A strategic mindset predicts and promotes effective learning and academic performance",
      "url": "https://www.nature.com/articles/s41539-025-00367-6",
      "processed_at": "2026-01-08T13:11:42.788994",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This research examined the role of a strategic mindset\u2014an orientation toward asking oneself strategy-eliciting questions during difficulty\u2014on learning outcomes across four studies with 7,475 adolescent and adult students in Singapore. The studies included correlational surveys and randomized controlled experiments spanning primary through university levels. Students with higher strategic mindset scores reported greater use of effective learning strategies, which mediated improved exam performance including high-stakes national examinations. In the field experiment with 1,070 secondary students, the strategic mindset intervention increased effective learning strategy use and exam performance among more academically prepared students and in conducive peer environments.",
        "measure": "Final exam performance scores, national examination scores (PSLE, GCE O-Levels/N-Levels), semester GPA, self-reported use of effective learning strategies (LASSI Skill subscale)",
        "study_size": 7475,
        "effect_size": 0.37,
        "student_racial_makeup": "Predominantly Chinese (164 Chinese, 11 Indian, 4 Malay, 4 other in Experiment 3)",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "54.1% female in Experiment 4; 59.4% female in Study 2",
        "student_age_distribution": "ages 11-16 in Study 1; mean age 23.9 years in Study 2; ages 13-17 in Experiment 4",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Southeast Asia",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 66,
      "paper_id": "paper_18378",
      "finding_id": "finding_18378",
      "title": "Do self-created metacognitive prompts promote short- and long-term effects in computer-based learning environments?",
      "url": "https://link.springer.com/article/10.1186/s41039-021-00148-w",
      "processed_at": "2026-01-08T13:12:02.592017",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This randomized controlled trial examined whether self-created metacognitive prompts could improve learning processes and outcomes in a hypermedia learning environment among 57 German undergraduate students. Participants in the experimental condition (n=28) created their own metacognitive prompts before a 40-minute learning session on operant conditioning, while control participants (n=29) learned without prompts. Results showed a significant overall effect on navigation behavior in the first learning session (partial \u03b7\u00b2=.27), specifically for time spent on relevant webpages, and a significant overall effect on learning performance (partial \u03b7\u00b2=.18), though individual comparisons for recall, comprehension, and transfer were not significant. Effects did not persist in a second unsupported learning session three weeks later, except that students who used prompts as reflection tools showed significantly better long-term transfer performance (partial \u03b7\u00b2=.50).",
        "measure": "Navigation behavior (relative frequency of relevant page visits, relative time on relevant pages, linearity of navigation) and learning performance (recall, comprehension, transfer tests)",
        "study_size": 57,
        "effect_size": 0.27,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "72% female",
        "student_age_distribution": "mean age 19.9 years, SD 1.58",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 67,
      "paper_id": "paper_85001",
      "finding_id": "finding_85001",
      "title": "Reflect on your teaching experience: systematic reflection of teaching behaviour and changes in student teachers' self-efficacy for reflection",
      "url": "https://link.springer.com/article/10.1007/s11618-023-01190-8",
      "processed_at": "2026-01-08T13:12:19.621953",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This longitudinal intervention study examined how self-efficacy for reflection changed among N=600 student teachers at a German university over one semester. The intervention group (n=248) participated in micro-teaching experiences where they taught lessons in schools and systematically reflected on their teaching using videos or protocols, while the control group (n=352) did not teach or systematically reflect. Using latent change models, results showed that self-efficacy for reflection increased significantly in the intervention group (M\u2206=0.23, p<0.001) but not in the control group (M\u2206=0.04, p=0.305). The increase in self-efficacy for reflection in the intervention group was positively moderated by prior pedagogical teaching experiences (\u03b2=0.74, p<0.001), while pedagogical knowledge showed no significant association with changes in self-efficacy.",
        "measure": "Self-efficacy for reflection scale (6-point Likert scale)",
        "study_size": 600,
        "effect_size": "not_reported",
        "student_racial_makeup": "91% born in Germany",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "52.7% female",
        "student_age_distribution": "mean age 24.24 years (SD=4.78), fifth bachelor semester on average",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 68,
      "paper_id": "paper_86844",
      "finding_id": "finding_86844",
      "title": "Interactive tutorials in undergraduate mathematics: investigating the impacts on performance and self-efficacy",
      "url": "https://link.springer.com/article/10.1007/s13394-025-00538-z",
      "processed_at": "2026-01-08T13:12:36.607134",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This quasi-experimental study examined the effects of in-person versus asynchronous online tutorial participation on academic performance and self-efficacy among 129 undergraduate students in a second-year mathematics course at the University of Auckland. Students who completed tutorials online achieved significantly higher final exam scores (M=73.8 vs M=61.3, d=0.77) and overall course grades (M=78.2 vs M=70.8, d=0.61) compared to in-person attendees. However, students attending in-person tutorials showed significantly greater improvements in the Emotional Regulation component of tutorial self-efficacy (p=.031), with positive median changes across all self-efficacy measures compared to negative changes for online students. These findings suggest that while online tutorial completion may be associated with higher academic performance, in-person tutorials uniquely support students' affective development and emotional regulation in mathematics learning.",
        "measure": "Final exam scores, overall course grades, and Measure of Assessment Self-Efficacy (MASE) for tutorial and exam self-efficacy",
        "study_size": 129,
        "effect_size": 0.77,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "second-year undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Oceania",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 69,
      "paper_id": "paper_51422",
      "finding_id": "finding_51422",
      "title": "Updated (2025) Supporting Students' Metacognition Skills",
      "url": "https://jennyponzuric.com/updated-2025-supporting-students-metacognition-skills/",
      "processed_at": "2026-01-08T13:12:53.137240",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This blog post provides practical guidance for educators on supporting students' metacognition skills in classroom settings. The content describes metacognition as 'thinking about thinking' and offers strategies such as self-reflection, rubrics, think-alouds, strategic questioning, and peer discussion. The post outlines a five-step explicit teaching process for metacognition but does not report any empirical study, intervention trial, or measured outcomes. No research design, participant data, or effect sizes are presented as this is a practitioner-oriented resource rather than an empirical study.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 70,
      "paper_id": "paper_26329",
      "finding_id": "finding_26329",
      "title": "Exploring Metacognitive Strategies to Support Young Learners in Developing Their Learner Autonomy",
      "url": "https://files.eric.ed.gov/fulltext/EJ1479000.pdf",
      "processed_at": "2026-01-08T13:13:06.513728",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This participatory action research study investigated the implementation of metacognitive strategy instruction using the 'Plan Do Review' reflective framework with 18 fourth-grade EFL students (ages 10-11) in an Indonesian primary school over seven weeks spanning 18 classroom sessions. The qualitative study employed classroom observations, field notes, and video recordings to examine how explicit instruction incorporating goal-setting, multimodal scaffolding, and structured reflection enhanced learners' metacognitive awareness. Findings indicated that the systematic, scaffolded approach enabled students to develop metacognitive skills gradually while receiving ongoing support and feedback, promoting greater learner autonomy. The intervention demonstrated positive outcomes in students' ability to engage in self-monitoring, self-correction, and self-assessment activities, though initial challenges were noted as learners were unfamiliar with reflection-based activities.",
        "measure": "Classroom observations of metacognitive awareness and learner autonomy behaviors",
        "study_size": 18,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 10-11, fourth-grade students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Southeast Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 71,
      "paper_id": "paper_6333",
      "finding_id": "finding_6333",
      "title": "Metacognitive strategies improve self-regulation skills in expert sports coaches",
      "url": "https://www.nature.com/articles/s41598-025-86606-7",
      "processed_at": "2026-01-08T13:13:22.549822",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This mixed-methods study evaluated the impact of a 12-week metacognitive strategy-based facilitation program on self-regulation skills among nine expert sports coaches in Lithuania. The intervention used metacognitive questioning based on Theory U principles to help coaches restructure their training practices. Quantitative results showed significant improvement in overall self-regulation scores (from 234.0 to 248.8 points, p<0.05), with large effect sizes particularly for 'Searching for options' (d=1.35). Qualitative thematic analysis revealed transformative experiences characterized by increased curiosity, openness to innovation, recognition of otherness, expanded horizons, and deeper understanding of complexity in coaching practices.",
        "measure": "Self-Regulation Questionnaire (SRQ) - 63-item scale measuring seven self-regulation processes",
        "study_size": 9,
        "effect_size": 0.8,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "5 males, 4 females",
        "student_age_distribution": "not_reported",
        "school_type": "vocational",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 72,
      "paper_id": "paper_16268",
      "finding_id": "finding_16268",
      "title": "Evaluating metacognitive strategies and self-regulated learning to predict primary school students' self-efficacy and problem-solving skills in science learning",
      "url": "https://files.eric.ed.gov/fulltext/EJ1441218.pdf",
      "processed_at": "2026-01-08T13:13:37.699272",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined the effects of metacognitive strategies and self-regulated learning on problem-solving skills and self-efficacy among 100 fifth-grade primary school students in Indonesia using a 2x2 factorial experimental design. Students were assigned to experimental (metacognitive strategy) and control (non-metacognitive) conditions across four classes. Results showed that metacognitive strategies significantly improved self-efficacy compared to non-metacognitive approaches, and high self-regulated learners demonstrated better self-efficacy than low self-regulated learners. However, contrary to expectations, students using non-metacognitive strategies performed better on problem-solving tasks, and no significant interaction effects were found between metacognitive strategies and self-regulation for either outcome variable.",
        "measure": "Self-efficacy questionnaire, self-regulation questionnaire, and problem-solving test with assessment rubric",
        "study_size": 100,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "5th grade elementary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Southeast Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 73,
      "paper_id": "paper_47876",
      "finding_id": "finding_47876",
      "title": "Enhancing Students' Learning Outcomes in Mathematics through Intelligent Tutoring Systems Based on Real-Time Feedback",
      "url": "https://files.eric.ed.gov/fulltext/EJ1487439.pdf",
      "processed_at": "2026-01-08T13:13:51.974997",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial examined the effectiveness of an intelligent tutoring system (ITS) with real-time automated feedback on mathematical learning outcomes among 78 Grade 7 gifted students at Khon Kaen University Demonstration School in Thailand. Students were randomly assigned to experimental (ITS with feedback) and control (ITS without feedback) groups, both using adaptive diagnostic assessments in Measurement and Geometry. The experimental group showed significantly greater improvement in Structured Learning Outcomes (SLO), with mean scores increasing from 1.90 to 3.54 compared to 1.90 to 2.85 in the control group. Statistical analyses including repeated measures ANOVA revealed a significant Time \u00d7 Treatment interaction (p < .001), with the experimental group achieving Advanced proficiency level (84.83%) compared to Medium level (61.54%) in the control group, yielding an effect size of 0.73.",
        "measure": "Structured Observed Learning Outcomes (SLO) conceptual structure ability score based on open-ended diagnostic test",
        "study_size": 78,
        "effect_size": 0.73,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grade 7 students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Southeast Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 74,
      "paper_id": "paper_24995",
      "finding_id": "finding_24995",
      "title": "Routine and Adaptive Experts: Individual Characteristics and Their Impact on Multidigit Arithmetic Strategy Flexibility and Mathematics Achievement",
      "url": "https://files.eric.ed.gov/fulltext/EJ1459947.pdf",
      "processed_at": "2026-01-08T13:14:06.715138",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined 2,216 Danish students in Grades 3, 6, and 8 to investigate the relationship between adaptive expertise in multidigit arithmetic and mathematics achievement. Using a Tri-phase Flexibility Assessment (TriFA) to categorize students as routine experts (never using shortcut strategies) or adaptive experts (regularly using shortcut strategies), the researchers employed multilevel logistic regression analyses. Results showed that experts scored 0.86 SD-units higher than non-experts on national mathematics tests, and within experts, adaptive experts scored 0.49 SD-units higher than routine experts. The findings indicate a strong positive relationship between adaptive expertise, strategy flexibility, and mathematics achievement, with boys being significantly more likely to be adaptive experts than girls.",
        "measure": "Danish National Tests for mathematics and reading achievement, Tri-phase Flexibility Assessment (TriFA) for strategy flexibility and adaptivity",
        "study_size": 2216,
        "effect_size": 0.86,
        "student_racial_makeup": "86-91% Western background, 9-14% non-Western background",
        "student_socioeconomic_makeup": "53-68% had at least one parent with university-level qualification (used as SES proxy)",
        "student_gender_makeup": "approximately 50% girls across all grades (49% Grade 3, 52% Grade 6, 48% Grade 8)",
        "student_age_distribution": "Grade 3 median age 9, Grade 6 median age 12, Grade 8 median age 14",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "53-68% with parent having higher education",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 75,
      "paper_id": "paper_87599",
      "finding_id": "finding_87599",
      "title": "'Sharp, Steep Declines': U.S. Students Are Falling Behind in Math and Science",
      "url": "https://www.edweek.org/leadership/sharp-steep-declines-u-s-students-are-falling-behind-in-math-and-science/2024/12",
      "processed_at": "2026-01-08T13:14:23.690540",
      "status": "success",
      "extracted_fields": {
        "direction": "Negative",
        "results_summary": "The 2023 Trends in International Mathematics and Science Study (TIMSS) assessed 4th and 8th graders across 63 and 45 education systems respectively in math and science. American 4th graders' math scores fell 18 points and 8th graders' scores fell 27 points since 2019, representing the largest decline since U.S. participation began in 1995. The study revealed widening achievement gaps between highest- and lowest-performing students, with low-performing 4th graders experiencing a 37-point drop in math. While U.S. students still score above the international average, countries like Poland, Sweden, and Australia have now surpassed the United States in some subjects and grade levels.",
        "measure": "TIMSS scale scores (0-1000 points) measuring math and science achievement",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "8th grade boys scored 14 points higher in math than girls and 11 points higher in science",
        "student_age_distribution": "4th and 8th graders",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 2,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 76,
      "paper_id": "paper_34157",
      "finding_id": "finding_34157",
      "title": "U.S. Math Performance in Global Perspective: How well does each state do at producing high-achieving students?",
      "url": "https://hanushek.stanford.edu/sites/default/files/publications/Hanushek%2BPeterson%2BWoessmann%202010%20PEPG%20report.pdf",
      "processed_at": "2026-01-08T13:14:35.733253",
      "status": "success",
      "extracted_fields": {
        "direction": "Negative",
        "results_summary": "This study compared the percentage of U.S. students performing at an advanced level in mathematics to students in 56 other countries using NAEP 2005 and PISA 2006 data. The study population included the U.S. high school graduating Class of 2009, examined when they were in 8th and 9th grade. The study design was a comparative analysis linking national and international assessment data. Key outcomes measured were the percentage of students scoring at the advanced level in math. The main finding was that the U.S. significantly underperforms compared to most industrialized nations, with only 6% of U.S. students reaching the advanced level compared to 28% in Taiwan, and 30 countries outperforming the U.S. overall.",
        "measure": "Percentage of students scoring at the advanced level on NAEP 2005 math test, linked to equivalent performance on PISA 2006",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Analysis included breakdowns for white students (8% advanced) and overall student population",
        "student_socioeconomic_makeup": "Analysis included students with at least one college-educated parent (10.3% advanced)",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "8th grade (NAEP 2005) and 15-year-olds (PISA 2006), Class of 2009",
        "school_type": "K-12",
        "public_private_status": "mixed",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "mixed",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 77,
      "paper_id": "paper_19192",
      "finding_id": "finding_19192",
      "title": "Positive Conditions for Mathematics Learning: An Overview of the Research",
      "url": "https://learningpolicyinstitute.org/product/positive-conditions-math-learning-brief",
      "processed_at": "2026-01-08T13:14:55.003336",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This research synthesis examines classroom conditions that support K-12 mathematics learning, drawing from mathematics education, educational psychology, and learning sciences literature. The review focuses on K-12 students, with particular attention to middle school populations and historically marginalized groups including students of color and those from low-income backgrounds. Using a systematic literature synthesis methodology, the authors identify four key conditions associated with improved math outcomes: positive teacher-student relationships, sense of belonging in mathematics, growth mindset, and high-quality instruction with high expectations. The findings indicate that these positive classroom conditions are associated with increased math achievement, self-efficacy, engagement, and enrollment in advanced courses, with effect sizes for growth mindset interventions estimated at 23-31 additional days of learning equivalent.",
        "measure": "Math achievement on standardized tests, math grades, self-efficacy, engagement, enrollment in advanced math courses",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Studies included focus on African American, Hispanic, Indigenous, Asian, and White students with findings noting disparities in belonging for Black, Hispanic, and Indigenous students",
        "student_socioeconomic_makeup": "Studies included students from low-income families and economically disadvantaged backgrounds, with findings noting stronger effects for lower-income students",
        "student_gender_makeup": "Studies included both male and female students with specific findings noting stronger effects for female students on some interventions",
        "student_age_distribution": "K-12 students, with specific studies focusing on 4th-7th grade and middle school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 78,
      "paper_id": "paper_19192",
      "finding_id": "finding_63405",
      "title": "Positive Conditions for Mathematics Learning: An Overview of the Research",
      "url": "https://learningpolicyinstitute.org/product/positive-conditions-math-learning-brief",
      "processed_at": "2026-01-08T13:15:12.166781",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This brief synthesizes research from mathematics teaching and learning, educational psychology, and learning sciences to identify classroom conditions that support K-12 math learning. The synthesis examines multiple studies across elementary through high school populations, focusing on correlational and quasi-experimental designs. Key findings indicate that positive teacher-student relationships, sense of belonging, growth mindset, and high-quality instruction are associated with improved math achievement. The effects are particularly pronounced for historically marginalized students including female students, students of color, and students from low-income backgrounds. One cited study estimated that a strong growth mindset is equivalent to 23-31 additional days of learning in mathematics.",
        "measure": "Math achievement scores, standardized test performance, math grades, algebra learning assessments",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Studies included Black, Hispanic, Indigenous, Asian, and White students with findings noting lower belonging among Black, Hispanic, and Indigenous students",
        "student_socioeconomic_makeup": "Studies included students from low-income families and socioeconomically disadvantaged populations",
        "student_gender_makeup": "Studies included both male and female students with specific findings for female students",
        "student_age_distribution": "4th through 7th grades, middle school students, K-12 range",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 79,
      "paper_id": "paper_35944",
      "finding_id": "finding_35944",
      "title": "My simple strategy for long-term math retention",
      "url": "https://getmoremath.com/2022/06/22/my-simple-strategy-for-long-term-math-retention/",
      "processed_at": "2026-01-08T13:15:27.386864",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "A high school algebra teacher describes implementing cumulative math practice using Get More Math software over multiple years at Lampeter-Strasburg School District in Pennsylvania. The intervention involved splitting class time between new lessons and mixed review of previously learned concepts, with all assessments being cumulative. The teacher reports observing improved long-term math retention and increased student confidence, with students finding final exams no more challenging than regular tests due to continuous exposure to material throughout the year. This is a practitioner testimonial rather than a controlled study, providing anecdotal evidence of positive outcomes from the cumulative practice approach.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "high school students, approximately ages 14-18",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 80,
      "paper_id": "paper_78908",
      "finding_id": "finding_78908",
      "title": "How Can We Increase Math Retention for Students?",
      "url": "https://blog.definedlearning.com/how-can-we-increase-math-retention-for-students",
      "processed_at": "2026-01-08T13:15:36.661020",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This article discusses the decline in U.S. students' math performance as revealed by the Nation's Report Card, with fourth-grade scores dropping by five points and eighth-grade scores by eight points. The author, a former math teacher, advocates for systemic changes in math instruction emphasizing conceptual understanding, discovery-based learning, and project-based learning (PBL). The piece references NAEP data showing scores returning to 2003 levels and stagnant performance between 2017-2019. No original empirical study was conducted; rather, the article synthesizes existing data and proposes instructional strategies to improve math retention and application in real-world contexts.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 81,
      "paper_id": "paper_93896",
      "finding_id": "finding_93896",
      "title": "Rethinking How We Teach Math: Three Tips for Better Long-term Retention",
      "url": "https://thejournal.com/articles/2023/02/01/rethinking-how-we-teach-math-three-tips-for-better-retention.aspx",
      "processed_at": "2026-01-08T13:15:45.532048",
      "status": "success",
      "extracted_fields": {
        "direction": "Negative",
        "results_summary": "This article discusses the decline in U.S. students' math scores as reported in the Nation's Report Card, with fourth graders' scores dropping an average of five points and eighth graders' scores dropping eight points. The author, a former math teacher, argues that the pandemic accelerated an already existing downward trend in math achievement, noting that scores were flat or declining even before remote learning. The article references NAEP data showing that between 2017 and 2019, 40 states had no significant change in math scores while four saw declines. The piece advocates for systemic changes in math instruction, emphasizing deeper conceptual understanding, more time for learning, and focus on long-term retention rather than rushed coverage of standards.",
        "measure": "NAEP math scores",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "4th and 8th grade students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 2,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 82,
      "paper_id": "paper_72920",
      "finding_id": "finding_72920",
      "title": "Concept-based instruction: Improving learner performance in mathematics through conceptual understanding",
      "url": "https://files.eric.ed.gov/fulltext/EJ1469567.pdf",
      "processed_at": "2026-01-08T13:15:54.296591",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This mixed-methods study examined the impact of concept-based instruction (CBI) on Grade 11 learners' understanding of mathematical functions in a South African township school. Using a one-group pre-test-post-test design with 35 participants, the intervention involved three weeks of CBI focusing on parabolas, hyperbolas, and exponential functions. The study employed tests, questionnaires, and semi-structured interviews to assess changes in conceptual understanding and attitudes. Results showed dramatic improvement in test scores, with the mean increasing from 20.26% to 75.23%, and a dependent t-test confirmed statistical significance (t=33.16, p=0.0001). Qualitative findings indicated positive gains in deep understanding, critical thinking, long-term retention, and student engagement with mathematics.",
        "measure": "Pre-test and post-test scores on functions topic (13 questions testing knowledge, comprehension, application, synthesis, and evaluation)",
        "study_size": 35,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Township school students (implied low-income based on township context)",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grade 11 students (approximately ages 16-17)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 83,
      "paper_id": "paper_72920",
      "finding_id": "finding_95200",
      "title": "Concept-based instruction: Improving learner performance in mathematics through conceptual understanding",
      "url": "https://files.eric.ed.gov/fulltext/EJ1469567.pdf",
      "processed_at": "2026-01-08T13:16:11.693221",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined the impact of concept-based instruction (CBI) on Grade 11 learners' understanding of mathematical functions in a South African township school. Using a one-group pre-test-post-test design with 35 participants, the intervention involved three weeks of CBI focusing on parabolas, hyperbolas, and exponential functions. The pre-test mean score was 20.26% compared to a post-test mean of 75.23%, with a dependent t-test yielding t=33.16 (p=0.0001), indicating statistically significant improvement. Qualitative data from questionnaires and interviews confirmed that learners developed deeper conceptual understanding, critical thinking skills, and improved engagement with mathematics.",
        "measure": "Pre-test and post-test scores on functions assessment (13 questions testing knowledge, comprehension, application, synthesis, and evaluation)",
        "study_size": 35,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "township school students",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grade 11 students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 84,
      "paper_id": "paper_51216",
      "finding_id": "finding_51216",
      "title": "Effectiveness of the Cognitive Tutor on Mathematics Achievement of High School Students",
      "url": "https://www.bakeru.edu/images/pdf/SOE/EdD_Theses/Basadre_Theresa.pdf",
      "processed_at": "2026-01-08T13:16:27.602297",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This quasi-experimental study investigated the impact of the Cognitive Tutor (CT) curriculum on tenth-grade students' mathematics achievement in a large urban Kansas school district, comparing KAP test scores before (2016-2017) and after (2017-2018) CT implementation. The study included over 3,000 students in each group and examined subgroups including students with disabilities, English language learners, and free/reduced lunch students. Results indicated no significant difference in mathematics KAP scores for all tenth-grade students, ELL students, or free/reduced lunch students between traditional and CT instruction groups. However, students with disabilities who received traditional instruction scored significantly higher than those who received CT instruction, with a small effect size (d = 0.15).",
        "measure": "Kansas Assessment Program (KAP) Mathematics Performance Level Scores",
        "study_size": 6101,
        "effect_size": 0.15,
        "student_racial_makeup": "Hispanic 36.1%, Caucasian 30.8%, African-American 20%, Multi-racial 7.6%, Asian 4.5%, Native American 0.8%, Pacific Islander 0.2%",
        "student_socioeconomic_makeup": "76.5% economically disadvantaged",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "10th grade students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "low",
        "ses_numeric": "76.5% economically disadvantaged",
        "special_education_services": "yes",
        "urban_type": "urban",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 85,
      "paper_id": "paper_20162",
      "finding_id": "finding_20162",
      "title": "AI-Assisted Tutoring Boosts Students' Math Skills",
      "url": "https://nssa.stanford.edu/news/study-ai-assisted-tutoring-boosts-students-math-skills",
      "processed_at": "2026-01-08T13:16:44.815296",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "Stanford University researchers developed an AI-powered digital tutoring assistant called Tutor CoPilot to support human tutors in math instruction. The study employed a randomized controlled trial design with approximately 1,000 students receiving help from about 900 tutors. Students who worked with AI-assisted tutors were four percentage points more likely to master the math topic after a given session compared to the control group whose tutors did not use AI assistance. Notably, the tool was particularly effective for lower-performing tutors, bringing their effectiveness nearly to the level of their higher-rated peers. This represents the first RCT to examine a human-AI tutoring system in live tutoring sessions.",
        "measure": "Topic mastery after tutoring session",
        "study_size": 1000,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 86,
      "paper_id": "paper_46611",
      "finding_id": "finding_46611",
      "title": "Impacts of Blended Learning Tutoring Models on Math Achievement After COVID-19: Results from Saga Education",
      "url": "https://www.mathematica.org/publications/impacts-of-blended-learning-tutoring-models-on-math-achievement-after-covid-19",
      "processed_at": "2026-01-08T13:16:52.747058",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study evaluated Saga Education's high-dosage blended tutoring models (online, in-person, and hybrid) across three U.S. school districts during the 2021-2022 school year using a matched comparison design. The intervention targeted high school students in algebra and geometry courses, comparing Saga participants with similar non-participating students within the same districts. Results showed large positive impacts on algebra standardized test scores in one district and geometry scores in another, but no effects on two other standardized tests. Saga also improved student math grades across all districts and models, with larger impacts observed for students with lower prior math achievement, Black students, and those in smaller tutoring groups of two or fewer. However, the program had a small negative impact on school attendance, and some staff reported challenges with student engagement.",
        "measure": "End-of-course standardized test scores (algebra and geometry) and student math grades",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Larger impacts observed for Black students; full racial composition not reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "High school students (algebra and geometry courses)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 87,
      "paper_id": "paper_44881",
      "finding_id": "finding_44881",
      "title": "Effects of Self-Explaining on Learning and Transfer of Critical Thinking Skills",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2018.00100/full",
      "processed_at": "2026-01-08T13:17:07.199817",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This randomized controlled trial examined whether self-explanation prompts during practice with heuristics and biases tasks would enhance learning and transfer of unbiased reasoning skills among 79 first-year undergraduate students at a Dutch University of Applied Sciences. Students received explicit critical thinking instruction and practiced with or without self-explanation prompts, with performance measured on pretest, immediate posttest, and delayed posttest (2 weeks later). Both conditions showed significant improvement from pretest to immediate posttest on practiced tasks, with gains maintained at delayed posttest, but self-explanation prompts did not enhance learning or transfer performance compared to the control condition. Surprisingly, self-explanation prompts had a negative effect on posttest performance for one task version (Wason and conjunction tasks), suggesting that the benefits of explicit instruction and practice on unbiased reasoning cannot be enhanced by increasing difficulty through self-explaining.",
        "measure": "Multiple-choice test scores and MC-plus-motivation scores on heuristics and biases tasks (syllogistic reasoning, Wason selection, base-rate, and conjunction tasks)",
        "study_size": 79,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "44 males out of 79 participants (approximately 56% male, 44% female)",
        "student_age_distribution": "mean age 19.16 years (SD = 1.61)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 88,
      "paper_id": "paper_44881",
      "finding_id": "finding_21204",
      "title": "Effects of Self-Explaining on Learning and Transfer of Critical Thinking Skills",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2018.00100/full",
      "processed_at": "2026-01-08T13:17:24.996069",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This randomized controlled trial examined whether self-explanation prompts during practice with heuristics and biases tasks would enhance learning and transfer of critical thinking skills among 79 first-year undergraduate students at a Dutch University of Applied Sciences. Participants received explicit instruction on two categories of reasoning tasks and then practiced either with or without self-explanation prompts. Performance was measured on pretest, immediate posttest, and delayed posttest (2 weeks later) using multiple-choice questions plus motivation explanations. Results showed that explicit instruction combined with practice improved performance on practiced tasks from pretest to posttest in both conditions equally, with gains maintained at delayed posttest. Surprisingly, self-explanation prompts had no positive effect on learning or transfer, and even showed a negative effect on practiced Wason and conjunction tasks.",
        "measure": "Multiple-choice test scores and MC-plus-motivation scores on heuristics and biases reasoning tasks",
        "study_size": 79,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "44 males out of 79 participants (approximately 56% male, 44% female)",
        "student_age_distribution": "mean age 19.16 years (SD = 1.61)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 89,
      "paper_id": "paper_50531",
      "finding_id": "finding_50531",
      "title": "The Double-Edged Interactions of Prompts and Self-efficacy",
      "url": "https://link.springer.com/article/10.1007/s11409-020-09227-7",
      "processed_at": "2026-01-08T13:17:42.053143",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study investigated the effects of cognitive and metacognitive prompts on strategy use, learning outcomes, and self-efficacy among 70 undergraduate psychology students learning with a hypermedia environment on empirical research methods. Using a between-subjects design, students either received prompts or learned without prompts while self-efficacy was measured before, during, and after learning. Prompting had no significant effect on self-reported cognitive and metacognitive online strategy use, the quality of learning strategies in notes, or learning outcomes. However, prompts increased learners' self-efficacy within the experimental group over time, though no between-group differences emerged. Critically, moderation analyses revealed that learners' perceived self-efficacy during learning moderated the effect of prompts on learning outcomes, indicating an aptitude-treatment interaction.",
        "measure": "Learning outcomes test (recall, comprehension, transfer), self-reported online learning strategies questionnaire, quality ratings of cognitive and metacognitive strategies in notes, self-efficacy scale (MSLQ)",
        "study_size": 70,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "90% female",
        "student_age_distribution": "mean age 19.40 years (SD = 1.60)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 90,
      "paper_id": "paper_27509",
      "finding_id": "finding_27509",
      "title": "Eliciting Self-Explanations Improves Understanding",
      "url": "https://andymatuschak.org/files/papers/Chi%20et%20al%20-%201994%20-%20Eliciting%20self-explanations%20improves%20understanding.pdf",
      "processed_at": "2026-01-08T13:17:58.170896",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined whether prompting eighth-grade students to self-explain while reading an expository text on the human circulatory system would improve their understanding compared to students who read the text twice without prompting. Fourteen students in the prompted group were asked to explain each sentence after reading it, while ten control students read the passage twice. Results showed that the prompted group had significantly greater pre- to posttest gains (32% vs. 22%), with the difference being more pronounced for complex knowledge inference and health questions (22.6% vs. 12.5% improvement). Within the prompted group, high explainers who generated more self-explanations achieved deeper understanding, answered more complex questions correctly, and all attained the correct double-loop mental model of the circulatory system, whereas low explainers and unprompted students often did not.",
        "measure": "Pre- and posttest question scores across four categories (verbatim, comprehension inference, knowledge inference, and health questions), function induction accuracy, and mental model classification",
        "study_size": 24,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "inner city school",
        "student_gender_makeup": "7 boys and 7 girls in prompted group, 5 boys and 5 girls in unprompted group",
        "student_age_distribution": "8th grade",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 91,
      "paper_id": "paper_51083",
      "finding_id": "finding_51083",
      "title": "The Impact of Web-Based Worked Examples and Self-Explanation on Performance, Problem Solving, and Self-Efficacy",
      "url": "https://eric.ed.gov/?id=EJ765099",
      "processed_at": "2026-01-08T13:18:28.443199",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This quasi-experimental study examined the impact of a web-based learning tool featuring worked examples and self-explanation prompts on student performance, problem-solving skills, and self-efficacy. The intervention used weekly quizzes to engage students in an environment designed to develop self-regulated learning strategies. Results were inconclusive regarding the impact of worked examples alone on student outcomes. However, the combination of worked examples with self-explanation prompts produced significant improvements in performance, problem-solving skill, and self-efficacy, demonstrating the value of integrating both strategies in web-based instruction.",
        "measure": "Performance, problem solving skill, and self-efficacy",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 92,
      "paper_id": "paper_78389",
      "finding_id": "finding_78389",
      "title": "Inducing Self-Explanation: a Meta-Analysis",
      "url": "https://gwern.net/doc/psychology/spaced-repetition/2018-bisra.pdf",
      "processed_at": "2026-01-08T13:18:37.746599",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 69 effect sizes from 64 studies (N=5917) investigating the impact of self-explanation prompts on learning outcomes across various educational contexts. Using a random effects model, the researchers found an overall weighted mean effect size of g = .55, indicating a moderate positive effect of self-explanation inducement on learning. The analysis included studies spanning elementary through professional education levels, covering subjects such as science, mathematics, and social sciences. Self-explanation prompts were found to be more effective than instructional explanations (g = .35 advantage), and prompts eliciting conceptual self-explanations showed particularly strong effects. The findings demonstrate that self-explanation is a robust instructional intervention across diverse learning tasks, knowledge types, and educational settings.",
        "measure": "Learning outcomes including comprehension, recall, transfer, problem solving, and inference measures",
        "study_size": 5917,
        "effect_size": 0.55,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary through professional program students",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 93,
      "paper_id": "paper_18936",
      "finding_id": "finding_18936",
      "title": "Can Virtual Tutoring Address Pandemic Learning Loss in a Cost-Effective Way?",
      "url": "https://www.alicoalition.org/blog/can-virtual-tutoring-address-pandemic-learning-loss-in-a-cost-effective-way/",
      "processed_at": "2026-01-08T13:18:53.959559",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog post discusses research on high-dosage virtual tutoring interventions to address pandemic-related learning loss. The primary study referenced is a randomized controlled trial conducted in a Texas district examining virtual tutoring for elementary students. Students who received 40 or more tutoring sessions over 12 weeks gained the equivalent of more than 2 additional months of learning in literacy. The intervention involved trained human tutors delivering structured literacy curriculum in one-on-one or small group sessions two to three times per week via virtual platforms. The findings support virtual tutoring as a cost-effective and scalable solution for improving student achievement, particularly in reading.",
        "measure": "Learning gains measured in months of additional learning",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 94,
      "paper_id": "paper_86878",
      "finding_id": "finding_86878",
      "title": "Human Tutoring Improves the Impact of AI Tutor Use on Learning Outcomes",
      "url": "https://phys.org/news/2025-10-adding-human-guidance-ai-benefits.html",
      "processed_at": "2026-01-08T13:19:05.093720",
      "status": "skipped",
      "extracted_fields": {},
      "error": "insufficient content"
    },
    {
      "index": 95,
      "paper_id": "paper_59797",
      "finding_id": "finding_59797",
      "title": "The Scaling Dynamics and Causal Effects of a District-Operated Tutoring Program",
      "url": "https://hechingerreport.org/proof-points-tutoring-research-nashville/",
      "processed_at": "2026-01-08T13:19:05.560099",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This quasi-experimental study examined a large-scale district-operated tutoring program in Nashville, Tennessee, tracking nearly 7,000 K-12 students between 2021 and 2023. The intervention involved both remote online tutoring (initially with college student volunteers) and later in-person tutoring by school teachers, targeting reading and math skills. The study found only a small positive effect on reading test scores and no significant improvement in math scores or course grades in either subject. Students in the middle of the achievement distribution showed the greatest gains, while students at the bottom and top of the distribution showed minimal or no improvement, suggesting the program's effectiveness varied substantially by student baseline achievement level.",
        "measure": "State standardized test scores in reading and math, course grades",
        "study_size": 7000,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "urban",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 96,
      "paper_id": "paper_65417",
      "finding_id": "finding_65417",
      "title": "The Push to Scale Up High-Impact Tutoring",
      "url": "https://www.nea.org/nea-today/all-news-articles/high-impact-tutoring",
      "processed_at": "2026-01-08T13:19:19.717000",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This article synthesizes research on high-impact tutoring programs, which involve small groups of 3-4 students meeting 2-3 times weekly with professionally-trained tutors during school hours. The evidence reviewed spans multiple grade levels and subject areas, drawing from various studies and meta-analyses. Key outcomes include learning gains of 3 to 15 additional months of learning across grade levels, with high-impact tutoring shown to be 20 times more effective than standard tutoring for math and 15 times more effective for reading. The overall finding direction is strongly positive, with the U.S. Department of Education endorsing it as a model best practice for learning recovery.",
        "measure": "Learning gains measured in months of additional learning; comparative effectiveness ratios versus standard tutoring",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 97,
      "paper_id": "paper_50184",
      "finding_id": "finding_50184",
      "title": "Unlocking Hearts & Minds: The Transformative Power of AI-Enhanced High-Dose Tutoring",
      "url": "https://www.norc.org/research/library/unlocking-hearts-and-minds-transformative-power-of-ai-enhanced-high-dose-tutoring.html",
      "processed_at": "2026-01-08T13:19:33.790581",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This expert view article synthesizes existing research on AI-enhanced high-dose tutoring systems for K-12 students, particularly focusing on mathematics instruction. The article reviews evidence from multiple intelligent tutoring systems including Carnegie Learning's LiveHint AI (based on data from 5.5 million students and 1.2 billion math problems), Khan Academy's Khanmigo, and DreamBox. Drawing on decades of research, the authors argue that high-dose tutoring (at least three 30-minute sessions per week in groups of 1-4 students) dramatically improves learning outcomes, increases school attendance, and helps students achieve reading proficiency. The overall finding direction is positive, suggesting AI-enhanced tutoring can democratize access to personalized education while overcoming traditional scalability and cost barriers.",
        "measure": "Learning outcomes, school attendance, reading proficiency",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 98,
      "paper_id": "paper_50184",
      "finding_id": "finding_59352",
      "title": "Unlocking Hearts & Minds: The Transformative Power of AI-Enhanced High-Dose Tutoring",
      "url": "https://www.norc.org/research/library/unlocking-hearts-and-minds-transformative-power-of-ai-enhanced-high-dose-tutoring.html",
      "processed_at": "2026-01-08T13:19:44.498374",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is an expert opinion piece rather than an empirical study, discussing the potential of AI-enhanced high-dose tutoring to transform education. The article synthesizes existing research on high-dose tutoring showing it can improve learning outcomes, increase school attendance, and help students achieve reading proficiency. It describes how AI tutoring systems like Carnegie Learning's LiveHint AI, Khan Academy's Khanmigo, and DreamBox use advanced algorithms to provide personalized, adaptive instruction. The piece argues that AI can help overcome the scalability and cost barriers of traditional high-dose tutoring, but no original empirical findings are reported in this document.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 99,
      "paper_id": "paper_29950",
      "finding_id": "finding_29950",
      "title": "A global evidence review for policymakers: findings from meta-analyses of tutoring",
      "url": "https://files.eric.ed.gov/fulltext/ED641960.pdf",
      "processed_at": "2026-01-08T13:19:57.161628",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-synthesis examined 19 meta-analyses covering over 1,173 study citations to evaluate the effectiveness of tutoring interventions including one-to-one tutoring, small-group tutoring, and Intelligent Tutoring Systems (ITS) on academic outcomes for school-age children. The review found that one-to-one tutoring produced an average effect size of 0.42 (approximately +5 months' progress), small-group tutoring showed an average effect size of 0.34 (+4 months' progress), while ITS demonstrated a lower average effect size of 0.20 (+3 months' progress). The evidence primarily came from high-income, English-speaking countries and focused predominantly on primary school students in reading and mathematics. The findings indicate that tutoring is an effective intervention for addressing learning loss, with intensive blocks of tutoring (12+ hours) and smaller group sizes (2-5 students) being most effective.",
        "measure": "Standardized test scores, curriculum assessments, and examinations converted to months of academic progress",
        "study_size": 1173,
        "effect_size": 0.42,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Studies note larger learning deficits for children from low socio-economic status; disadvantaged students specifically targeted",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Primary and secondary school age (4-18), with majority of research relating to primary schools",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 100,
      "paper_id": "paper_72792",
      "finding_id": "finding_72792",
      "title": "A Systematic Review of Research on Tutoring Implementation: Considerations when Undertaking Complex Instructional Supports for Students",
      "url": "https://edworkingpapers.com/sites/default/files/ai22-652.pdf",
      "processed_at": "2026-01-08T13:20:13.929178",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic review synthesized 33 articles on the implementation of K-12 tutoring programs, defined as one-to-one or small-group human instruction in academic subjects. The review examined three main program types: NCLB Supplemental Education Services, established national models (Reading Partners, Reading Recovery, America Reads), and university professor-run initiatives. The study found that successful tutoring implementation depended on federal policy and funding allocation, strategic partnerships between schools and external providers, school leader buy-in, adequate administrative capacity, and effective tutor recruitment strategies. While tutoring showed promise for academic support, many programs failed to reach targeted students due to low enrollment (only 17% of eligible SES students participated nationally), variable instructional quality, and sustainability challenges, highlighting that program design and implementation processes critically influence outcomes.",
        "measure": "Implementation fidelity indicators, enrollment rates, attendance rates, instructional quality observations, program sustainability",
        "study_size": "not_reported",
        "effect_size": 0.37,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Low-income students in Title I schools (focus of NCLB SES programs)",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grades K-12",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "title_i",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "mixed",
        "governance_type": "mixed",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 4,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 101,
      "paper_id": "paper_29189",
      "finding_id": "finding_29189",
      "title": "The Benefits of One-on-One Tutoring vs. Group Tutoring",
      "url": "https://resourceroomnc.com/2023/03/28/the-benefits-of-one-on-one-tutoring-vs-group-tutoring/",
      "processed_at": "2026-01-08T13:20:33.589231",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This article is not a research study but rather a promotional blog post from Resource Room Learning Center in North Carolina. The content discusses the general benefits of one-on-one tutoring (personalized attention, flexibility, improved confidence) versus group tutoring (collaboration, affordability, social interaction) without presenting any empirical data or research findings. No intervention was tested, no study design was employed, and no measurable outcomes were reported. The article serves as marketing content for the tutoring center's services.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 102,
      "paper_id": "paper_98971",
      "finding_id": "finding_98971",
      "title": "5 Benefits of 1-on-1 Tutoring for Academic Performance",
      "url": "https://northaveeducation.com/blog/1-on-1-tutoring-benefits",
      "processed_at": "2026-01-08T13:20:41.772140",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is not a research paper but a promotional blog post from a tutoring company (North Avenue Education) discussing the general benefits of one-on-one tutoring. The article references academic research and educational initiatives but does not present original empirical findings, specific study designs, or quantitative outcomes. The content describes theoretical benefits including individualized instruction, improved academic performance, better study habits, positive mentor relationships, and growth mindset development, but provides no experimental data or measured results.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 103,
      "paper_id": "paper_81563",
      "finding_id": "finding_81563",
      "title": "One-On-One Tutoring: Top Benefits for Student Success",
      "url": "https://www.prodigygame.com/main-en/blog/one-on-one-tutoring",
      "processed_at": "2026-01-08T13:20:53.777963",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog post summarizes Benjamin Bloom's 1984 research on one-on-one tutoring, which found that students receiving individual tutoring performed better than 98% of peers in traditional classroom environments. The intervention involves personalized one-on-one tutoring sessions where tutors customize lessons to individual student needs and learning pace. The population discussed includes K-12 students in general educational settings. The referenced study design from Bloom (1984) compared tutored students to those in conventional classroom instruction. The main finding indicates substantial positive effects of individualized tutoring on student academic performance and mastery of concepts.",
        "measure": "Academic performance compared to peers in traditional classroom",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 104,
      "paper_id": "paper_8268",
      "finding_id": "finding_8268",
      "title": "Children's learning-by-teaching with a social robot versus a younger child: Comparing interactions and tutoring styles",
      "url": "https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2022.875704/full",
      "processed_at": "2026-01-08T13:21:06.884571",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study compared learning-by-teaching interactions between sixth-grade tutors (ages 12-13) teaching either a social robot tutee or a third-grade child tutee (ages 9-10) using a two-player mathematics game in a Swedish primary school. The within-subject design involved 10 sixth-graders conducting 30-minute tutoring sessions with both tutee types. Video analysis using the IRFCE tutoring framework revealed significant differences: robot tutees initiated more dialogs and asked significantly more questions, while child tutees received significantly more and longer explanations from tutors and were more involved in decision-making. The findings indicate both conditions provide learning opportunities for tutors but through different mechanisms\u2014robot tutees challenged tutors with questions and feedback while child tutees enabled tutors to practice explanations and collaborative engagement.",
        "measure": "Frequency counts of tutoring actions (initiations, questions, explanations, tutee involvement, evaluation feedback) coded from video transcripts using IRFCE framework",
        "study_size": 20,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "10 sixth graders (5 girls), 10 third graders (6 girls)",
        "student_age_distribution": "Tutors: 12-13 years old (sixth grade); Tutees: 9-10 years old (third grade)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 105,
      "paper_id": "paper_23906",
      "finding_id": "finding_23906",
      "title": "The Impact of a Peer-Tutoring Model on the Academic Performance of Secondary Students",
      "url": "https://scholarcommons.sc.edu/cgi/viewcontent.cgi?article=5496&context=etd",
      "processed_at": "2026-01-08T13:21:24.789683",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 106,
      "paper_id": "paper_91728",
      "finding_id": "finding_91728",
      "title": "Examining the Academic Effects of Cross-age Tutoring: A Meta-analysis",
      "url": "https://link.springer.com/article/10.1007/s10648-025-09997-z",
      "processed_at": "2026-01-08T13:21:33.090574",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 32 studies on cross-age tutoring, where older tutors are paired with younger tutees in school settings. The studies included randomized controlled trials and quasi-experimental designs with a combined sample of 5,500 participants, primarily elementary school students. The intervention focused predominantly on reading skills (86% of studies) with some mathematics instruction. Results showed a small to moderate positive overall effect size of 0.34 on academic outcomes, with tutees benefiting at 0.33 and tutors at 0.39. Moderator analyses revealed no significant differences based on number of sessions, tutor type (older students vs. adults), tutee risk status, or subject area.",
        "measure": "Standardized mean differences (Hedges' g) on academic outcomes including reading comprehension, decoding skills, and mathematics achievement",
        "study_size": 5500,
        "effect_size": 0.34,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Tutees typically in 1st to 3rd grade (78%); tutors in grades 5 through 12 or adult/university students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 107,
      "paper_id": "paper_91728",
      "finding_id": "finding_76398",
      "title": "Examining the Academic Effects of Cross-age Tutoring: A Meta-analysis",
      "url": "https://link.springer.com/article/10.1007/s10648-025-09997-z",
      "processed_at": "2026-01-08T13:21:49.273338",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 32 studies on cross-age tutoring, where older tutors are paired with younger tutees in school settings. The study population included primarily elementary students (grades 1-3 as tutees) and older students or adult volunteers as tutors, with a combined sample of 5,500 participants. Using robust variance estimation in random effects meta-regression models, the analysis found a small to moderate positive effect on academic outcomes with an overall effect size of 0.34, with tutees benefiting at 0.33 and tutors at 0.39. Moderator analyses revealed no significant differences based on number of sessions, tutor type, tutee risk status, or subject area (reading vs. math), indicating broad applicability of cross-age tutoring across various educational contexts.",
        "measure": "Standardized mean differences (Hedges' g) on academic outcomes including reading comprehension, decoding skills, and mathematics",
        "study_size": 5500,
        "effect_size": 0.34,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Tutees primarily grades 1-3 (78%); tutors grades 5-12 or adult volunteers",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 108,
      "paper_id": "paper_29047",
      "finding_id": "finding_29047",
      "title": "A Spoonful of Success: Undergraduate Tutor-Tutee Interactions and Performance",
      "url": "https://files.eric.ed.gov/fulltext/EJ1114523.pdf",
      "processed_at": "2026-01-08T13:22:05.957040",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined 333 tutor-tutee pairs at a student success center at a mid-sized public comprehensive university in the southern United States during spring 2015. Using modified Student-Teacher Relationship Scales and path analysis, researchers investigated how tutor-tutee relationship dynamics influence independent study skill acquisition and course performance. The study found that positive tutor-tutee relationships characterized by closeness and low conflict were associated with tutors suggesting more independent study skills, which in turn led to tutees adopting these skills. The acquisition of independent study skills (such as class attendance, preparation, and asking questions) and frequency of tutoring sessions were directly associated with perceived grade improvement, with students reporting approximately one full letter grade improvement on average.",
        "measure": "Perceived grade improvement (difference between entry grade and anticipated final grade), resulting independent learning skills scale, suggested independent learning skills scale",
        "study_size": 333,
        "effect_size": "not_reported",
        "student_racial_makeup": "Tutees: 39% White, 52.6% Black, 5.4% Other; Tutors: 69.7% White, 21.6% Black, 8.7% Other",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "Tutees: 80% female, 20% male; Tutors: 77.7% female, 22.3% male",
        "student_age_distribution": "Undergraduate students (college-aged)",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 109,
      "paper_id": "paper_22327",
      "finding_id": "finding_22327",
      "title": "Undergraduate technical skills training guided by student tutors \u2013 Analysis of tutors' attitudes, tutees' acceptance and learning progress in an innovative teaching model",
      "url": "https://bmcmededuc.biomedcentral.com/articles/10.1186/1472-6920-8-18",
      "processed_at": "2026-01-08T13:22:23.293273",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study evaluated a cross-year peer tutoring system for undergraduate medical students learning technical clinical skills in a skills lab setting at a German university. Using a mixed-methods design combining web-based surveys (n=85 respondents from 127 participants) and focus group analysis with 13 tutors, the study assessed tutee acceptance and self-confidence changes. Results showed very high acceptance of the peer teaching model (5.69/6.0 on Likert scale), with 85% of tutees considering peer tutoring sufficient for skills training. Self-confidence ratings improved significantly for all trained skills, with an average increase of 1.96 points on a 6-point scale (p<0.002), demonstrating positive outcomes for this peer-assisted learning approach.",
        "measure": "Self-confidence ratings on 6-point Likert scale, acceptance ratings, global tutor ratings",
        "study_size": 127,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "45 male, 82 female (35% male, 65% female)",
        "student_age_distribution": "mean age 22.9 \u00b1 0.6 years, 3rd year medical students",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 110,
      "paper_id": "paper_47895",
      "finding_id": "finding_47895",
      "title": "To Wait or Not to Wait: Adding to the Debate on Immediate Versus Delayed Feedback",
      "url": "https://repository.isls.org/bitstream/1/8637/1/ICLS2022_1910-1911.pdf",
      "processed_at": "2026-01-08T13:22:39.878787",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This randomized controlled trial examined the effects of immediate versus delayed feedback on algebra performance among 855 seventh-grade students using the ASSISTments online tutoring system. Students were randomly assigned to receive either immediate feedback (hints and correctness feedback during problem-solving) or delayed feedback (feedback only after assignment completion) across four 30-minute intervention sessions. The study found significant overall learning gains from pre-assessment to end-of-semester assessment across both conditions (0.63 points higher, p<.001). However, there was no statistically significant difference between immediate and delayed feedback conditions on end-of-semester assessment scores (d<.17, p=.12), and prior knowledge did not moderate the effect of feedback timing.",
        "measure": "End-of-semester algebra assessment scores (10-item validated measure of conceptual understanding, procedural knowledge, and flexibility)",
        "study_size": 855,
        "effect_size": 0.17,
        "student_racial_makeup": "52% White, 27% Asian, 13% Hispanic/Latino, 8% other",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "50% male, 50% female",
        "student_age_distribution": "7th grade",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 111,
      "paper_id": "paper_47895",
      "finding_id": "finding_93629",
      "title": "To Wait or Not to Wait: Adding to the Debate on Immediate Versus Delayed Feedback",
      "url": "https://repository.isls.org/bitstream/1/8637/1/ICLS2022_1910-1911.pdf",
      "processed_at": "2026-01-08T13:22:49.795746",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This randomized controlled trial examined the effects of immediate versus delayed feedback on algebra performance among 855 seventh-grade students using the ASSISTments online tutoring system. Students were randomly assigned to receive either immediate feedback (hints and correctness feedback during problem-solving) or delayed feedback (feedback only after assignment completion) across four 30-minute intervention sessions. The study found significant overall learning gains from pre-assessment to end-of-semester assessment across both conditions (0.63 points higher, p<.001). However, there was no statistically significant difference between immediate and delayed feedback conditions on end-of-semester assessment scores (d<.17, p=.12), and prior knowledge did not moderate the effect of feedback timing.",
        "measure": "End-of-semester algebra assessment scores (10-item validated measure of conceptual understanding, procedural knowledge, and flexibility)",
        "study_size": 855,
        "effect_size": 0.17,
        "student_racial_makeup": "52% White, 27% Asian, 13% Hispanic/Latino, 8% other",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "50% male, 50% female",
        "student_age_distribution": "7th grade",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 112,
      "paper_id": "paper_24169",
      "finding_id": "finding_24169",
      "title": "Formative assessment: Comparing immediate and delayed feedback",
      "url": "https://commons.lib.jmu.edu/cgi/viewcontent.cgi?article=1383&context=master201019",
      "processed_at": "2026-01-08T13:23:01.045973",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 113,
      "paper_id": "paper_24169",
      "finding_id": "finding_30134",
      "title": "Formative assessment: Comparing immediate and delayed feedback",
      "url": "https://commons.lib.jmu.edu/cgi/viewcontent.cgi?article=1383&context=master201019",
      "processed_at": "2026-01-08T13:23:05.436057",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 114,
      "paper_id": "paper_66178",
      "finding_id": "finding_66178",
      "title": "The Effects of Immediate and Delayed Feedback on Secondary Distance Learners",
      "url": "https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=6656&context=facpub",
      "processed_at": "2026-01-08T13:23:10.002521",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined the effects of immediate versus delayed feedback on secondary distance learners enrolled in online courses. The quasi-experimental design compared student performance outcomes between groups receiving immediate automated feedback and those receiving delayed instructor feedback. The study population consisted of high school students in distance learning programs. Results indicated mixed findings, with immediate feedback showing advantages for certain types of learning tasks while delayed feedback was more effective for others. The main finding suggests that feedback timing effects depend on the nature of the learning task and student characteristics.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 115,
      "paper_id": "paper_66178",
      "finding_id": "finding_281",
      "title": "The Effects of Immediate and Delayed Feedback on Secondary Distance Learners",
      "url": "https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=6656&context=facpub",
      "processed_at": "2026-01-08T13:23:26.329248",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined the effects of immediate versus delayed feedback on secondary distance learners enrolled in online courses. The quasi-experimental design compared student performance outcomes between groups receiving immediate automated feedback and those receiving delayed instructor feedback. The study population consisted of high school students in distance learning programs. Results indicated mixed effects, with immediate feedback showing advantages for certain types of learning tasks while delayed feedback was more beneficial for others. The findings suggest that the optimal timing of feedback may depend on the nature of the learning content and task complexity.",
        "measure": "Student performance on course assessments and learning outcomes",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "High school age (approximately 14-18 years)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 116,
      "paper_id": "paper_24706",
      "finding_id": "finding_24706",
      "title": "Timing of feedback and retrieval practice: a laboratory study with EFL students",
      "url": "https://www.nature.com/articles/s41599-024-03983-6",
      "processed_at": "2026-01-08T13:23:46.189285",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial examined the effects of immediate versus delayed feedback on retrieval practice among 177 Saudi undergraduate EFL students learning from a prose passage. Participants were randomly assigned to four groups: repeated studying, repeated testing without feedback, repeated testing with immediate feedback, and repeated testing with delayed feedback. Testing occurred immediately, one week later, and one month later using short-answer questions. Results showed that both feedback conditions significantly outperformed no-feedback and restudying conditions, with immediate feedback producing superior long-term retention compared to delayed feedback at both one-week and one-month intervals.",
        "measure": "Number of correct answers on 15-item short-answer comprehension tests (scored 0-2 per item, max 30 points)",
        "study_size": 177,
        "effect_size": 0.5,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "100% male",
        "student_age_distribution": "ages 19-23, mean age 21.4 years (SD = 1.6)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 117,
      "paper_id": "paper_24706",
      "finding_id": "finding_84217",
      "title": "Timing of feedback and retrieval practice: a laboratory study with EFL students",
      "url": "https://www.nature.com/articles/s41599-024-03983-6",
      "processed_at": "2026-01-08T13:24:01.363273",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial examined the effects of immediate versus delayed feedback on retrieval practice among 177 Saudi undergraduate EFL students learning from a prose passage. Participants were randomly assigned to four groups: repeated studying, repeated testing without feedback, repeated testing with immediate feedback, and repeated testing with delayed feedback. Testing occurred immediately, one week later, and one month later using short-answer questions. Results showed that both feedback conditions significantly outperformed no-feedback and restudying conditions, with immediate feedback producing superior long-term retention compared to delayed feedback at both one-week and one-month intervals.",
        "measure": "Number of correct answers on 15-item short-answer comprehension tests (scored 0-2 per item, max 30 points)",
        "study_size": 177,
        "effect_size": 0.5,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "100% male",
        "student_age_distribution": "ages 19-23, mean age 21.4 years (SD = 1.6)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 118,
      "paper_id": "paper_68342",
      "finding_id": "finding_68342",
      "title": "The Power of Feedback Revisited: A Meta-Analysis of Educational Feedback Research",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.03087/full",
      "processed_at": "2026-01-08T13:24:16.957202",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis integrated 435 studies with 994 effect sizes and over 61,000 participants to examine the effects of feedback on student learning outcomes. Using a random-effects model, the study found a medium overall effect size (d = 0.48) of feedback on student learning, though with significant heterogeneity indicating feedback cannot be understood as a single consistent treatment. Moderator analysis revealed that high-information feedback was most effective, while simple reinforcement and punishment had low effects. Feedback showed higher impact on cognitive and motor skills outcomes than on motivational and behavioral outcomes, with 17% of effects being negative overall.",
        "measure": "Student learning outcomes including achievement, motivation, and behavioral change",
        "study_size": 61000,
        "effect_size": 0.48,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 119,
      "paper_id": "paper_57880",
      "finding_id": "finding_57880",
      "title": "A meta-analysis of the effects of context, content, and task factors of digitally delivered instructional feedback on learning performance",
      "url": "https://link.springer.com/article/10.1007/s10984-024-09501-4",
      "processed_at": "2026-01-08T13:24:33.117775",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the effects of digitally delivered instructional feedback on learning performance across 116 interventions from 46 studies published between 2004-2019. The study population included learners aged 5 and older across primary, secondary, and higher education settings. Using a random effects model, the researchers found a moderate positive summary effect (Hedges' g = 0.41, SE = 0.05) for digitally delivered feedback on learning performance. Key moderators included feedback focus (process-focused feedback was most effective), educational sector (higher education showed stronger effects), and learner control. The meta-regression revealed that process-focused feedback was the primary factor explaining heterogeneity in learning outcomes.",
        "measure": "Learning performance outcomes including academic, social, and psychomotor domains",
        "study_size": 116,
        "effect_size": 0.41,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "5 years and older, spanning primary through higher education",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 120,
      "paper_id": "paper_57880",
      "finding_id": "finding_72011",
      "title": "A meta-analysis of the effects of context, content, and task factors of digitally delivered instructional feedback on learning performance",
      "url": "https://link.springer.com/article/10.1007/s10984-024-09501-4",
      "processed_at": "2026-01-08T13:24:49.034436",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the effects of digitally delivered instructional feedback on learning performance across 116 interventions from 46 studies published between 2004-2019. The study population included learners aged 5 and older across primary, secondary, and higher education settings. Using a random effects model, the researchers found a moderate positive summary effect (Hedges' g = 0.41, SE = 0.05) for digitally delivered feedback on learning performance. Significant moderators included feedback focus (process-focused feedback was most effective), educational sector (higher education showed stronger effects), learner control, and assessment type. The meta-regression revealed that process-focused feedback was the key factor explaining heterogeneity in learning outcomes.",
        "measure": "Learning performance outcomes including academic, social, and psychomotor domains",
        "study_size": 116,
        "effect_size": 0.41,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "5 years and older, spanning primary through higher education",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 121,
      "paper_id": "paper_64908",
      "finding_id": "finding_64908",
      "title": "The Effects of Adaptive Feedback on Student's Learning Gains",
      "url": "https://thesai.org/Publications/ViewPaper?Volume=12&Issue=7&Code=IJACSA&SerialNo=9",
      "processed_at": "2026-01-08T13:25:04.811301",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study investigated the effect of adaptive feedback characteristics on student learning gains using an intelligent tutoring system that retrieves appropriate feedback based on established weights between related concepts. The research employed a quasi-experimental design comparing three groups: adaptive feedback, normal feedback, and non-feedback conditions. Students who received adaptive feedback demonstrated learning gains and normalized learning gains of 0.87 and 0.05 over the normal feedback group, and 0.97 and 0.07 over the non-feedback group. The authors report that these results yielded better outcomes than previous similar studies, indicating a positive effect of adaptive feedback on learning.",
        "measure": "Learning gains and normalized learning gains",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 122,
      "paper_id": "paper_70191",
      "finding_id": "finding_70191",
      "title": "Peer Tutoring and Academic Achievement in Mathematics: A Meta-Analysis",
      "url": "https://www.ejmste.com/article/peer-tutoring-and-academic-achievement-in-mathematics-a-meta-analysis-5265",
      "processed_at": "2026-01-08T13:25:13.472289",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 50 independent studies of peer tutoring programs in mathematics across multiple educational stages. The study found that 88% of peer tutoring programs had positive effects on academic performance, with an overall effect size of Hedge's g = 0.333. The analysis investigated moderating variables and found that educational stage, study design, program duration, tutor knowledge level, timing (school vs. out-of-school), and sample size were significant moderators. Variables such as participant age, roles, tutee skills, session length, and frequency were not significant moderators of academic achievement.",
        "measure": "Academic achievement in mathematics (various standardized and researcher-developed measures across included studies)",
        "study_size": "not_reported",
        "effect_size": 0.333,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 123,
      "paper_id": "paper_40400",
      "finding_id": "finding_40400",
      "title": "The Effects of Peer Tutoring on Mathematics Performance: A Recent Review",
      "url": "https://eric.ed.gov/?id=EJ400662",
      "processed_at": "2026-01-08T13:25:27.615560",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This review examined studies published from 1980 to 1989 on the effects of peer tutoring on mathematics performance. The study population included low achievers, mildly handicapped, and socially disadvantaged children at the elementary and secondary education levels. Using a meta-analytic approach, the authors synthesized findings across multiple studies. The key outcome measured was mathematics achievement and cognitive development. Results indicate that peer tutoring is effective in promoting significant cognitive gains for both tutors and tutees in these populations.",
        "measure": "Mathematics achievement and cognitive development",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "socially disadvantaged children",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "elementary and secondary education levels",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 124,
      "paper_id": "paper_70746",
      "finding_id": "finding_70746",
      "title": "Blended Learning Effect on Mathematical Skills: A Meta-Analysis Study",
      "url": "https://iieta.org/journals/isi/paper/10.18280/isi.280122",
      "processed_at": "2026-01-08T13:25:37.190429",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis synthesized 37 effect sizes from 26 primary studies examining the effectiveness of blended learning on students' mathematical abilities compared to traditional learning. The studies included various populations from elementary school through college across multiple countries. Using a random effects model, the analysis found a combined effect size of d=1.01 (p=0.00), classified as a large effect. Moderator analysis revealed significant differences based on skill type, media platform, education level, and publication type, but not sample size. The findings confirm that blended learning has a substantial positive effect on mathematical skills, with the largest effects observed for conceptual understanding and critical thinking outcomes.",
        "measure": "Mathematical skills including learning achievement, critical thinking, problem solving, and concept understanding",
        "study_size": 37,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary through college students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 125,
      "paper_id": "paper_99577",
      "finding_id": "finding_99577",
      "title": "Evaluating the effectiveness of private supplementary tutoring on grade 12 learners' mathematics achievement",
      "url": "https://www.ejmste.com/download/evaluating-the-effectiveness-of-private-supplementary-tutoring-on-grade-12-learners-mathematics-15168.pdf",
      "processed_at": "2026-01-08T13:25:51.702903",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study evaluated the effectiveness of private supplementary tutoring on grade 12 learners' mathematics performance in the OR Tambo Inland District of South Africa using a causal-comparative research design. The study involved 347 participants from four schools, comparing 80 students who attended private tutoring with 267 who did not. Students who attended private supplementary tutoring scored significantly higher on a standardized Euclidean geometry test (M=53.95, SD=28.054) compared to non-tutored students (M=33.59, SD=25.807). An independent samples t-test revealed this difference was statistically significant (t(345)=6.07, p<.0001) with a large effect size (d=0.773), indicating that private supplementary tutoring substantially enhances mathematics performance.",
        "measure": "Standardized Euclidean geometry test scores",
        "study_size": 347,
        "effect_size": 0.773,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "86.1% of non-tutored students cited affordability as primary barrier to tutoring",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grade 12 learners",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 126,
      "paper_id": "paper_9286",
      "finding_id": "finding_9286",
      "title": "The Impressive Effects of Tutoring on PreK-12 Learning: A Systematic Review and Meta-Analysis of the Experimental Evidence",
      "url": "https://www.nber.org/system/files/working_papers/w27476/w27476.pdf",
      "processed_at": "2026-01-08T13:26:08.580883",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis synthesized 96 randomized controlled trials examining tutoring interventions (one-on-one or small-group instruction) for PreK-12 students across literacy and math subjects. The study population was predominantly elementary school students, with nearly half of studies involving first-graders. Using random effects models with inverse variance weights and robust variance estimation, the authors found an overall pooled effect size of 0.37 standard deviations on learning outcomes. Effects were stronger for teacher tutoring (0.50 SD) and paraprofessional tutoring (0.40 SD) compared to nonprofessional (0.21 SD) and parent tutoring (0.23 SD), with during-school programs showing larger impacts than after-school programs.",
        "measure": "Standardized test scores in reading/literacy and mathematics",
        "study_size": 96,
        "effect_size": 0.37,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "PreK through Grade 12, with 48% of studies involving first-graders and 19% involving PreK-Kindergarten",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 127,
      "paper_id": "paper_22223",
      "finding_id": "finding_22223",
      "title": "Boost Math Skills with Intelligent Tutoring Systems Insights",
      "url": "https://zipline.ac/2025/09/23/intelligent-tutoring-systems-help-learning/",
      "processed_at": "2026-01-08T13:26:27.532247",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog post synthesizes findings from multiple meta-analyses examining the effectiveness of Intelligent Tutoring Systems (ITS) for K-12 mathematics instruction. The review draws on studies by Ma et al. (2014), Kulik and Fletcher (2016), and L\u00e9tourneau et al. (2025), which collectively analyzed dozens of studies on ITS effectiveness. Key findings indicate effect sizes ranging from 0.41 to 0.66 standard deviations in favor of ITS over traditional instruction, with the strongest results coming from systems providing immediate, step-level feedback. The evidence also suggests ITS can help reduce achievement gaps, with Huang et al. (2016) finding that the ALEKS system helped lower-income and lower-performing 6th-grade students catch up to peers.",
        "measure": "Math achievement/proficiency test scores",
        "study_size": "not_reported",
        "effect_size": 0.41,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Studies referenced include lower-income students showing benefits from ITS",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12, with specific mention of 6th grade and elementary/middle school",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 128,
      "paper_id": "paper_49396",
      "finding_id": "finding_49396",
      "title": "Online Math Tutor vs ChatGPT: Why Human Tutors Win Every Time (2025 Study)",
      "url": "https://www.tutor-ology.com/post/online-math-tutor-vs-chatgpt-why-human-tutors-win-every-time-2025-study",
      "processed_at": "2026-01-08T13:26:40.201923",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog post compares human online math tutors to AI tools like ChatGPT for mathematics instruction. The content focuses primarily on middle school students struggling with algebra and geometry. The post presents case studies and claims that human tutors are 78% more effective than AI tools, with 94% of students showing grade improvement within 4-6 weeks. Two anecdotal case studies are presented: a 7th grader improving from D+ to B+ in 8 weeks and a 10th grader improving from C- to A- in 6 weeks after switching from AI tools to human tutoring. However, no rigorous study design, control group, or peer-reviewed methodology is described to support these claims.",
        "measure": "Grade improvement (letter grades)",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Middle school and high school students (7th-10th grade mentioned in case studies)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 129,
      "paper_id": "paper_57054",
      "finding_id": "finding_57054",
      "title": "AI Tutors vs Human Tutors: Which Is Best for Your Child?",
      "url": "https://www.starspark.ai/blog/ai-tutors-vs-human-tutors-best-for-your-child",
      "processed_at": "2026-01-08T13:26:53.917234",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog post compares AI tutors (specifically StarSpark.AI) with human tutors for K-12 math education, targeting parents as the primary audience. The post cites multiple external studies: Stanford's Center for Learning Technologies found students using AI-guided instruction learned 1.5 to 2 times faster than peers in traditional settings. In pilot schools using StarSpark, 91% of students reported improved clarity and confidence in math, and students improved math problem-solving accuracy by 0.7 standard deviations, comparable to gains from small-group tutoring programs. The Institute of Education Sciences research cited indicates students receiving immediate feedback retain up to 80 percent more information than those with delayed correction.",
        "measure": "Math problem-solving accuracy, student-reported confidence and clarity, learning speed",
        "study_size": "not_reported",
        "effect_size": 0.7,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 (grades K-12)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 130,
      "paper_id": "paper_18478",
      "finding_id": "finding_18478",
      "title": "AI Tutors vs Human Tutors: What's the Right Choice?",
      "url": "https://tutorai.me/blog/ai-tutors-vs-human-tutors/",
      "processed_at": "2026-01-08T13:27:03.454238",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog article synthesizes multiple studies and pilot programs comparing AI tutors to human tutors across various educational contexts. A Harvard 2024 study found students using AI tutors completed assignments 2x faster with similar or better accuracy. A New York City pilot program using GPT-4-based tutoring tools across 10 schools showed reading levels rose by 15%. Khan Academy reported a 30% increase in test scores among students using Khanmigo for SAT prep, and Duolingo Max increased engagement by 40% among adult learners. Overall, the evidence presented suggests AI tutoring produces positive outcomes for speed, efficiency, and academic performance, though the article recommends a hybrid approach combining AI and human tutors for optimal results.",
        "measure": "Assignment completion speed, reading levels, test scores, engagement metrics",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 131,
      "paper_id": "paper_6506",
      "finding_id": "finding_6506",
      "title": "Investigating Factors that Influence the Peer Tutoring Experience in Mathematics",
      "url": "https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1004&context=nera-2018",
      "processed_at": "2026-01-08T13:27:13.187483",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This qualitative study investigated factors influencing peer tutoring experiences in mathematics at a university tutoring center. The study involved undergraduate students serving as both tutors and tutees in mathematics courses. Using surveys and interviews, researchers examined tutor-tutee interactions, preparation, and engagement. Findings revealed that while peer tutoring was generally perceived positively, effectiveness varied based on tutor preparation, communication skills, and the nature of tutor-tutee relationships. The study identified both facilitating factors (such as tutor approachability and subject knowledge) and barriers (such as scheduling difficulties and tutor inexperience) to successful peer tutoring experiences.",
        "measure": "Surveys and semi-structured interviews assessing tutoring experience quality",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 132,
      "paper_id": "paper_42636",
      "finding_id": "finding_42636",
      "title": "Effects of Conceptual Understanding, Math and Visualization Skills on Problem-Solving in Statics",
      "url": "https://peer.asee.org/effects-of-conceptual-understanding-math-and-visualization-skills-on-problem-solving-in-statics.pdf",
      "processed_at": "2026-01-08T13:27:29.385982",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined undergraduate engineering students enrolled in Statics courses to identify clusters based on mathematics skills, spatial reasoning, and conceptual knowledge related to Statics. Using Ward's method of cluster analysis with 336 participants, researchers identified six statistically significant clusters that predicted performance on mid-semester exam problems with large effect sizes (partial-eta-squared = 0.122). The quasi-experimental design revealed that lower-performing clusters demonstrated deficiencies in basic Statics knowledge and math skills, particularly in understanding reaction forces and modeling pin joints. The findings suggest that different student clusters require different instructional interventions, with the poorest performing cluster (CR6) showing significant gaps in fundamental support modeling knowledge compared to the highest performing cluster (CR1).",
        "measure": "Mid-semester Statics examination scores (free body diagrams, equilibrium equations, distributed load analysis)",
        "study_size": 336,
        "effect_size": 0.122,
        "student_racial_makeup": "87% Caucasian, 6% Asian, 4.2% Hispanic, 1.5% Other, 1% African-American, 0.6% Indian, 0.3% Pacific Islander",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "88% male, 12% female",
        "student_age_distribution": "88% sophomores, 8% juniors, 2% seniors, 1% freshmen",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 133,
      "paper_id": "paper_77008",
      "finding_id": "finding_77008",
      "title": "The Impact of Artificial Intelligence on Student Achievement in Education",
      "url": "https://scholarworks.uni.edu/cgi/viewcontent.cgi?article=1920&context=grp",
      "processed_at": "2026-01-08T13:27:45.804682",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This literature review examines the effectiveness of intelligent tutoring systems (ITS) in increasing student academic achievement. The review synthesizes findings from multiple studies across various educational contexts and grade levels. The study design is a systematic literature review analyzing existing research on ITS implementations. Key outcomes measured include student achievement gains, particularly in mathematics and science domains. The main finding indicates that intelligent tutoring systems generally have a positive effect on student learning outcomes compared to traditional instruction methods.",
        "measure": "Academic achievement test scores",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 134,
      "paper_id": "paper_22491",
      "finding_id": "finding_22491",
      "title": "The effectiveness of intelligent tutoring systems in supporting students with varying levels of programming experience",
      "url": "https://link.springer.com/article/10.1007/s44217-024-00385-3",
      "processed_at": "2026-01-08T13:28:03.631168",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This mixed-methods study examined the effectiveness of an Intelligent Tutoring System (Blackbox) in supporting 160 undergraduate computer science students in Southern China with varying levels of programming experience (beginner, intermediate, advanced). The quantitative analysis using chi-square and ANOVA tests revealed significant differences in ITS effectiveness based on programming proficiency levels. Advanced students showed the most significant improvement in programming skills and found ITS feedback more valuable, while intermediate and advanced students reported higher satisfaction with the ITS interface. However, no significant association was found between programming level and increases in confidence/motivation or perceived usefulness in completing tasks, indicating mixed results across different outcome measures.",
        "measure": "Self-reported programming skill improvement, usefulness of ITS feedback, satisfaction with interface and functionality, confidence and motivation levels",
        "study_size": 160,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "East Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 135,
      "paper_id": "paper_19650",
      "finding_id": "finding_19650",
      "title": "An Exploratory Comparison of Traditional Classroom Instruction and Anchored Instruction with Secondary School Students: Turkish Experience",
      "url": "https://www.ejmste.com/download/an-exploratory-comparison-of-traditional-classroom-instruction-and-anchored-instruction-with-4345.pdf",
      "processed_at": "2026-01-08T13:28:18.097863",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study investigated the impact of anchored instruction using video-based learning on sixth-grade students' mathematics achievement in Turkey. The experimental group (n=32) received anchored instruction using a video called 'Taraftar' about set operations, while the control group (n=34) received traditional teacher-centered instruction. Both groups were taught by the same instructor for two weeks covering the same content. Results showed the experimental group significantly outperformed the control group on both post-test (75.4 vs 64.1, p<0.05) and permanence test (72.8 vs 58.0, p<0.05), indicating anchored instruction was more effective for both knowledge acquisition and retention.",
        "measure": "Achievement test scores (pre-test, post-test, and permanence test) measuring mathematics knowledge on set operations",
        "study_size": 66,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "low socio-economic status families",
        "student_gender_makeup": "Experimental: 19 male, 13 female; Control: 20 male, 14 female",
        "student_age_distribution": "6th grade (secondary school)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "low",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 136,
      "paper_id": "paper_86508",
      "finding_id": "finding_86508",
      "title": "What Works Better than Traditional Math Instruction",
      "url": "https://www.alfiekohn.org/article/works-better-traditional-math-instruction/",
      "processed_at": "2026-01-08T13:28:34.131312",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This book chapter synthesizes research comparing traditional drill-and-skill math instruction with constructivist approaches emphasizing conceptual understanding and student-invented problem-solving strategies. The review examines multiple studies across elementary grades in the United States, including quasi-experimental comparisons and analyses of international assessment data (TIMSS, NAEP). Key outcomes measured include computational skills, mathematical reasoning, problem-solving ability, and transfer of learning. The consistent finding across studies is that constructivist approaches produce better reasoning and conceptual understanding without sacrificing computational skills, while traditional instruction leads to superficial learning and poor number sense.",
        "measure": "Mathematical reasoning, computational skills, standardized achievement tests, problem-solving ability",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "One study mentioned low-income, mostly minority students in Maryland",
        "student_socioeconomic_makeup": "One study focused on low-income students; general population otherwise not specified",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary grades (first through third grade primarily), with some references to middle and high school",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 137,
      "paper_id": "paper_78411",
      "finding_id": "finding_78411",
      "title": "Student success in intelligent tutoring systems: An assessment of key factors",
      "url": "https://iacis.org/iis/2025/1_iis_2025_126-140.pdf",
      "processed_at": "2026-01-08T13:28:49.967638",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined 73 high school seniors from three U.S. high schools who used the ALEKS Placement, Preparation, and Learning (PPL) intelligent tutoring system throughout an academic year to prepare for college-level mathematics. Students completed the ALEKS Mathematics Placement Exam in October (pre-test) and May (post-test), with researchers analyzing factors including exam time, module mastery scores, cumulative module time, and teacher assignment. Multiple linear regression revealed that 39.1% of variance in exam score growth was explained by the predictor variables, with the amount of time spent taking the placement exam and the number of modules mastered being significant positive predictors of exam performance. The findings suggest that students who took more time on the final exam and mastered more topics in the learning modules demonstrated greater improvement in college mathematics placement scores.",
        "measure": "ALEKS College Mathematics Placement Exam scores (difference between October pre-test and May post-test)",
        "study_size": 73,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 16-18",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 138,
      "paper_id": "paper_78411",
      "finding_id": "finding_61131",
      "title": "Student success in intelligent tutoring systems: An assessment of key factors",
      "url": "https://iacis.org/iis/2025/1_iis_2025_126-140.pdf",
      "processed_at": "2026-01-08T13:29:04.380826",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined 73 high school seniors from three U.S. high schools who used the ALEKS Placement, Preparation, and Learning (PPL) intelligent tutoring system throughout an academic year to prepare for college-level mathematics. Students completed the ALEKS Mathematics Placement Exam in October (pre-test) and May (post-test), with researchers analyzing factors including exam time, module mastery scores, cumulative module time, and teacher assignment. Multiple linear regression revealed that 39.1% of variance in exam score growth was explained by the predictor variables, with the amount of time spent taking the placement exam and the number of modules mastered being significant positive predictors of exam performance. The findings suggest that students who took more time on the final exam and mastered more topics in the learning modules demonstrated greater improvement in college mathematics placement scores.",
        "measure": "ALEKS PPL Mathematics Placement Exam scores (difference between October pre-test and May post-test)",
        "study_size": 73,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 16-18",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 139,
      "paper_id": "paper_56931",
      "finding_id": "finding_56931",
      "title": "Comparing Traditional and Modern Teaching Methods in Mathematics Education: Effects on Undergraduate Students' Achievement and Motivation",
      "url": "https://cdn.ymaws.com/www.psichi.org/resource/resmgr/journal_2024/29_150_norton.pdf",
      "processed_at": "2026-01-08T13:29:18.928062",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This quasi-experimental study compared traditional (teacher-centered, lecture-based) and modern (student-centered, collaborative) teaching methods on mathematical achievement and motivation among 43 undergraduate students at a private liberal arts college in Arkansas. Participants were assigned to one of five instructional sessions covering combinatorics content, with a pretest-posttest design measuring achievement and the Mathematics Motivation Questionnaire assessing motivation. Results showed that teaching method had no significant effect on student achievement (F(1, 37) = 2.00, p = .17, partial \u03b7\u00b2 = .05) or motivation (Wilks' Lambda = .86, F(1, 41) = 1.25, p = .30). However, students with intermediate and advanced mathematical education levels scored significantly higher on posttests and motivation subscales (self-regulation, self-efficacy, utility value) than introductory students.",
        "measure": "Pretest-posttest content assessment scores and Mathematics Motivation Questionnaire subscales",
        "study_size": 43,
        "effect_size": 0.05,
        "student_racial_makeup": "African American (n=6), Asian (n=1), Asian American/Pacific Islander (n=4), European American (n=25), Hispanic/Latin American (n=2), Multiracial (n=3), Other/Not Specified (n=2)",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "Women (n=13), Men (n=30)",
        "student_age_distribution": "ages 18-24, mean age 19.95",
        "school_type": "postsecondary",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "independent",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 140,
      "paper_id": "paper_27987",
      "finding_id": "finding_27987",
      "title": "Heterogeneity in Mathematics Intervention Effects: Evidence from a Meta-Analysis of 191 Randomized Experiments",
      "url": "https://d-miller.github.io/assets/Williams2022.pdf",
      "processed_at": "2026-01-08T13:29:36.829030",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis synthesized 191 randomized controlled trials of U.S. PreK-12 mathematics interventions conducted between 1991 and 2017, representing over 250,000 students. The study design was a systematic review and meta-analysis using the MUTOS framework to examine heterogeneity in intervention effects. The average effect size on student mathematics achievement was 0.31 standard deviations, with wide heterogeneity ranging from -0.60 to 1.23. Key moderators included outcome measure type (researcher-created measures yielded larger effects than standardized measures) and intervention delivery mechanism (teacher and interventionist delivery produced larger effects than technology delivery). The probability that a random mathematics intervention has a positive impact was estimated at 75%.",
        "measure": "Standardized mean difference effect sizes on mathematics achievement measures",
        "study_size": 250000,
        "effect_size": 0.31,
        "student_racial_makeup": "40% White, 32% Black, 25% Hispanic, 6% Asian",
        "student_socioeconomic_makeup": "57% economically disadvantaged (as indicated by free or reduced-price lunch status)",
        "student_gender_makeup": "52% male",
        "student_age_distribution": "PreK-12, with 72% elementary school, 23% middle school, 8% high school, 8% prekindergarten",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "57% economically disadvantaged",
        "special_education_services": "yes",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 4
      },
      "error": null
    },
    {
      "index": 141,
      "paper_id": "paper_4518",
      "finding_id": "finding_4518",
      "title": "Effect sizes \u2013 Robert Slavin's Blog",
      "url": "https://robertslavinsblog.wordpress.com/tag/effect-sizes/",
      "processed_at": "2026-01-08T13:29:56.805176",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This blog post series by Robert Slavin discusses methodological issues in meta-analyses of educational interventions, particularly intelligent tutoring systems. The author critiques a meta-analysis by Kulik & Fletcher (2016) that reported an effect size of +0.66 for intelligent tutoring, demonstrating how excluding studies with small samples, brief durations, and researcher-made measures reduces the effect size to +0.09 (non-significant). The posts emphasize that methodological inclusion standards dramatically affect reported effect sizes, with researcher/developer-made measures producing effect sizes two to three times larger than independent measures. The author advocates for selective standards in meta-analyses to produce more valid and practically meaningful findings for educators.",
        "measure": "Achievement test scores (standardized vs. researcher-made measures)",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 142,
      "paper_id": "paper_52019",
      "finding_id": "finding_52019",
      "title": "Comparative Analysis of Digital Tools and Traditional Teaching Methods in Educational Effectiveness",
      "url": "https://arxiv.org/pdf/2408.06689",
      "processed_at": "2026-01-08T13:30:10.659121",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study compared digital learning tools (Khan Academy) versus traditional paper-based worksheets for teaching elementary probability to 30 students in grades 3-5 at Clarksburg Elementary School. Students were randomly assigned to either a Digital Learning Group (DLG) or Traditional Methods Group (TMG) and completed pre- and post-assessments after a 30-minute learning session. The DLG showed a 24.2% improvement in test scores (from 70% to 87%), while the TMG improved by only 8.3% (from 72% to 78%). Statistical analysis using paired t-tests confirmed significant improvements in both groups (p<.01), with an independent t-test showing the DLG's improvement was significantly greater than the TMG's (p<.01), supporting the hypothesis that digital tools are more effective for improving mathematical skills.",
        "measure": "Pre-test and post-test scores on elementary probability assessments",
        "study_size": 30,
        "effect_size": "not_reported",
        "student_racial_makeup": "diverse set of races including white, hispanic, black and asian ethnic groups",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "boys and girls",
        "student_age_distribution": "grades 3, 4 and 5",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "suburban",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 143,
      "paper_id": "paper_54654",
      "finding_id": "finding_54654",
      "title": "How Different Teaching Modes affect Different Student Demographics across a University \u2013 A Case Study",
      "url": "https://www.kennesaw.edu/coles/research/docs/fall-2021/fall-21-02.pdf",
      "processed_at": "2026-01-08T13:30:25.371448",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined five years of undergraduate course data (2015-2019) from Kennesaw State University to compare student outcomes across face-to-face, hybrid, and online teaching modes. Using a quasi-experimental design with 939,917 student-course records, the researchers analyzed final course grades while controlling for previous GPA and demographic factors. Results showed that students in hybrid course sections earned significantly higher final grades than those in online or face-to-face sections across all demographic groups. The study also found that the advantage of hybrid mode varied by demographic characteristics, with Black students showing the largest benefit from hybrid instruction compared to other modes.",
        "measure": "Final course grade (converted to numeric scale: A=4, B=3, C=2, D=1, F=0)",
        "study_size": 939917,
        "effect_size": "not_reported",
        "student_racial_makeup": "55.83% White, 20.54% Black, 9.9% Hispanic, 5.26% Asian, 4.52% Multiethnic, 1.99% Alien, 0.11% Other",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "52.4% Male, 47.6% Female",
        "student_age_distribution": "Mean age 22.1 years, range 18-75",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 144,
      "paper_id": "paper_72571",
      "finding_id": "finding_72571",
      "title": "Identifying Differences in Learning Strategies by Demographics and Course Grade in a Community College Context",
      "url": "https://www.nsta.org/journal-college-science-teaching/journal-college-science-teaching-septemberoctober-2020/identifying?srsltid=AfmBOopmi1TkxPLPQgsc5xEXQzeVjDGPHOoNQ2BIMJgyoreOg7CiY4DN",
      "processed_at": "2026-01-08T13:30:43.077995",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This study examined metacognitive learning strategies among community college biology students enrolled in Anatomy & Physiology 1 at a Hispanic Serving Institution. Using a survey administered to 38 students, researchers investigated whether learning strategy use differed by race, age, gender, and final course grade. The quasi-experimental design employed Fisher's exact tests to analyze closed-ended survey responses about nine learning strategies. Results showed minimal significant differences across demographic groups, with only small gender effects for study guide creation and large age effects for creating study questions. Notably, learning strategies did not differ significantly between high-achieving and low-achieving students, contradicting previous research linking study skills to academic performance.",
        "measure": "Self-reported learning strategy use via survey responses and final course grades",
        "study_size": 38,
        "effect_size": "not_reported",
        "student_racial_makeup": "59% White, 23% Hispanic or Latino, 8% Black or African American, 5% Asian, 5% prefer not to answer",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "81% female, 19% male",
        "student_age_distribution": "62% age 22 or younger, categorized as 18-19 years, 20-22 years, and over 22 years",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "community_college",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 145,
      "paper_id": "paper_73684",
      "finding_id": "finding_73684",
      "title": "Innovating High School Math Through K\u201312 and Higher Education Partnerships",
      "url": "https://files.eric.ed.gov/fulltext/ED628238.pdf",
      "processed_at": "2026-01-08T13:31:01.642301",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This mixed-methods study examined six intersegmental partnerships between university faculty and high school math specialists that developed advanced innovative math (AIM) courses as alternatives to traditional 12th-grade math courses in California. The study combined qualitative research (interviews with project directors and 20 teachers from 20 high schools) with quantitative analysis of course-taking data linked to postsecondary enrollment data using matching estimation methods. The intervention targeted high school seniors who might not otherwise enroll in math during their senior year, with enrollment representative of racial/ethnic and socioeconomic diversity in participating districts. Quantitative analysis indicated that enrollment in an AIM course increases the likelihood of completing CSU/UC eligibility requirements by 3-10 percentage points, improves high school math grades in some cases, and increases the likelihood of attending college.",
        "measure": "CSU/UC eligibility completion, high school math GPA, college enrollment",
        "study_size": 9009,
        "effect_size": "not_reported",
        "student_racial_makeup": "Representative of district diversity; Latinx students slightly overrepresented in AIM courses compared to cohort; includes Asian American/Pacific Islander, Black, Latinx, White, and Multi/Other students",
        "student_socioeconomic_makeup": "Socioeconomically disadvantaged (SED) enrollment aligned with cohort percentages, ranging from 43-86% SED across different courses",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "12th grade students (seniors)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "43-86% socioeconomically disadvantaged across courses",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 146,
      "paper_id": "paper_66372",
      "finding_id": "finding_66372",
      "title": "Teaching for conceptual understanding: A cross-national comparison of the relationship between teachers' instructional practices and student achievement in mathematics",
      "url": "https://largescaleassessmentsineducation.springeropen.com/articles/10.1186/s40536-014-0011-6",
      "processed_at": "2026-01-08T13:31:20.731152",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined the relationship between eighth-grade mathematics teachers' instructional practices supporting conceptual understanding and student achievement using TIMSS 2007 data from the U.S., Korea, Japan, and Singapore. The study employed multilevel regression models with data from 217-160 schools and 2,270-4,102 students per country. In the U.S. and Singapore, specific instructional practices (writing equations to represent relationships, working on problems with no obvious solution) were positively associated with mathematics achievement, with standardized effects of 0.32-0.37. However, in Korea and Japan, none of the six teaching practices examined showed significant relationships with achievement. Despite statistically significant relationships in the U.S. and Singapore, these practices explained very little additional variance (0.2-1.6 percentage points) in student test scores.",
        "measure": "TIMSS 2007 mathematics achievement scores (total mathematics score based on IRT scaling with five plausible values)",
        "study_size": 12346,
        "effect_size": 0.33,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Home background composite created from educational resources, books in home, and parents' education; school-level SES aggregated from student data",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "8th grade students (approximately ages 13-14)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 147,
      "paper_id": "paper_55163",
      "finding_id": "finding_55163",
      "title": "Automated Feedback vs. Human Feedback: A Study on AI-Driven Language Assessment",
      "url": "https://journals.kmanpub.com/index.php/aitechbesosci/article/view/3813",
      "processed_at": "2026-01-08T13:31:38.640655",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study conducted a 12-week randomized controlled experiment comparing AI-driven automated feedback with traditional human instructor feedback among 80 EFL (English as a Foreign Language) learners at a university in Iran. Participants were divided into two groups, with language proficiency improvements assessed across grammar, vocabulary, and pronunciation domains. Both feedback methods significantly enhanced language skills overall. However, human feedback proved superior in fostering gains in pronunciation and contextual understanding, while AI-driven feedback excelled in detecting and correcting grammatical errors, suggesting a hybrid model combining both approaches would be most effective.",
        "measure": "Language proficiency assessments in grammar, vocabulary, and pronunciation",
        "study_size": 80,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 148,
      "paper_id": "paper_5501",
      "finding_id": "finding_5501",
      "title": "Meta-analysis of mobile applications and their impact on student outcomes: Enhancing interest and intellectual abilities in physics learning",
      "url": "https://www.ejmste.com/download/meta-analysis-of-mobile-applications-and-their-impact-on-student-outcomes-enhancing-interest-and-16653.pdf",
      "processed_at": "2026-01-08T13:31:52.718530",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the impact of mobile applications on students' affective outcomes in physics learning, specifically evaluating their contribution to the development of interest and cognitive abilities. The study synthesized 44 experimental studies from Web of Science and Scopus databases, encompassing 11,683 participants across high school and university levels. Using a random effects model, the overall effect size was found to be large (g = 1.72), indicating that mobile applications are highly effective in enhancing student interest and intellectual abilities in physics education. Moderator analyses revealed significant differences based on education level, publication year, mobile learning technique, intellectual outcome type, research type, database, and cultural context, with all hypotheses confirmed.",
        "measure": "Interest and intellectual abilities in physics learning (including creative thinking, reflective thinking, critical thinking, problem-solving, learning gains, learning independence)",
        "study_size": 11683,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "High school and university students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 149,
      "paper_id": "paper_95937",
      "finding_id": "finding_95937",
      "title": "A meta-analysis of the impact of technology related factors on students' academic performance",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1524645/full",
      "processed_at": "2026-01-08T13:32:09.817114",
      "status": "success",
      "extracted_fields": {
        "direction": "Negative",
        "results_summary": "This meta-analysis examined the relationship between smartphone addiction, social media use, video game playing, and academic performance across 63 studies with 124,166 students from 28 countries spanning primary, secondary, and tertiary education levels. Using a random effects model, the study found a small but statistically significant negative association between these technology-related factors and academic performance (d = -0.085). Smartphone addiction showed a negative effect (d = -0.129), video games showed a negative effect (d = -0.134), while social media use showed a non-significant positive effect (d = 0.025). The findings suggest that excessive engagement with smartphones and video games can detract from academic success, though the overall effect size is small.",
        "measure": "Academic performance measured via GPA, standardized test scores, or self-reported grades",
        "study_size": 124166,
        "effect_size": 0.085,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 7-27",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 150,
      "paper_id": "paper_62300",
      "finding_id": "finding_62300",
      "title": "A Comparison of Automated Corrective Feedback and Traditional Corrective Feedback: A Review Study",
      "url": "https://wap.hillpublisher.com/ArticleDetails.aspx?cid=2261",
      "processed_at": "2026-01-08T13:32:24.435547",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This review study compared automated corrective feedback (ACF) using AI systems with traditional corrective feedback (teacher, peer, and self-feedback) for language learners. The review examined four aspects: response time, potential risks, interpersonal interaction, and personalized learning. The study found that ACF offers benefits including instant response time, minimal emotional damage, and individualized feedback, while traditional CF provides advantages in real-time interpersonal interaction and privacy protection. The authors recommend combining both feedback modes to enhance effectiveness and efficiency of language learning, suggesting neither approach is universally superior.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 151,
      "paper_id": "paper_7796",
      "finding_id": "finding_7796",
      "title": "An adaptive feedback system for the improvement of learners",
      "url": "https://www.nature.com/articles/s41598-025-01429-w",
      "processed_at": "2026-01-08T13:32:38.014025",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study developed an adaptive feedback system for Learning Management Systems using machine learning algorithms including Stacking, Capsule Network, SVM, Random Forest, Decision Tree, and KNN to identify specific instances affecting learner outcomes. The study utilized both simulated data of software engineering students and real datasets from Cyprus including 145 undergraduate students from Engineering and Educational Sciences faculties. Using a quasi-experimental design with multiple algorithm comparisons, the Stacking classifier achieved the highest accuracy of 76.70% while SVM demonstrated the highest precision of 0.78. The study found multilingual education settings as the most influential instance affecting student efficiency, demonstrating positive results for the adaptive feedback approach in identifying learning gaps.",
        "measure": "Classification accuracy, precision, recall, and F1-score for predicting student performance categories",
        "study_size": 145,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "52.4% received 50% scholarship, 0.7% had no scholarship",
        "student_gender_makeup": "60% male, 40% female",
        "student_age_distribution": "48.3% aged 22-25, 44.8% aged 18-21",
        "school_type": "postsecondary",
        "public_private_status": "mixed",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "52.4% received 50% scholarship",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Middle East & North Africa",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 152,
      "paper_id": "paper_21607",
      "finding_id": "finding_21607",
      "title": "Investigating the effect of automated feedback on learning behavior in MOOCs for programming",
      "url": "https://educationaldatamining.org/edm2022/proceedings/2022.EDM-short-papers.35/2022.EDM-short-papers.35.pdf",
      "processed_at": "2026-01-08T13:32:54.491142",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study investigated the effect of an automated testing and feedback (ATF) system on learning behavior in a Python programming MOOC with 4,652 active learners. Learners were randomly assigned to an experimental group with ATF access or a control group without. The study measured engagement, persistence, and performance using course log data and cluster analysis. Results showed that ATF users demonstrated significantly higher engagement (more videos watched, more exercises solved), greater persistence (more units completed), and better performance (higher grades) compared to non-users, with small-to-medium effect sizes. However, no significant differences were found between groups on subjective measures of sense of learning and intention fulfillment.",
        "measure": "Learning behavior measures including number of videos watched, units touched, exercises solved, mean attempts, maximum unit reached, and grades on closed exercises",
        "study_size": 4652,
        "effect_size": 0.32,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "73.5% male, 25.9% female, 0.6% unidentified",
        "student_age_distribution": "ages ranged from less than 11 to over 75, with majority (79.3%) in the 12-34 age range",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 153,
      "paper_id": "paper_9485",
      "finding_id": "finding_9485",
      "title": "AI-POWERED EDUCATIONAL TOOLS AND THEIR EFFECT ON STUDENT MOTIVATION IN ONLINE LEARNING ENVIRONMENTS: A PRELIMINARY STUDY",
      "url": "https://scholarworks.umt.edu/cgi/viewcontent.cgi?article=13506&context=etd",
      "processed_at": "2026-01-08T13:33:11.133139",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 154,
      "paper_id": "paper_93382",
      "finding_id": "finding_93382",
      "title": "AI-based feedback tools in education: A comprehensive bibliometric analysis study",
      "url": "https://files.eric.ed.gov/fulltext/EJ1454425.pdf",
      "processed_at": "2026-01-08T13:33:22.182149",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This bibliometric analysis examined 239 articles from the Web of Science database spanning 2007 to February 2024 to map the research landscape of AI-based feedback tools in education. The study population consisted of scholarly publications rather than direct student participants, with analysis revealing an annual growth rate of 21.65% in publications. Key findings indicate increasing scholarly attention toward AI-driven feedback mechanisms, with China and the United States as leading contributors. The analysis identified prominent themes including intelligent tutoring systems, automated writing evaluation, and personalized learning, with the overall direction suggesting positive momentum and growing recognition of AI-based feedback tools' potential to enhance educational outcomes.",
        "measure": "Publication counts, citation rates, keyword co-occurrence, and co-citation patterns",
        "study_size": 239,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 155,
      "paper_id": "paper_89906",
      "finding_id": "finding_89906",
      "title": "A qualitative systematic review on AI empowered self-regulated learning in higher education",
      "url": "https://www.nature.com/articles/s41539-025-00319-0",
      "processed_at": "2026-01-08T13:33:40.114662",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic review examined 14 empirical studies on AI applications supporting self-regulated learning (SRL) in higher education settings. The review employed PRISMA guidelines to synthesize research on chatbots, adaptive feedback systems, serious games, and e-textbooks used to enhance student autonomy. Findings revealed that AI tools demonstrated potential in facilitating SRL's forethought, performance, and reflection phases, with most applications predominantly supporting the performance phase through help-seeking, learning monitoring, and instructional strategies. While positive outcomes included enhanced motivation, self-efficacy, and personalized feedback, negative aspects included learner over-reliance on AI, feedback overload, and reduced autonomy, indicating a mixed overall effect on SRL processes.",
        "measure": "Self-regulated learning processes across forethought, performance, and self-reflection phases",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 156,
      "paper_id": "paper_57489",
      "finding_id": "finding_57489",
      "title": "A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour",
      "url": "https://link.springer.com/article/10.1186/s41239-023-00436-z",
      "processed_at": "2026-01-08T13:33:55.566947",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This tertiary review synthesized 66 evidence syntheses on artificial intelligence in higher education (AIHEd), examining the scope and nature of secondary research published between 2018 and July 2023. The review found that most AIHEd research focused on adaptive systems and personalisation (54.5%) and profiling and prediction (48.5%), with systematic reviews being the dominant methodology (66.7%). Key findings indicated benefits including personalised learning, positive influence on learning outcomes, and reduced administrative time for educators, while challenges included lack of ethical consideration, curriculum development issues, and infrastructure problems. The review identified significant research gaps requiring greater ethical, methodological, and contextual considerations, with 40.9% of reviews calling for enhanced ethical focus and 36.4% emphasizing the need for more rigorous empirical research.",
        "measure": "Quality assessment scores using DARE and AMSTAR 2 tools, thematic coding of AI applications, and synthesis of benefits, challenges, and research gaps",
        "study_size": 66,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Global",
        "system_impact_levels": 2,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 157,
      "paper_id": "paper_39571",
      "finding_id": "finding_39571",
      "title": "The Impact of AI Tools on English Writing Skills Development",
      "url": "https://www.allsocialsciencejournal.com/uploads/archives/20250426185823_SER-2025-2-040.1.pdf",
      "processed_at": "2026-01-08T13:34:12.903835",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined the impact of AI writing tools (ChatGPT, Grammarly, QuillBot) on English writing skills among 160 Vietnamese university students using a pretest/posttest design over two months. The research employed multiple regression analysis to evaluate five independent variables: type of AI tool, level of interaction with AI, instruction method, initial English proficiency, and duration of AI use. Results showed all five variables significantly contributed to writing skills development, collectively explaining 58.1% of variance in writing performance. Duration of AI use emerged as the strongest predictor (\u03b2 = 0.331), followed by instruction method (\u03b2 = 0.243), indicating that sustained engagement with AI tools combined with structured pedagogical approaches yields the greatest improvements in writing skills.",
        "measure": "Comprehensive writing rubric evaluating grammatical accuracy, vocabulary richness, coherence, idea development, and overall effectiveness",
        "study_size": 160,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "65% female, 35% male",
        "student_age_distribution": "ages 19-22",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Southeast Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 158,
      "paper_id": "paper_95045",
      "finding_id": "finding_95045",
      "title": "AI-Driven Tools in Providing Feedback on Students' Writing",
      "url": "https://rsisinternational.org/journals/ijriss/articles/ai-driven-tools-in-providing-feedback-on-students-writing/",
      "processed_at": "2026-01-08T13:34:27.650533",
      "status": "skipped",
      "extracted_fields": {},
      "error": "insufficient content"
    },
    {
      "index": 159,
      "paper_id": "paper_16436",
      "finding_id": "finding_16436",
      "title": "The impact of AI-driven tools on student writing development: A case study",
      "url": "https://www.ojcmt.net/article/the-impact-of-ai-driven-tools-on-student-writing-development-a-case-study-16738",
      "processed_at": "2026-01-08T13:34:29.227121",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This case study examined the impact of CGScholar AI Helper, an AI-driven writing feedback tool, on 11th-grade students' writing development in English Language Arts. The intervention involved one teacher and six students in a diverse school setting. Using a qualitative thematic approach, researchers analyzed students' initial and revised writing assignments, focus group feedback, teacher post-surveys, and research team observations. The findings suggest that the AI helper supported students' writing development in several ways when calibrated to align with the teacher's instructional objectives. The study concludes that AI can be beneficial for K-12 writing instruction, though recommendations for tool improvement were also identified.",
        "measure": "Qualitative analysis of writing assignments, focus group feedback, teacher surveys, and observations",
        "study_size": 6,
        "effect_size": "not_reported",
        "student_racial_makeup": "diverse school",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "11th grade",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 160,
      "paper_id": "paper_72437",
      "finding_id": "finding_72437",
      "title": "AI-Powered Writing Assistants in Second Language Education: A Systematic Review",
      "url": "https://ideas.repec.org/a/bcp/journl/v9y2025i10p10239-10249.html",
      "processed_at": "2026-01-08T13:34:39.876257",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic literature review examined ESL teachers' perceptions of AI-powered writing assistants such as Grammarly, QuillBot, and ChatGPT. The study analyzed fifteen studies published between 2020-2025 sourced from ERIC and Google Scholar databases. Benefits identified included improved writing accuracy, vocabulary enhancement, and increased student engagement. However, concerns were raised about over-reliance on AI tools, potential negative impacts on critical thinking skills, data privacy issues, and inadequate teacher training for effective integration.",
        "measure": "Teacher perceptions of AI writing assistants",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 161,
      "paper_id": "paper_6710",
      "finding_id": "finding_6710",
      "title": "Automated feedback and writing: a multi-level meta-analysis of effects on students' performance",
      "url": "https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2023.1162454/full",
      "processed_at": "2026-01-08T13:34:48.885985",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the effectiveness of automated writing evaluation (AWE) feedback tools on students' writing performance across 20 primary studies with 84 effect sizes and 2,828 participants. The study employed a three-level random effects model to account for dependent effect sizes within studies. Results showed a medium positive effect (g = 0.55) of automated feedback on writing performance, with significant heterogeneity in the data. Moderator analyses examined sample characteristics (educational level, language status), intervention characteristics (treatment duration, control condition type), and outcome characteristics (time of measurement, outcome type, outcome level), though none of the subgroup comparisons reached statistical significance despite substantial differences in effect sizes.",
        "measure": "Writing performance (holistic and analytic measures including grammar, mechanics, content, and overall text quality)",
        "study_size": 2828,
        "effect_size": 0.55,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 162,
      "paper_id": "paper_6710",
      "finding_id": "finding_24768",
      "title": "Automated feedback and writing: a multi-level meta-analysis of effects on students' performance",
      "url": "https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2023.1162454/full",
      "processed_at": "2026-01-08T13:35:04.071501",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the effectiveness of automated writing evaluation (AWE) feedback tools on students' writing performance across 20 primary studies with 84 effect sizes and 2,828 participants. The study employed a three-level random effects model to account for dependent effect sizes within studies. Results showed a medium positive effect (g = 0.55) of automated feedback on writing performance, with significant heterogeneity in the data. Moderator analyses examined sample characteristics (educational level, language status), intervention characteristics (treatment duration, control condition type), and outcome characteristics (time of measurement, outcome type, outcome level), though none of the subgroup comparisons reached statistical significance. The findings support the use of AWE feedback for facilitating students' writing development, though the heterogeneity suggests automated feedback should not be viewed as a one-size-fits-all solution.",
        "measure": "Writing performance (holistic and analytic measures including grammar, mechanics, content, and overall text quality)",
        "study_size": 2828,
        "effect_size": 0.55,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Secondary and tertiary level students (high school and higher education)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 163,
      "paper_id": "paper_13477",
      "finding_id": "finding_13477",
      "title": "Meta-Analysis of Using AI-Based Feedback Systems in Developing College Students' Academic Writing Skills",
      "url": "https://link.springer.com/chapter/10.1007/978-981-96-2532-1_20",
      "processed_at": "2026-01-08T13:35:19.444831",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This meta-analysis synthesized 35 studies published between 2015-2023 examining AI-based feedback systems (such as Turnitin, Grammarly, and Pigai) for developing college students' academic writing skills. The study population consisted of undergraduate students across multiple international contexts. Using Cooper's (1998) meta-analysis guidelines, the review identified significant benefits including improved writing accuracy (grammar, vocabulary, coherence), increased student engagement and motivation, and enhanced self-regulation and metacognitive skills. However, challenges were also documented including generic feedback that ignores individual differences, inability to assess higher-order thinking skills like critical thinking and argumentation, potential for student over-reliance on automated systems, and failure to address contextual and cultural writing issues. The overall finding direction is mixed, with substantial positive effects on mechanical writing skills but notable limitations for complex writing competencies.",
        "measure": "Writing quality, writing accuracy (grammar, vocabulary, coherence), student engagement, self-regulation, metacognitive skills",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 164,
      "paper_id": "paper_13477",
      "finding_id": "finding_47604",
      "title": "Meta-Analysis of Using AI-Based Feedback Systems in Developing College Students' Academic Writing Skills",
      "url": "https://link.springer.com/chapter/10.1007/978-981-96-2532-1_20",
      "processed_at": "2026-01-08T13:35:34.748289",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This meta-analysis synthesized 35 studies published between 2015-2023 examining AI-based feedback systems (such as Turnitin, Grammarly, and Pigai) for developing college students' academic writing skills. The study population consisted of undergraduate students across multiple international contexts. Using Cooper's (1998) meta-analysis guidelines, the review identified significant benefits including improved writing accuracy (grammar, vocabulary, coherence), increased student engagement and motivation, and enhanced self-regulation and metacognitive skills. However, challenges were also documented including generic feedback that ignores individual differences, inability to assess higher-order thinking skills like critical thinking and argumentation, potential for student over-reliance on automated systems, and failure to address contextual and cultural writing issues. The overall finding direction is mixed, with substantial positive effects on mechanical writing skills but notable limitations for complex writing competencies.",
        "measure": "Writing quality, writing accuracy (grammar, vocabulary, coherence), student engagement, self-regulation, metacognitive skills",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 165,
      "paper_id": "paper_44086",
      "finding_id": "finding_44086",
      "title": "STEM education's impact on student learning outcomes: A meta-analysis",
      "url": "https://pubmed.ncbi.nlm.nih.gov/40880820/",
      "processed_at": "2026-01-08T13:35:50.846645",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis systematically reviewed 66 experimental and quasi-experimental studies on STEM education published between 2000-2024 to examine effects on student learning outcomes. The study population spanned multiple academic levels, with the strongest effects observed at the high school level. Using meta-analytic methods, researchers found that STEM education had the most significant impact on cognitive outcomes in high school students (d = 0.58) with reduced heterogeneity (I\u00b2 = 62.1%). Overall, STEM education demonstrated a moderate positive effect on learning outcomes, though this aggregate effect size masked important differences across outcome types and academic levels. The effects were moderated by sample size, academic level, subjects, experimental period, and teaching method.",
        "measure": "Cognitive learning outcomes across multiple STEM subjects",
        "study_size": 66,
        "effect_size": 0.58,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 166,
      "paper_id": "paper_44580",
      "finding_id": "finding_44580",
      "title": "Systematic review and meta-analysis of the impact of STEM education on students learning outcomes",
      "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1579474/full",
      "processed_at": "2026-01-08T13:35:59.427984",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis systematically analyzed 66 experimental and quasi-experimental studies on STEM education published from 2000-2024 to examine effects on student learning outcomes. The study population included students across primary school, high school, and university levels from multiple countries. Using a random effects model, the analysis found an overall moderate positive effect size (d = 0.46) of STEM education on learning outcomes. Subgroup analysis revealed that STEM education had the most significant impact on cognitive outcomes in high school students (d = 0.58), with reduced heterogeneity (I\u00b2 = 62.1%). The findings indicate that STEM education positively influences cognitive ability, non-cognitive ability, and skill performance, though effects vary by academic level and outcome type.",
        "measure": "Learning outcomes including cognitive ability (academic performance, knowledge retention), non-cognitive ability (self-efficacy, learning interest), and skill performance (problem-solving, creativity)",
        "study_size": 66,
        "effect_size": 0.46,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Primary school, high school, and university students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 167,
      "paper_id": "paper_36560",
      "finding_id": "finding_36560",
      "title": "The Impact of AI-Powered Learning Tools on STEM Education Outcomes: A Policy Perspective",
      "url": "https://www.allmultidisciplinaryjournal.com/uploads/archives/20250308171120_MGE-2025-2-031.1.pdf",
      "processed_at": "2026-01-08T13:36:15.521127",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This policy-focused review paper examines the impact of AI-powered learning tools on STEM education outcomes by synthesizing existing literature and theoretical frameworks. The paper draws on multiple studies including meta-analyses from ISTE and research on adaptive learning platforms to argue that AI tools can significantly improve student engagement, understanding of complex concepts, and academic performance in STEM subjects. The review highlights that students using adaptive learning systems and intelligent tutoring systems outperform peers in traditional learning environments, with personalized feedback and tailored learning experiences contributing to deeper comprehension. However, the paper also identifies significant challenges including accessibility issues related to the digital divide, potential algorithmic biases, and inadequate teacher training that must be addressed for effective implementation.",
        "measure": "Academic performance, student engagement, learning outcomes in STEM subjects",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 168,
      "paper_id": "paper_61984",
      "finding_id": "finding_61984",
      "title": "Enhancing Student Engagement through AI-Driven Adaptive Learning and Gamification",
      "url": "https://eajournals.org/bje/wp-content/uploads/sites/5/2025/12/Enhancing-Student-Engagement.pdf",
      "processed_at": "2026-01-08T13:36:30.510711",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study designed and evaluated an AI-driven adaptive learning system combining a Python Flask backend with an Unreal Engine 5.4 frontend for delivering gamified quizzes with real-time difficulty adjustment. The prototype used a rule-based threshold algorithm to personalize question difficulty based on learner performance, with content sourced from the OpenTDB API. Testing involved functional validation, simulated user profiles, and informal user testing rather than a formal experimental study with a control group. Results indicated the system successfully matched question difficulty to user proficiency, achieved an average API response time of 190ms, and showed a 15% improvement in simulated accuracy from session start to end, with users demonstrating increased engagement compared to static quiz systems.",
        "measure": "API response time, simulated accuracy improvement, difficulty transition frequency, time-on-task",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 169,
      "paper_id": "paper_55457",
      "finding_id": "finding_55457",
      "title": "Bridging Educational Equity Gaps: A Systematic Review of AI-Driven and New Technologies for Students Living with Disabilities in STEM Education",
      "url": "https://peer.asee.org/bridging-educational-equity-gaps-a-systematic-review-of-ai-driven-and-new-technologies-for-students-living-with-disabilities-in-stem-education.pdf",
      "processed_at": "2026-01-08T13:36:48.266116",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic literature review examined 13 articles on AI-driven and new technologies for students living with disabilities (SLWD) in STEM education. The review identified six categories of technologies including AI/ML, game-based learning, intelligent tutoring systems, NLP, VR/AR, and robotics. Benefits included enhanced engagement, accessibility, personalized learning, progress tracking, skill development, and increased confidence. However, significant limitations were found including accessibility and technological constraints, customization issues, practical barriers such as high costs and setup complexity, and concerns about educational effectiveness. The findings indicate mixed results with both promising benefits and substantial challenges requiring further development.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 170,
      "paper_id": "paper_88636",
      "finding_id": "finding_88636",
      "title": "AI-based Adaptive Programming Education for Socially Disadvantaged Students: Bridging the Digital Divide",
      "url": "https://link.springer.com/article/10.1007/s11528-025-01088-8",
      "processed_at": "2026-01-08T13:37:05.135949",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the impact of AI-based adaptive programming education on 122 socially disadvantaged undergraduate students in Hungary over 13 weeks. Students were divided into an experimental group receiving AI-driven adaptive instruction via ChatGPT and a control group receiving traditional non-adaptive curriculum. The experimental group demonstrated significantly higher post-test programming knowledge scores (M=7.1 vs M=6.0) with a large effect size (Cohen's d=1.40) and significantly higher engagement across behavioral, emotional, and cognitive dimensions. ANCOVA controlling for socioeconomic background confirmed that the AI system had positive effects regardless of students' socioeconomic status, suggesting AI-based adaptive learning can help bridge educational gaps for disadvantaged students.",
        "measure": "Pre-test and post-test programming knowledge assessments and self-report engagement questionnaires measuring behavioral, emotional, and cognitive engagement",
        "study_size": 122,
        "effect_size": 0.88,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "All participants were socially disadvantaged students with Social Condition Index (SCI) below 3.00, representing 42.21% of initial 289 respondents",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "ages 18-21, M=18.67, SD=0.93",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "low",
        "ses_numeric": "42.21% of respondents classified as socially disadvantaged (SCI < 3.00)",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 171,
      "paper_id": "paper_303",
      "finding_id": "finding_303",
      "title": "Examining Access and Inclusion in STEM Fields in Higher Education: Digital Learning Environments, Personalized Learning, and Institutional Change to Advance Educational Opportunity",
      "url": "https://www.intechopen.com/chapters/1209836",
      "processed_at": "2026-01-08T13:37:21.901463",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This chapter synthesizes existing research and autoethnographic reflections to examine how digital educational tools such as serious games and virtual laboratories can enhance STEM access and inclusion for marginalized and neurodivergent students in higher education. The population of focus includes undergraduate students, particularly those from racially minoritized backgrounds and those with neurodivergent identities such as ADHD and autism. The study design is qualitative, drawing on literature synthesis and personal narrative rather than experimental methods. Key outcomes examined include student engagement, cognitive load reduction, and the effectiveness of Universal Design for Learning principles in creating judgment-free digital learning environments. The findings are mixed, indicating that while digital tools show promise for personalized learning and reducing role strain, their effectiveness depends heavily on thoughtful design, institutional support, and alignment with diverse learner needs.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Focus on African American/Black, Latin\u00e9, Indigenous, and other racially minoritized groups in STEM",
        "student_socioeconomic_makeup": "Includes first-generation and socioeconomically disadvantaged students",
        "student_gender_makeup": "Includes women in STEM, particularly women of color",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 172,
      "paper_id": "paper_57109",
      "finding_id": "finding_57109",
      "title": "Do intelligent tutoring systems benefit K-12 students? A meta-analysis and evaluation of heterogeneity of treatment effects in the U.S.",
      "url": "https://arxiv.org/pdf/2511.04997",
      "processed_at": "2026-01-08T13:37:37.628973",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis evaluated the effects of intelligent tutoring systems (ITS) on K-12 student achievement in U.S. schools, including 18 experimental studies with 77 effect sizes across 11 different ITS platforms. The study population included elementary, middle, and high school students across urban, suburban, and rural settings. Using a multivariate multilevel meta-regression model with robust variance estimation, the analysis found a statistically significant positive overall effect size (g=0.271, SE=0.011, p=0.001) of ITS on student learning outcomes. Key moderators of treatment effects included provision of worked-out examples, intervention duration (with shorter interventions showing larger effects), intervention condition, type of learning outcome, and immediate measurement timing. Effect sizes were notably lower in studies including rural schools (g=0.146) compared to urban (g=0.298) and suburban (g=0.260) settings.",
        "measure": "Standardized tests and researcher-developed tests measuring mathematics and reading/writing achievement",
        "study_size": 77,
        "effect_size": 0.271,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Studies included targeting of students in poverty, English language learners, and low achievers, but specific percentages not consistently reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary (PreK-5th), Middle School (6th-8th), and some High School (9th-12th) students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 173,
      "paper_id": "paper_49218",
      "finding_id": "finding_49218",
      "title": "A Systematic Review of Self-Regulated Learning through Integration of Multimodal Data and Artificial Intelligence",
      "url": "https://link.springer.com/article/10.1007/s10648-025-10028-0",
      "processed_at": "2026-01-08T13:37:55.342744",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic review examined 142 empirical studies on self-regulated learning (SRL) to identify how multimodal data streams and analytical methods have been used to measure cognitive, affective, metacognitive, and motivational (CAMM) processes. The review found a shift from unimodal approaches (one data stream, one process) toward more integrated multimodal approaches, with log data being the most common data source. Metacognition and cognition were the most studied CAMM processes, while motivation received less attention. Despite increased multimodal data collection, standard statistics remained the dominant analytical method even in integrated approaches, suggesting a gap between data collection sophistication and analytical methods. The findings highlight the need for more advanced AI-based analytics to capture the temporal and dynamic nature of SRL processes.",
        "measure": "Systematic coding of data streams, CAMM processes, analytical methods, and study characteristics across 142 included studies",
        "study_size": 142,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 174,
      "paper_id": "paper_85325",
      "finding_id": "finding_85325",
      "title": "Using Prompts to Scaffold Metacognition in Case-Based Problem Solving within the Domain of Attribution Theory",
      "url": "https://www.ejpbl.org/journal/view.php?doi=10.24313/jpbl.2020.00206",
      "processed_at": "2026-01-08T13:38:10.986181",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study investigated whether metacognitive prompting in a hypermedia case-based learning environment on attribution theory improved knowledge acquisition among 40 participants (27 university students, 13 non-academic) randomly assigned to prompting or non-prompting conditions. The study employed a one-factorial pre-/post-test experimental design with knowledge tests, learning strategy questionnaires, and cognitive load measures. Results showed no significant main effect for prompting on knowledge acquisition, and no significant interaction between prior knowledge and prompting. However, learners with low prior knowledge showed significant benefits from prompting in non-parametric analysis, and regression analysis revealed that metacognitive prompting enabled learners who already possessed metacognitive abilities to activate these skills during problem-solving, resulting in higher knowledge post-test scores compared to learners with low metacognitive abilities without prompting.",
        "measure": "Knowledge test (16 items) assessing attribution theory content, LIST questionnaire for learning strategies, NASA-TLX for cognitive load",
        "study_size": 40,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "75% female, 25% male",
        "student_age_distribution": "mean age 25.90 years (SD = 3.91)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 0,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 175,
      "paper_id": "paper_97546",
      "finding_id": "finding_97546",
      "title": "The effect of using technology in teaching and learning mathematics on student's mathematics performance: The mediation effect of students' mathematics interest",
      "url": "https://www.mathsciteacher.com/download/the-effect-of-using-technology-in-teaching-and-learning-mathematics-on-students-mathematics-14309.pdf",
      "processed_at": "2026-01-08T13:38:31.994761",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study examined the impact of technology use in mathematics teaching and learning on student mathematics performance, mediated by students' mathematics interest, among 216 senior high school students in Kumasi, Ghana. Using a quantitative survey design with structural equation modeling (Amos version 23), the researchers analyzed the relationships between technology use, mathematics interest, and mathematics performance. Results showed that technology use had a positive and significant direct effect on mathematics performance (\u03b2=.151, p<.05) and on mathematics interest (\u03b2=.587, p<.01). Mathematics interest also had a positive and significant effect on mathematics performance (\u03b2=.487, p<.01). The mediation analysis confirmed that students' mathematics interest partially mediates the relationship between technology use and mathematics performance, with the indirect effect being statistically significant.",
        "measure": "Self-reported questionnaire items on technology use, mathematics interest, and mathematics performance measured on 5-point Likert scales",
        "study_size": 216,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "60.2% male, 39.8% female",
        "student_age_distribution": "39.8% ages 12-17, 34.7% ages 18-25, 25.5% above 25 years",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 176,
      "paper_id": "paper_81732",
      "finding_id": "finding_81732",
      "title": "Effects of Technology on Student Learning",
      "url": "https://files.eric.ed.gov/fulltext/EJ1290791.pdf",
      "processed_at": "2026-01-08T13:38:49.158153",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This mixed-methods study surveyed K-12 educators in a central Illinois school district to examine their perceptions of technology's effects on student learning. The survey included 29 participants, with 62.07% being elementary teachers. Findings indicated that technology enhances student engagement and motivation, with students showing higher interest and comfort when technology is incorporated into learning. However, teachers also reported negative outcomes including management concerns, student distraction, technology reliability issues, and the need for more training for both teachers and students. Additionally, 79.31% of teachers believed students rely heavily on technology, and 72.41% reported having no designated handwriting block, raising concerns about fine motor skill development.",
        "measure": "Teacher perceptions via Likert scale and open-ended survey questions",
        "study_size": 29,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 177,
      "paper_id": "paper_53356",
      "finding_id": "finding_53356",
      "title": "Empirical reconstruction of mathematics teaching practices in problem-solving lessons: a multi-method case study",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1555763/full",
      "processed_at": "2026-01-08T13:39:02.630970",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This exploratory case study examined the teaching practices of two experienced secondary mathematics teachers in Germany during problem-solving lessons using a sequential multi-method design combining video-based classroom observations, semi-structured interviews, and video-stimulated recalls. The study focused on reconstructing teachers' routinized patterns of action for coping with recurrent requirement situations in problem-solving instruction. Findings validated the theoretical conceptualization that teaching practices are expressions of teachers' professional competence, involving cognitive and affective dispositions, situation-specific skills, and pedagogical tools. The multi-method approach successfully captured self-reported, observable, and articulable elements of teaching practices, demonstrating how experienced teachers adaptively orchestrate problem-solving lessons through practices such as guiding the problem-solving process and instructing retrospective reviews.",
        "measure": "Qualitative analysis of teaching practices through video observations, interviews, and video-stimulated recalls",
        "study_size": 2,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "grades 5 and 9",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 178,
      "paper_id": "paper_95149",
      "finding_id": "finding_95149",
      "title": "Supplementary Private Tutoring and Mathematical Achievements in Higher Education: An Empirical Study on Linear Algebra",
      "url": "https://arxiv.org/abs/2411.03332",
      "processed_at": "2026-01-08T13:39:23.661036",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study investigated the effectiveness of short-term private tutoring (PT) on linear algebra achievement among 60 undergraduate science and engineering students from universities in Zhejiang, Jiangsu, Hubei, and Shandong provinces in China. Students received 24 classes of instruction over 3 days from three mathematics professors with PhDs and over 10 years of teaching experience. Using Item Response Theory (IRT) measurement models with pre-test and post-test assessments, the study found that short-term training significantly enhanced students' mastery of linear algebra knowledge points regardless of test difficulty (Wilcoxon signed rank test Z=-6.139, p=0.001). Multiple linear regression analysis revealed that study time and self-evaluation were significant predictors of improvement, with students able to accurately perceive their mathematical achievement gains.",
        "measure": "Latent trait scores derived from IRT analysis of pre-test and post-test performance on linear algebra problems",
        "study_size": 60,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "38 male, 22 female",
        "student_age_distribution": "Third year undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "East Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 179,
      "paper_id": "paper_72417",
      "finding_id": "finding_72417",
      "title": "AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting",
      "url": "https://etcjournal.com/2025/11/10/review-of-kestin-et-al-s-june-2025-harvard-study-on-ai-tutoring/",
      "processed_at": "2026-01-08T13:39:40.951343",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial compared a custom-designed AI tutor (PS2 Pal) with in-class active learning for 194 undergraduate physics students at Harvard University using a crossover design. Students using the AI tutor achieved median post-test scores of 4.5 compared to 3.5 for active learning classrooms, representing learning gains more than double those of the control group. The effect size ranged from 0.73 to 1.3 standard deviations, with statistical significance at p < 0.00000001. Students also completed the AI-tutored material in less time (median 49 minutes vs 60 minutes) while reporting higher engagement (4.1 vs 3.6) and motivation (3.4 vs 3.1) on five-point scales.",
        "measure": "Post-test scores on physics content (surface tension and fluid flow topics)",
        "study_size": 194,
        "effect_size": 0.73,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "independent",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 180,
      "paper_id": "paper_72417",
      "finding_id": "finding_25072",
      "title": "AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting",
      "url": "https://etcjournal.com/2025/11/10/review-of-kestin-et-al-s-june-2025-harvard-study-on-ai-tutoring/",
      "processed_at": "2026-01-08T13:39:56.610266",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial compared a custom-designed AI tutor (PS2 Pal) with in-class active learning for 194 undergraduate physics students at Harvard University using a crossover design. Students using the AI tutor achieved median post-test scores of 4.5 compared to 3.5 for active learning classrooms, representing learning gains more than double those of the control group. The effect size ranged from 0.73 to 1.3 standard deviations, with statistical significance at p < 0.00000001. Students also completed AI-tutored sessions faster (median 49 minutes vs 60 minutes) while reporting higher engagement (4.1 vs 3.6) and motivation (3.4 vs 3.1) on five-point scales.",
        "measure": "Post-test scores on physics content (surface tension and fluid flow topics)",
        "study_size": 194,
        "effect_size": 0.73,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "independent",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 181,
      "paper_id": "paper_72417",
      "finding_id": "finding_66430",
      "title": "AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting",
      "url": "https://etcjournal.com/2025/11/10/review-of-kestin-et-al-s-june-2025-harvard-study-on-ai-tutoring/",
      "processed_at": "2026-01-08T13:40:12.678224",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial at Harvard University compared a custom-designed AI tutor (PS2 Pal) with in-class active learning for 194 undergraduate physics students using a crossover design. Students using the AI tutor achieved median post-test scores of 4.5 compared to 3.5 for active learning classrooms, representing learning gains more than double those of the control group. The effect size ranged from 0.73 to 1.3 standard deviations, with statistical significance at p < 0.00000001. Students also completed AI-tutored sessions faster (median 49 minutes vs 60 minutes) while reporting higher engagement (4.1 vs 3.6) and motivation (3.4 vs 3.1) on five-point scales.",
        "measure": "Post-test scores on physics content (surface tension and fluid flow topics)",
        "study_size": 194,
        "effect_size": 0.73,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "independent",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 182,
      "paper_id": "paper_86516",
      "finding_id": "finding_86516",
      "title": "AI Tutoring vs. Traditional Tutoring: Key Differences",
      "url": "https://dialzara.com/blog/ai-tutoring-vs-traditional-tutoring-key-differences",
      "processed_at": "2026-01-08T13:40:27.616086",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This blog post compares AI tutoring platforms with traditional human tutoring across multiple dimensions including cost, availability, and learning outcomes. The article synthesizes various claims about AI tutoring effectiveness, citing that AI tutoring costs 85-95% less than human tutors while delivering comparable results. A Harvard study is referenced showing AI tutoring in physics achieved double the learning outcomes at 40% less cost. The article reports that students using AI learn at twice the speed of traditional methods, with 83% of participants rating AI explanations as good as or better than human instruction. However, this is not a primary research study but rather a commercial blog post aggregating various claims without rigorous methodology or systematic review.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 183,
      "paper_id": "paper_21165",
      "finding_id": "finding_21165",
      "title": "Ai Learning vs Traditional Learning 2025",
      "url": "https://autotutor.org/ai-vs-traditional-learning-what-works-better/",
      "processed_at": "2026-01-08T13:40:42.069208",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This blog post is not an empirical research study but rather a comparative opinion piece discussing AI learning versus traditional learning approaches. The article describes features of AI learning tools such as personalization, instant feedback, and 24/7 accessibility, contrasting them with traditional classroom strengths like human connection and collaborative environments. No experimental intervention, control group, or measured outcomes are reported. The piece advocates for a hybrid approach combining both methods but provides no empirical evidence or data to support its claims.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 184,
      "paper_id": "paper_47265",
      "finding_id": "finding_47265",
      "title": "How AI is helping students improve reading and writing",
      "url": "https://publicpolicy.google/article/quillorg-ai-personalized-education-teachers-students/",
      "processed_at": "2026-01-08T13:40:54.488257",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "Quill.org, an AI-powered literacy tool, was implemented across more than 12,000 schools in the United States, serving over 8 million students, with 5 million attending Title I-eligible low-income schools. The intervention provides immediate AI-generated feedback on writing and reading comprehension exercises, allowing students to practice writing more frequently than traditional classroom instruction permits. A quasi-experimental study found that students who used Quill.org once a week for a semester demonstrated a 71% gain in their writing skills, as measured by paragraph revision assessments. The tool also saved teachers approximately 90 hours per year by automating feedback that would otherwise require 3.6 million hours of teacher time annually across all users.",
        "measure": "Paragraph revision skills assessment",
        "study_size": 8000000,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "62.5% low-income (5 million of 8 million students attend Title I-eligible schools)",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "title_i",
        "ses_indicator": "low",
        "ses_numeric": "88% of low-income students not proficient in basic writing; 62.5% of users from Title I schools",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "mixed",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 185,
      "paper_id": "paper_26079",
      "finding_id": "finding_26079",
      "title": "AI-Enhanced Structured Literacy Intervention for Secondary Students: A Case Study of Science of Reading",
      "url": "https://digitalcommons.odu.edu/cgi/viewcontent.cgi?article=1303&context=teachinglearning_fac_pubs",
      "processed_at": "2026-01-08T13:41:08.166885",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This paper presents a case study examining an AI-enhanced structured literacy intervention for secondary students based on the Science of Reading framework. The study focuses on how artificial intelligence tools can support structured literacy instruction for high school students who struggle with reading. The research appears to be qualitative in nature, exploring the implementation and design of AI-supported reading interventions rather than measuring quantitative outcomes. The paper discusses the integration of AI technology with evidence-based literacy practices for older students, though specific empirical findings regarding effectiveness are not clearly reported in the available metadata.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "secondary students (high school level)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 186,
      "paper_id": "paper_76450",
      "finding_id": "finding_76450",
      "title": "Reinforcing L2 reading comprehension through artificial intelligence intervention: refining engagement to foster self-regulated learning",
      "url": "https://link.springer.com/article/10.1186/s40561-025-00377-2",
      "processed_at": "2026-01-08T13:41:32.070912",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This mixed-methods study examined the effectiveness of an AI-based reading platform (ReadToMe) on L2 reading comprehension, engagement, and self-regulated learning among 60 upper-intermediate Iranian EFL female learners. Using a quasi-experimental design with experimental and control groups over 12 weeks, the study employed pre- and post-assessments along with semi-structured interviews. ANCOVA results revealed significant improvements in reading comprehension (F=43.82, p<.001, partial \u03b7\u00b2=0.167), self-regulation (F=19.23, p=.011, partial \u03b7\u00b2=0.151), and engagement (F=24.11, p<.001, partial \u03b7\u00b2=0.171) for the experimental group. Qualitative findings indicated 77% of students reported enhanced engagement and self-regulation through the AI platform, though 23% noted usability challenges.",
        "measure": "Reading comprehension test (24 multiple-choice and 6 open-ended questions), School Engagement Scale, English Self-Regulated Learning Strategies Questionnaire",
        "study_size": 60,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "100% female",
        "student_age_distribution": "mean age 21 (SD=3.12)",
        "school_type": "not_reported",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 187,
      "paper_id": "paper_22102",
      "finding_id": "finding_22102",
      "title": "Helping K-12 schools navigate the complex world of AI",
      "url": "https://news.mit.edu/2025/helping-k-12-schools-navigate-complex-world-of-ai-1103",
      "processed_at": "2026-01-08T13:41:49.552210",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This article describes MIT's Teaching Systems Lab guidebook and podcast series designed to help K-12 educators navigate AI integration challenges. The resources were developed with input from over 100 students and teachers across the United States sharing their experiences with generative AI tools. The project emphasizes an ethos of humility rather than prescriptive solutions, acknowledging that effective AI implementation strategies are not yet established. No empirical study was conducted; rather, the work aggregates qualitative perspectives and hypotheses from educators about potential paths forward. The article advocates for decentralized learning and testing of ideas rather than rushing to definitive conclusions about AI in education.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 3,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 188,
      "paper_id": "paper_309",
      "finding_id": "finding_309",
      "title": "Investigating Efficacy, Moderators and Mediators for an Online Mathematics Homework Intervention",
      "url": "https://files.eric.ed.gov/fulltext/ED657283.pdf",
      "processed_at": "2026-01-08T13:41:58.404293",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This randomized controlled trial evaluated the ASSISTments online homework intervention with 7th grade students in Maine. The study employed a school-level cluster randomized design with 43 schools, 87 teachers, and 2,769 students. The intervention provided immediate feedback to students on mathematics homework and automated reports to teachers to support formative assessment practices. Results showed a statistically significant positive effect on mathematics achievement (Hedges' g = 0.22), with larger effects for students with lower prior mathematics achievement (g = 0.29 for lower achievers vs. g = 0.12 for higher achievers).",
        "measure": "TerraNova Common Core Assessment for mathematics (7th grade standardized math assessment)",
        "study_size": 2769,
        "effect_size": 0.22,
        "student_racial_makeup": "92% White, 8% ethnic minority (including Asians, Blacks, Latinos)",
        "student_socioeconomic_makeup": "39% received free or reduced-price lunch",
        "student_gender_makeup": "50% male, 50% female",
        "student_age_distribution": "7th grade students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "39% FRPL",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 189,
      "paper_id": "paper_23837",
      "finding_id": "finding_23837",
      "title": "Adaptive intelligent tutoring systems for STEM education: analysis of the learning impact and effectiveness of personalized feedback",
      "url": "https://link.springer.com/article/10.1186/s40561-025-00389-y",
      "processed_at": "2026-01-08T13:42:14.220955",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study evaluated an AI-based intelligent tutoring system designed to provide real-time personalized and adaptive learning experiences in STEM disciplines (mathematics, physics, and programming) among 450 university students. Using a quasi-experimental design with experimental and control groups over one academic semester, the system integrated deep learning and natural language processing models to deliver targeted feedback and dynamically adjust learning trajectories. The experimental group achieved significantly higher feedback precision (88.5% vs 76.3%, p < 0.001) and greater mastery of concepts (85% in programming, 78% in mathematics, 70% in physics) compared to the control group. A linear regression model revealed a positive correlation between interaction time and progress rate (R\u00b2 = 0.76), and 80% of students found the adaptive feedback useful for identifying and correcting errors.",
        "measure": "Feedback precision (percentage of correct responses), mastery of concepts (percentage of concepts mastered), progress rate, response time, student satisfaction surveys",
        "study_size": 450,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Latin America & Caribbean",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 190,
      "paper_id": "paper_23613",
      "finding_id": "finding_23613",
      "title": "The Impact of Artificial Intelligence-Based Tutoring Systems on Developing Mathematical Reasoning among Secondary School Students",
      "url": "https://www.theamericanjournals.com/index.php/tajas/article/view/6969",
      "processed_at": "2026-01-08T13:42:30.659010",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the impact of AI-based tutoring systems on mathematical reasoning among 120 secondary school students in Amman, Jordan, divided into experimental groups receiving AI tutoring and control groups following traditional teaching methods. Data were collected through pre- and post-tests, engagement logs, surveys, and interviews, with quantitative analysis using t-tests, effect sizes, and correlation analyses. Results showed that AI tutoring significantly improved overall mathematical reasoning, with all reasoning components (conjecture, justification, representation, and metacognition) positively influenced, particularly conjecture and representation. Higher student engagement and frequent interaction with the AI system were strongly associated with better learning outcomes. Both students and teachers reported positive perceptions of the AI tutoring system, with effective implementation depending on teacher guidance, scaffolding, and a supportive learning environment.",
        "measure": "Mathematical reasoning pre- and post-tests measuring conjecture, justification, representation, and metacognition",
        "study_size": 120,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Secondary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 191,
      "paper_id": "paper_23613",
      "finding_id": "finding_71566",
      "title": "The Impact of Artificial Intelligence-Based Tutoring Systems on Developing Mathematical Reasoning among Secondary School Students",
      "url": "https://www.theamericanjournals.com/index.php/tajas/article/view/6969",
      "processed_at": "2026-01-08T13:42:41.805276",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the impact of AI-based tutoring systems on mathematical reasoning among 120 secondary school students in Amman, Jordan, divided into experimental groups receiving AI tutoring and control groups following traditional teaching methods. Data were collected through pre- and post-tests, engagement logs, surveys, and interviews, with quantitative analysis using t-tests, effect sizes, and correlation analyses. Results showed that AI tutoring significantly improved overall mathematical reasoning, with all reasoning components (conjecture, justification, representation, and metacognition) positively influenced, particularly conjecture and representation. Higher student engagement and frequent interaction with the AI system were strongly associated with better learning outcomes. Both students and teachers reported positive perceptions of the AI tutoring system, with effective implementation depending on teacher guidance, scaffolding, and a supportive learning environment.",
        "measure": "Mathematical reasoning pre- and post-tests measuring conjecture, justification, representation, and metacognition",
        "study_size": 120,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Secondary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 192,
      "paper_id": "paper_23613",
      "finding_id": "finding_605",
      "title": "The Impact of Artificial Intelligence-Based Tutoring Systems on Developing Mathematical Reasoning among Secondary School Students",
      "url": "https://www.theamericanjournals.com/index.php/tajas/article/view/6969",
      "processed_at": "2026-01-08T13:42:51.509010",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the impact of AI-based tutoring systems on mathematical reasoning among 120 secondary school students in Amman, Jordan, divided into experimental groups receiving AI tutoring and control groups following traditional teaching methods. Data were collected through pre- and post-tests, engagement logs, surveys, and interviews, with quantitative analysis using t-tests, effect sizes, and correlation analyses. Results showed that AI tutoring significantly improved overall mathematical reasoning, with all reasoning components (conjecture, justification, representation, and metacognition) positively influenced, particularly conjecture and representation. Higher student engagement and frequent interaction with the AI system were strongly associated with better learning outcomes. Both students and teachers reported positive perceptions of the AI tutoring system, with effective implementation depending on teacher guidance, scaffolding, and a supportive learning environment.",
        "measure": "Mathematical reasoning pre- and post-tests measuring conjecture, justification, representation, and metacognition",
        "study_size": 120,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Secondary school students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Middle East & North Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 193,
      "paper_id": "paper_78012",
      "finding_id": "finding_78012",
      "title": "A meta-analysis of AI-enabled personalized STEM education in schools",
      "url": "https://link.springer.com/article/10.1186/s40594-025-00566-y",
      "processed_at": "2026-01-08T13:43:01.566136",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis synthesized 99 effect sizes from 32 randomized controlled trial studies examining AI-enabled personalized STEM education in K-12 schools from 2012-2024. The study population included students from kindergarten through senior high school across multiple countries. Using a random effects model, the analysis found a significant small-to-medium overall effect size (Hedges' g = 0.455, p < 0.001) favoring AI-enabled approaches over traditional non-AI methods. Significant moderators included school level (greater effects in secondary schools), AI application type (AR/VR showing largest effects at g = 1.765), personalized learning model type (models with teacher involvement showing stronger effects), and subject area (comprehensive courses showing largest effects at g = 2.161). The findings indicate that AI technologies provide meaningful but modest improvements in K-12 STEM learning outcomes.",
        "measure": "Learning outcomes including knowledge/skills, perceptions/attitudes, engagement, and comprehensive ability measured through various assessments",
        "study_size": 99,
        "effect_size": 0.455,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (kindergarten through senior high school)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 194,
      "paper_id": "paper_3361",
      "finding_id": "finding_3361",
      "title": "The Algorithmic Turn: The Emerging Evidence On AI Tutoring That's Hard to Ignore",
      "url": "https://carlhendrick.substack.com/p/the-algorithmic-turn-the-emerging",
      "processed_at": "2026-01-08T13:43:18.014820",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This article synthesizes emerging evidence on AI tutoring systems, primarily focusing on a Harvard University randomized controlled trial with 194 undergraduate physics students where a GPT-4-based AI tutor was compared against well-implemented active learning instruction. The AI tutor produced median learning gains more than double those of the classroom group, with effect sizes ranging from 0.73 to 1.3 standard deviations. The article also reviews other AI tutoring systems including ASSISTments (effect sizes 0.18-0.29 SD), Carnegie Learning's MATHia (0.21-0.38 SD), and VanLehn's meta-analysis showing intelligent tutoring systems produce 0.76 SD gains compared to no tutoring. However, the author notes that poorly designed AI tools can harm learning through cognitive offloading, and emphasizes that effectiveness depends critically on pedagogical design rather than the technology itself.",
        "measure": "Learning gains measured through physics assessments, standardized tests, and mastery rates",
        "study_size": "not_reported",
        "effect_size": 0.73,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Undergraduate students (college-age)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "research_university",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 195,
      "paper_id": "paper_84506",
      "finding_id": "finding_84506",
      "title": "Examining the effect of AI-based tutoring systems on students' mathematical problem-solving skills: The moderating role of mathematics anxiety",
      "url": "https://www.j-psp.com/article/examining-the-effect-of-ai-based-tutoring-systems-on-students-mathematical-problem-solving-skills-16906",
      "processed_at": "2026-01-08T13:43:33.644653",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study investigated the effect of AI-based tutoring systems on university students' mathematical problem-solving skills, with mathematics anxiety as a moderating variable. Using a cross-sectional survey design, data were collected from 338 university students in Ghana via standardized questionnaires and analyzed using Structural Equation Modeling with Amos. The findings revealed that AI-based tutoring systems had a direct and significant positive impact on students' mathematical problem-solving abilities. However, mathematics anxiety negatively affected problem-solving skills and also negatively moderated the relationship between AI tutoring systems and mathematical problem-solving, meaning students with higher anxiety benefited less from the AI intervention.",
        "measure": "Mathematical problem-solving skills (standardized questionnaire)",
        "study_size": 338,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "private",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 196,
      "paper_id": "paper_84506",
      "finding_id": "finding_70157",
      "title": "Examining the effect of AI-based tutoring systems on students' mathematical problem-solving skills: The moderating role of mathematics anxiety",
      "url": "https://www.j-psp.com/article/examining-the-effect-of-ai-based-tutoring-systems-on-students-mathematical-problem-solving-skills-16906",
      "processed_at": "2026-01-08T13:43:48.728717",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study investigated the effect of AI-based tutoring systems on university students' mathematical problem-solving skills, with mathematics anxiety as a moderating variable. Using a cross-sectional survey design, data were collected from 338 university students in Ghana via standardized questionnaires and analyzed using Structural Equation Modeling with Amos. The findings revealed that AI-based tutoring systems had a direct and significant positive impact on students' mathematical problem-solving abilities. However, mathematics anxiety negatively affected problem-solving skills and also negatively moderated the relationship between AI tutoring systems and mathematical problem-solving, meaning students with higher anxiety benefited less from the AI intervention.",
        "measure": "Mathematical problem-solving skills (standardized questionnaire)",
        "study_size": 338,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "university students",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 197,
      "paper_id": "paper_23490",
      "finding_id": "finding_23490",
      "title": "Nonprofit Launches Studies to Assess AI's Role in K-12",
      "url": "https://www.govtech.com/education/k-12/nonprofit-launches-studies-to-assess-ais-role-in-k-12",
      "processed_at": "2026-01-08T13:44:04.149224",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This news article describes the launch of the AI in Education Network by the American Institutes for Research (AIR), which will conduct six coordinated studies on AI use in K-12 education. The studies will examine AI's role in instruction, assessment, professional learning, and data-driven decision-making. No empirical findings are reported as the studies are newly launched and have not yet produced results. The initiative aims to provide evidence-based insights for educators and policymakers about which AI tools improve teaching and learning.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 3,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 198,
      "paper_id": "paper_91847",
      "finding_id": "finding_91847",
      "title": "Student Reasoning Patterns in Science (SPIN-Science)",
      "url": "https://ies.ed.gov/use-work/awards/student-reasoning-patterns-science-spin-science",
      "processed_at": "2026-01-08T13:44:13.195738",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is a measurement development grant focused on creating an AI-supported classroom assessment tool to measure middle-school students' reasoning patterns during scientific argumentation about ecosystem phenomena. The project involves iterative development through cognitive lab studies, pilot studies with approximately 200 students, and field studies with approximately 1,000 students across California, South Carolina, and New Jersey. The assessment tool will use natural language processing to classify student reasoning patterns and provide real-time feedback. As this is a development and validation project beginning in 2024 with completion expected in 2028, empirical findings on effectiveness have not yet been reported.",
        "measure": "Scientific argumentation competence including claims, grounds/evidence, and rebuttal components using items from California Science Test (CAST) database",
        "study_size": 1250,
        "effect_size": "not_reported",
        "student_racial_makeup": "at least 25% minorities",
        "student_socioeconomic_makeup": "at least 25% low-income students",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "grades 6-8",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "at least 25% low-income",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 199,
      "paper_id": "paper_62247",
      "finding_id": "finding_62247",
      "title": "A meta-analysis of technology-delivered literacy instruction for elementary students",
      "url": "https://link.springer.com/article/10.1007/s11423-024-10354-0",
      "processed_at": "2026-01-08T13:44:25.963105",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 53 experimental or quasi-experimental studies evaluating technology-delivered literacy instruction for students in Grades K-5. The intervention involved computer-based literacy programs addressing skills such as phonological awareness, phonics, vocabulary, comprehension, and fluency, delivered primarily on computers in school settings. The study population consisted of elementary students, with about half of studies including students with or at risk for reading difficulties. Using a random-effects model, the analysis found a statistically significant small positive effect (g = 0.24, p < .001) on norm- or criterion-referenced literacy outcomes, indicating that elementary students benefit from technology-delivered literacy instruction. No moderator variables (study design, grade level, dosage, or literacy domain) were statistically significant, though instruction including phonics/decoding and encoding/spelling showed trends toward larger effects.",
        "measure": "Norm- or criterion-referenced literacy outcome measures (phonological awareness, phonics/decoding/word reading, reading comprehension, text reading/fluency, vocabulary, spelling)",
        "study_size": 10812,
        "effect_size": 0.24,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Nine studies reported at least 50% of participants experienced economic disadvantage (eligible for free or reduced-price lunch)",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grades K-5 (ages 5-11), with majority in Grades K-2",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 200,
      "paper_id": "paper_9617",
      "finding_id": "finding_9617",
      "title": "Modern vs. Traditional: Comparing Reading-Level and Strategy-Based Small Groups in Primary Grades",
      "url": "https://scholarworks.gvsu.edu/cgi/viewcontent.cgi?article=2981&context=mrj",
      "processed_at": "2026-01-08T13:44:43.584654",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 201,
      "paper_id": "paper_9743",
      "finding_id": "finding_9743",
      "title": "Beyond traditional teaching: a systematic review of innovative pedagogical practices in higher education",
      "url": "https://f1000research.com/articles/13-22",
      "processed_at": "2026-01-08T13:44:48.022754",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review synthesized 25 scholarly articles on innovative pedagogical practices in higher education, covering publications from 2015 to 2023 across ERIC, Scopus, and Proquest databases. The review identified three key teaching strategy categories: student-centered approaches, integration of educational technology, and evaluation and feedback methodologies. The population consisted primarily of university faculty and students across diverse educational contexts in Europe, Asia, and Latin America. The qualitative synthesis found that these innovative practices promote teaching effectiveness, student autonomy, and meaningful learning, with the overall direction of findings being positive regarding the impact of these pedagogical innovations on higher education quality.",
        "measure": "Qualitative synthesis of pedagogical strategies and their reported impacts on teaching and learning effectiveness",
        "study_size": 25,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 202,
      "paper_id": "paper_36243",
      "finding_id": "finding_36243",
      "title": "The relationship between reading age, education and life outcomes",
      "url": "https://cfey.org/wp-content/uploads/2019/03/The-relationship-between-reading-age-education-and-life-outcomes.pdf",
      "processed_at": "2026-01-08T13:45:03.849875",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This literature review synthesizes research on the relationship between reading ability and educational attainment as well as broader life outcomes across multiple populations. The review examines evidence from UK and US studies involving children, adolescents, and adults to assess how reading age affects academic success, employment, health, offending risk, and psychological wellbeing. Key findings indicate that reading ability at ages 6, 9, and 11 predicts reading comprehension, vocabulary, and general knowledge at age 16, and that poor readers are significantly more likely to drop out of secondary education (1 in 6 poor readers at age 7 versus 1 in 25 proficient readers). Adults with functional literacy (reading age of 11 or above) earn on average 16% more than those without, and 60% of prisoners have difficulties with basic literacy, demonstrating the profound impact of reading ability across the lifespan.",
        "measure": "Reading age assessments (WRAT, SWRT, STAR), educational attainment (GCSE grades, dropout rates), employment status, earnings, health outcomes, incarceration rates, life satisfaction ratings",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "Studies reference low socioeconomic populations and note that 16% of UK adults are functionally illiterate",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Studies span from preschool through adulthood, with specific references to ages 6, 7, 9, 11, 16, and 30",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Europe",
        "system_impact_levels": 3,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 203,
      "paper_id": "paper_35984",
      "finding_id": "finding_35984",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K-12 Students' Mathematical Learning",
      "url": "https://eric.ed.gov/?id=EJ1054449",
      "processed_at": "2026-01-08T13:45:21.354274",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, while some compared ITS with human tutoring or homework practices. Results indicated that ITS had no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effects were greater for interventions lasting less than a school year and for students from the general population compared to low achievers. The findings raise concerns about whether computerized learning might contribute to achievement gaps between students with different achievement levels.",
        "measure": "Mathematical learning outcomes and achievement gains",
        "study_size": 34,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (elementary and secondary education)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 204,
      "paper_id": "paper_35984",
      "finding_id": "finding_77269",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K-12 Students' Mathematical Learning",
      "url": "https://eric.ed.gov/?id=EJ1054449",
      "processed_at": "2026-01-08T13:45:29.810662",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, while some compared ITS with human tutoring or homework practices. Results indicated that ITS had no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effects were greater for interventions lasting less than a school year and for students from the general population compared to low achievers. The findings raise concerns about whether computerized learning might contribute to achievement gaps between students with different achievement levels.",
        "measure": "Mathematical learning outcomes and achievement gains",
        "study_size": 34,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (elementary and secondary education)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 205,
      "paper_id": "paper_35984",
      "finding_id": "finding_39952",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K-12 Students' Mathematical Learning",
      "url": "https://eric.ed.gov/?id=EJ1054449",
      "processed_at": "2026-01-08T13:45:38.737580",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, while some compared ITS with human tutoring or homework practices. Results indicated that ITS had no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effects were greater for interventions lasting less than a school year and for students from the general population compared to low achievers. The findings raise concerns about whether computerized learning might contribute to achievement gaps between students with different achievement levels.",
        "measure": "Mathematical learning outcomes and achievement gains",
        "study_size": 34,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (elementary and secondary education)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 206,
      "paper_id": "paper_35984",
      "finding_id": "finding_21169",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K-12 Students' Mathematical Learning",
      "url": "https://eric.ed.gov/?id=EJ1054449",
      "processed_at": "2026-01-08T13:45:47.076520",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, while some compared ITS with human tutoring or homework practices. Results indicated that ITS had no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effects were greater for interventions lasting less than a school year and for students from the general population compared to low achievers. The findings raise concerns about whether computerized learning might contribute to achievement gaps between students with different achievement levels.",
        "measure": "Mathematical learning outcomes and achievement gains",
        "study_size": 34,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (elementary and secondary education)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 207,
      "paper_id": "paper_49472",
      "finding_id": "finding_49472",
      "title": "Designing and deploying scalable intelligent tutoring systems to enhance adult education",
      "url": "https://researchdiscovery.drexel.edu/view/pdfCoverPage?instCode=01DRXU_INST&filePid=13590127400004721&download=true",
      "processed_at": "2026-01-08T13:45:55.897676",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 208,
      "paper_id": "paper_88733",
      "finding_id": "finding_88733",
      "title": "AI in Education: The Rise of Intelligent Tutoring Systems",
      "url": "https://www.park.edu/blog/ai-in-education-the-rise-of-intelligent-tutoring-systems/",
      "processed_at": "2026-01-08T13:46:12.407284",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This is not an empirical research paper but rather an informational blog post from Park University describing intelligent tutoring systems (ITS) and their potential applications in education. The article provides a conceptual overview of how ITS work, including their four key components (domain model, student model, tutoring model, and user interface model), and discusses potential benefits such as personalized learning, immediate feedback, and scalability. No original research study was conducted, and no empirical data or findings are reported. The piece serves as an educational resource promoting Park University's Master of Education program in Educational Technology.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 209,
      "paper_id": "paper_91943",
      "finding_id": "finding_91943",
      "title": "A Comprehensive Review of AI-based Intelligent Tutoring Systems: Applications and Challenges",
      "url": "https://arxiv.org/pdf/2507.18882",
      "processed_at": "2026-01-08T13:46:21.269201",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic literature review analyzed 127 qualified studies published from 2010 to 2025 examining AI-based Intelligent Tutoring Systems across domains including pedagogical strategies, NLP, adaptive learning, student modeling, and domain-specific applications. The review found that ITS can improve student performance by approximately 20% and achieve learning gains comparable to human tutors in structured domains like mathematics and physics. However, the results reveal a complex landscape with both advancements and persistent challenges, including methodological inconsistencies across studies, limited longitudinal validation, concerns about algorithmic bias and data privacy, and difficulties generalizing findings across diverse learner populations and educational contexts. The study identifies a need for greater scientific rigor in experimental design and standardized evaluation methods.",
        "measure": "Learning gains, student performance, engagement metrics, user satisfaction",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 210,
      "paper_id": "paper_78115",
      "finding_id": "finding_78115",
      "title": "How should schools be teaching math?",
      "url": "https://littleknownfacts.substack.com/p/how-should-schools-be-teaching-math",
      "processed_at": "2026-01-08T13:46:38.276445",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This study analyzed 2012 PISA data across OECD countries to examine the relationship between mathematics instructional practices and student math proficiency. The researchers compared teacher-directed instruction (explicit teaching, checking understanding, setting goals) versus student-oriented instruction (group work, student-planned activities, complex projects) while controlling for socioeconomic status, family structure, and other demographic factors. Results showed that a one standard deviation increase in teacher-directed instruction corresponded with a 0.19 standard deviation increase in math scores, while a one standard deviation increase in student-oriented instruction correlated with a 0.27 standard deviation decrease in scores. The positive effects of teacher-directed instruction persisted across all difficulty levels of PISA questions, with students receiving teacher-directed instruction being approximately 20% more likely to correctly answer even the most difficult questions compared to those receiving student-oriented instruction.",
        "measure": "PISA mathematics exam scores",
        "study_size": "not_reported",
        "effect_size": 0.19,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "15-year-old students (PISA standard age)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 211,
      "paper_id": "paper_40387",
      "finding_id": "finding_40387",
      "title": "A Randomized Controlled Trial of a Modularized, Computer-Assisted, Self-Paced Approach to Developmental Math",
      "url": "https://www.mdrc.org/work/publications/randomized-controlled-trial-modularized-computer-assisted-self-paced-approach",
      "processed_at": "2026-01-08T13:46:48.273704",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This randomized controlled trial evaluated a modularized, computer-assisted, self-paced approach to developmental math compared to traditional direct-instruction courses at community colleges in Texas. The study included 1,403 undergraduate students who required developmental math remediation. Using a randomized controlled trial design, researchers assessed whether the intervention improved students' likelihood of completing the developmental math course sequence. Despite the program being well implemented, the study found no evidence that the modularized, computer-assisted, self-paced approach was superior to traditional math instruction. These null findings are significant given the popularity of modularization and self-paced computer-assisted instruction as developmental education reforms.",
        "measure": "Completion of developmental math course sequence",
        "study_size": 1403,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "community_college",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 212,
      "paper_id": "paper_54399",
      "finding_id": "finding_54399",
      "title": "Using Computer-Assisted Instruction to Accelerate Students through Developmental Math: An Impact Study of Modularization and Compression",
      "url": "https://ies.ed.gov/use-work/awards/using-computer-assisted-instruction-accelerate-students-through-developmental-math-impact-study",
      "processed_at": "2026-01-08T13:47:01.519964",
      "status": "success",
      "extracted_fields": {
        "direction": "No Effect",
        "results_summary": "This randomized controlled trial examined ModMath, a computer-assisted, modularized, self-paced approach to developmental math at a large Texas community college. Approximately 1,400 community college students referred to non-credit remedial math were randomly assigned to either ModMath or traditional lecture-based developmental math courses. The study tracked academic outcomes including completion of developmental math, credit attainment, and passing the first college-level math course over at least two semesters. While ModMath was well-implemented, researchers did not find evidence that ModMath was superior to the traditional non-modularized direct-instruction math course in improving student outcomes.",
        "measure": "Academic progress in mathematics including completing developmental math, credit accumulation, and passing first college-level math course",
        "study_size": 1400,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "community_college",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 213,
      "paper_id": "paper_66675",
      "finding_id": "finding_66675",
      "title": "Current practices and future direction of artificial intelligence in mathematics education: A systematic review",
      "url": "https://files.eric.ed.gov/fulltext/EJ1469663.pdf",
      "processed_at": "2026-01-08T13:47:15.022777",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic literature review examined 32 studies on artificial intelligence in mathematics education (AIME) published between 2019-2024 from Web of Science and Scopus databases. The review analyzed AI tools across primary, secondary, and higher education levels, finding that most studies focused on middle/high school (43.8%), followed by university/adult learners (31.2%) and primary/elementary (25%). Seven categories of AI tools were identified including chatbots, virtual reality, augmented reality, adaptive learning systems/ITS, learning analytics, serious games, and mathematics problem solvers. The findings indicate that AI technologies, particularly adaptive learning systems and intelligent tutoring systems, significantly enhance personalized learning experiences and improve mathematics education outcomes across all educational levels.",
        "measure": "Systematic categorization and thematic analysis of AI tools, educational levels, and implementation trends",
        "study_size": 32,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 214,
      "paper_id": "paper_48743",
      "finding_id": "finding_48743",
      "title": "Changes in Math Instruction and Student Outcomes since the Implementation of Common Core State Standards in Chicago",
      "url": "https://eric.ed.gov/?id=ED589668",
      "processed_at": "2026-01-08T13:47:30.065425",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined how math instruction and student outcomes changed in Chicago Public Schools following the implementation of Common Core State Standards in Mathematics (CCSS-M) in 2014-15, comparing schools with varying levels of professional development. The study population included elementary, middle, and high school students across CPS, with data spanning from pre-implementation (2010-11, 2011-12) through early implementation (2014-15 to 2016-17). Students reported increasingly higher levels of academic demand, rigor, instructional clarity, and teacher support across all school types, with significantly larger improvements in schools with extensive standards-related professional development. Among sixth- through eighth-grade students, math test scores, course grades, and pass rates improved over time, with significantly larger gains in schools with extensive professional development compared to those with limited professional development. The findings indicate positive effects of CCSS-M implementation, particularly when accompanied by robust professional development support.",
        "measure": "Math test scores, course grades, course passing rates, and student survey responses on academic demand, rigor, instructional clarity, and teacher support",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary (PreK-5th), Middle School (6th-8th), and High School (9th-12th) students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "district",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 2,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 215,
      "paper_id": "paper_65238",
      "finding_id": "finding_65238",
      "title": "An Investigation of the Impact of Integrated Learning System Use on Mathematics Achievement of Elementary Students",
      "url": "https://dc.etsu.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1897&context=etd",
      "processed_at": "2026-01-08T13:47:40.072322",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 216,
      "paper_id": "paper_89863",
      "finding_id": "finding_89863",
      "title": "Effectiveness of Technology-Integrated Instruction on High School Students' Mathematic Achievement Scores",
      "url": "https://scholarworks.waldenu.edu/cgi/viewcontent.cgi?article=1071&context=dissertations",
      "processed_at": "2026-01-08T13:47:43.621113",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 217,
      "paper_id": "paper_45142",
      "finding_id": "finding_45142",
      "title": "The Effectiveness of Educational Technology Applications for Enhancing Mathematics Achievement in K-12 Classrooms: A Meta-Analysis",
      "url": "https://bestevidence.org/2021/02/07/mathematics-effectiveness-of-technology/",
      "processed_at": "2026-01-08T13:47:47.739427",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the effectiveness of educational technology applications for enhancing mathematics achievement in K-12 classrooms, synthesizing 74 qualifying studies with a total sample of 56,886 students. The study compared three categories of educational technology (computer-managed learning, comprehensive models, and supplemental CAI) against traditional teaching methods without educational technology. Results indicated that educational technology applications produce a positive but small overall effect (ES=+0.16) on mathematics achievement. Supplemental CAI showed the largest effect size (+0.19), while computer-managed learning (+0.09) and comprehensive models (+0.06) demonstrated smaller effects. The findings suggest that methodological features such as sample size, study design, and fidelity of implementation moderate the effects of educational technology interventions.",
        "measure": "Mathematics achievement test scores",
        "study_size": 56886,
        "effect_size": 0.16,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 218,
      "paper_id": "paper_50106",
      "finding_id": "finding_50106",
      "title": "Science and Engineering Indicators 2018 - Chapter 1: Elementary and Secondary Mathematics and Science Education",
      "url": "https://www.nsf.gov/statistics/2018/nsb20181/report/sections/elementary-and-secondary-mathematics-and-science-education/instructional-technology-and-digital-learning",
      "processed_at": "2026-01-08T13:47:56.784918",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This comprehensive government report synthesizes research on instructional technology and online learning in K-12 education across the United States. The report reviews multiple meta-analyses and studies examining the effects of computers, mobile devices, and online learning on student achievement in mathematics and science. Key findings indicate that technology integration shows modest positive effects on student learning when properly implemented, with one-to-one laptop programs and technology-assisted mathematics programs demonstrating small but positive effects on achievement. However, full-time online charter schools showed significantly weaker academic growth compared to traditional schools, and online credit recovery courses produced weaker outcomes than face-to-face instruction, indicating mixed overall results depending on implementation type.",
        "measure": "Student academic achievement in mathematics and science, annual academic growth, test scores",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "Students in high-minority schools were half as likely to have high-speed Internet as students in low-minority schools",
        "student_socioeconomic_makeup": "Students in low-income schools were twice as likely as students in affluent schools to have slow Internet access",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (approximately ages 5-18)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "mixed",
        "governance_type": "mixed",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 3,
        "decision_making_complexity": 3,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 219,
      "paper_id": "paper_37478",
      "finding_id": "finding_37478",
      "title": "Inquiry Based Mathematics Instruction Versus Traditional Mathematics Instruction: The Effect on Student Understanding and Comprehension in an Eighth Grade Pre-Algebra Classroom",
      "url": "https://digitalcommons.cedarville.edu/cgi/viewcontent.cgi?article=1025&context=education_theses",
      "processed_at": "2026-01-08T13:48:14.038717",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 220,
      "paper_id": "paper_38747",
      "finding_id": "finding_38747",
      "title": "Mathematics teaching efficacy among traditional and non-traditional elementary pre-service teachers",
      "url": "https://www.scimath.net/download/mathematics-teaching-efficacy-among-traditional-and-non-traditional-elementary-pre-service-teachers-9425.pdf",
      "processed_at": "2026-01-08T13:48:18.872082",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined the impact of a three-course mathematics sequence taught from a constructivist approach on the mathematics teaching efficacy beliefs of 51 elementary pre-service teachers, categorized as traditional (n=27) and non-traditional (n=24). Using a pre-post design with the Mathematics Teaching Efficacy Beliefs Instrument (MTEBI), the study measured personal mathematics teaching efficacy (PMTE) and mathematics teaching outcome expectancy (MTOE). Results showed that non-traditional pre-service teachers demonstrated significant improvements in both PMTE and MTOE subscales, while traditional pre-service teachers showed significant improvement only in PMTE but not in MTOE. The findings suggest that constructivist pedagogy in content courses can positively influence self-efficacy beliefs, though the effects differ between traditional and non-traditional students.",
        "measure": "Mathematics Teaching Efficacy Beliefs Instrument (MTEBI) with Personal Mathematics Teaching Efficacy (PMTE) and Mathematics Teaching Outcome Expectancy (MTOE) subscales",
        "study_size": 51,
        "effect_size": "not_reported",
        "student_racial_makeup": "Traditional group: 21 Caucasian females, 1 Bosnian female, 1 Asian American female, 1 African American female, 1 Native American female, 2 Caucasian males; Non-traditional group: 20 Caucasian females, 1 African American female, 3 Caucasian males",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "Traditional: 25 females, 2 males; Non-traditional: 21 females, 3 males",
        "student_age_distribution": "Traditional: ages 19-24; Non-traditional: ages 33-58",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 221,
      "paper_id": "paper_63936",
      "finding_id": "finding_63936",
      "title": "Personalized Goal Setting Support to Enhance Technology-Supported Learning",
      "url": "https://cborchers.com/pdf/dissertation-proposal-draft.pdf",
      "processed_at": "2026-01-08T13:48:37.281949",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This thesis proposal examines the effects of adaptive, data-driven goal-setting interventions embedded within intelligent tutoring systems on middle school students' engagement and learning outcomes. Across multiple quasi-experimental and randomized crossover studies conducted in grades 5-9 classrooms, students who received goal-setting contracts with contingent rewards demonstrated approximately 25% more time on task and 40% higher skill mastery compared to baseline periods without goal support. Adaptive, student-centered goals with data-driven calibration led to significantly higher goal achievement rates than static, teacher-assigned goals. The intervention was broadly effective for over 80% of students, though students with higher baseline engagement benefited less, suggesting that intrinsic motivation may moderate intervention effects.",
        "measure": "Weekly practice time (minutes), skill proficiency (skills mastered per week), goal achievement rate",
        "study_size": 184,
        "effect_size": 0.48,
        "student_racial_makeup": "Nearly all African American",
        "student_socioeconomic_makeup": "All from low-income backgrounds",
        "student_gender_makeup": "School 1: all male; School 2: approximately equally represented genders",
        "student_age_distribution": "Grades 5-9 (approximately ages 10-15)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_reported",
        "ses_indicator": "low",
        "ses_numeric": "100% low-income",
        "special_education_services": "yes",
        "urban_type": "suburban",
        "governance_type": "charter",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 222,
      "paper_id": "paper_3428",
      "finding_id": "finding_3428",
      "title": "A Meta-Synthesis of the Effectiveness of Differentiated Instruction Strategies on Students' Academic Performance in Mathematics",
      "url": "https://rsisinternational.org/journals/ijriss/articles/a-meta-synthesis-of-the-effectiveness-of-differentiated-instruction-strategies-on-students-academic-performance-in-mathematics/",
      "processed_at": "2026-01-08T13:48:58.205348",
      "status": "skipped",
      "extracted_fields": {},
      "error": "insufficient content"
    },
    {
      "index": 223,
      "paper_id": "paper_15218",
      "finding_id": "finding_15218",
      "title": "Effects of Intelligent Tutoring Systems on Mathematics Achievement of Underachieving Students",
      "url": "https://edutec.science/new-pub-effects-of-intelligent-tutoring-systems-on-mathematics-achievement-of-underachieving-students/",
      "processed_at": "2026-01-08T13:48:59.789994",
      "status": "success",
      "extracted_fields": {
        "direction": "Negative",
        "results_summary": "This quasi-experimental study examined the effect of the ALEKS intelligent tutoring system on mathematics achievement among underachieving 8th-grade students. The study compared pretest and posttest results between two consecutive years: the first year used only McGraw's 'Reveal' curriculum with teacher-led instruction, while the second year supplemented the curriculum with ALEKS for fifty minutes every other day in a math support class. The study population consisted of struggling middle school students receiving supplemental mathematics instruction. Contrary to expectations, findings revealed that students who received teacher-led instructions showed greater mathematics achievement than those who used ALEKS-led instructions, indicating a negative effect of the ITS intervention on student outcomes.",
        "measure": "Mathematics achievement pretest and posttest scores",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "8th grade",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 224,
      "paper_id": "paper_15218",
      "finding_id": "finding_77449",
      "title": "Effects of Intelligent Tutoring Systems on Mathematics Achievement of Underachieving Students",
      "url": "https://edutec.science/new-pub-effects-of-intelligent-tutoring-systems-on-mathematics-achievement-of-underachieving-students/",
      "processed_at": "2026-01-08T13:49:10.020929",
      "status": "success",
      "extracted_fields": {
        "direction": "Negative",
        "results_summary": "This quasi-experimental study examined the effect of the ALEKS intelligent tutoring system on mathematics achievement among underachieving 8th-grade students. The study compared pretest and posttest results between two consecutive years: the first year used only McGraw's 'Reveal' curriculum with teacher-led instruction, while the second year supplemented the curriculum with ALEKS for fifty minutes every other day in a math support class. The study population consisted of struggling middle school students receiving supplemental mathematics instruction. Contrary to expectations, findings revealed that students who received teacher-led instructions showed greater mathematics achievement than those who used ALEKS-led instructions, indicating a negative effect of the ITS intervention on student outcomes.",
        "measure": "Mathematics achievement pretest and posttest scores",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "8th grade",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 225,
      "paper_id": "paper_45180",
      "finding_id": "finding_45180",
      "title": "A Systematic Review of Literature on the Effectiveness of Intelligent Tutoring Systems in STEM",
      "url": "https://people.csail.mit.edu/dkao/pdf/feng2021its.pdf",
      "processed_at": "2026-01-08T13:49:25.131779",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic literature review examined 22 papers on intelligent tutoring systems (ITS) in STEM domains published over the past two decades. The review focused on pedagogical aspects including scaffolding approaches, learning theories, and effectiveness for conceptual learning, problem-solving, and model building. The studies primarily involved college students (n=16) and high school/middle school students (n=5) across physics, computer science, and mathematics domains. Effect sizes across the reviewed studies ranged from no evidence of impact to 2.33, with most ITS showing significant learning improvements compared to control conditions, though not matching expert human tutors. The review found that while ITS contribute to better learning outcomes, there is a lack of fine-grained research on specific learning modes and a need for better integration of established learning theories and pedagogical scaffolding methods.",
        "measure": "Learning gains measured through pre-post test comparisons and effect sizes",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "not_applicable",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 226,
      "paper_id": "paper_46380",
      "finding_id": "finding_46380",
      "title": "The Effectiveness of AI-Driven Tools in Improving Student Learning Outcomes Compared to Traditional Methods",
      "url": "https://iacis.org/iis/2025/4_iis_2025_233-247.pdf",
      "processed_at": "2026-01-08T13:49:40.057279",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review synthesized 21 empirical studies published between 2015 and 2025 examining AI-driven tools including adaptive learning platforms and intelligent tutoring systems across K-12, higher education, and vocational settings. The review employed quasi-experimental, qualitative, mixed-methods, and quantitative study designs to compare AI-supported instruction with traditional methods. Key outcomes measured included academic performance, student engagement, and knowledge retention, with performance gains ranging from 15% to 35%, engagement increases up to 40%, and faster task completion rates. The majority of studies reported substantial improvements favoring AI-driven tools, though effectiveness varied by context, implementation strategy, and subject matter, with some studies showing minimal or no significant differences.",
        "measure": "Academic performance (test scores, quiz scores), student engagement, knowledge retention, task completion efficiency, learner satisfaction",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 227,
      "paper_id": "paper_16270",
      "finding_id": "finding_16270",
      "title": "Artificial Intelligence Interventions in Mathematics Education: A Systematic Literature Review",
      "url": "https://files.eric.ed.gov/fulltext/EJ1481890.pdf",
      "processed_at": "2026-01-08T13:49:54.787575",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined 14 empirical studies on AI interventions in mathematics education, including Intelligent Tutoring Systems, adaptive learning platforms, and AI-powered educational apps. The review covered students from elementary through post-secondary levels across multiple countries including the United States, Slovakia, Philippines, Israel, Spain, Nigeria, Taiwan, South Korea, Sweden, and Jordan. Using PRISMA guidelines for systematic review methodology, the authors found that AI interventions generally improved student learning outcomes, with effect sizes ranging from small (d = 0.13) to large (d = 1.37). The findings indicate that longer intervention durations and integration with teacher support produced stronger effects, while shorter interventions or those without substantial teacher involvement yielded smaller improvements.",
        "measure": "Mathematics achievement test scores, problem-solving proficiency, fraction understanding, pre-calculus performance",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary through post-secondary, Grades PreK-5 through undergraduate",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 228,
      "paper_id": "paper_16270",
      "finding_id": "finding_4244",
      "title": "Artificial Intelligence Interventions in Mathematics Education: A Systematic Literature Review",
      "url": "https://files.eric.ed.gov/fulltext/EJ1481890.pdf",
      "processed_at": "2026-01-08T13:50:09.182493",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined 14 empirical studies on AI interventions in mathematics education, including Intelligent Tutoring Systems, adaptive learning platforms, and AI-powered educational apps. The review covered students from elementary through post-secondary levels across multiple countries. Studies employed various designs including randomized controlled trials, quasi-experimental designs, and mixed-methods approaches. Key findings showed that extended AI interventions produced larger effect sizes, with Photomath achieving d = 1.37 in pre-calculus and Learn with ME showing d = 0.49 in elementary mathematics. Overall, the review found positive effects of AI on mathematics learning outcomes, though effectiveness depended on intervention duration, teacher involvement, and pedagogical integration.",
        "measure": "Mathematics achievement test scores, problem-solving proficiency, fraction understanding assessments",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary through post-secondary, Grades PreK-12 and undergraduate",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 229,
      "paper_id": "paper_16270",
      "finding_id": "finding_81832",
      "title": "Artificial Intelligence Interventions in Mathematics Education: A Systematic Literature Review",
      "url": "https://files.eric.ed.gov/fulltext/EJ1481890.pdf",
      "processed_at": "2026-01-08T13:50:24.099475",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined 14 empirical studies on AI interventions in mathematics education, including Intelligent Tutoring Systems, adaptive learning platforms, and AI-powered educational apps. The review covered students from elementary through post-secondary levels across multiple countries including the United States, Slovakia, Philippines, Israel, Spain, Nigeria, Taiwan, South Korea, Sweden, and Jordan. Using PRISMA guidelines for systematic review methodology, the authors found that AI interventions generally improved student learning outcomes, with effect sizes ranging from small (d = 0.13) to large (d = 1.37). The findings indicate that longer intervention durations and integration with teacher support produced stronger effects, while shorter interventions or those without substantial teacher involvement yielded smaller improvements.",
        "measure": "Mathematics achievement test scores, problem-solving proficiency, fraction understanding, pre-calculus performance",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Elementary through post-secondary, Grades PreK-5 through undergraduate",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 230,
      "paper_id": "paper_96264",
      "finding_id": "finding_96264",
      "title": "AI Cognitive Tutors in Education: 20 Advances (2025)",
      "url": "https://yenra.com/ai20/cognitive-tutors-in-education//",
      "processed_at": "2026-01-08T13:50:38.799444",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This article synthesizes 20 advances in AI cognitive tutoring systems, drawing on multiple meta-analyses and empirical studies across various educational contexts. The review covers intelligent tutoring systems that adapt to individual learners' knowledge states, personalized learning paths, real-time feedback, emotion recognition, and predictive analytics. Key findings include a meta-analytic effect size of 0.76 for intelligent tutoring systems (nearly matching the 0.79 of one-on-one human tutoring), with 59% of adaptive learning implementations reporting improved academic performance. The overall direction of findings strongly supports the effectiveness of AI cognitive tutors in improving learning outcomes across multiple domains.",
        "measure": "Learning gains, academic performance, student engagement, effect sizes from meta-analyses",
        "study_size": "not_reported",
        "effect_size": 0.76,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "not_reported",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "not_reported",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 231,
      "paper_id": "paper_51931",
      "finding_id": "finding_51931",
      "title": "Intelligent Tutoring Systems: 7 Research-Backed Principles for Building an Effective AI Tutor",
      "url": "https://thirdspacelearning.com/us/blog/intelligent-tutoring-systems/",
      "processed_at": "2026-01-08T13:50:51.591301",
      "status": "success",
      "extracted_fields": {
        "direction": "not_reported",
        "results_summary": "This article is not an empirical study but rather a practitioner-oriented guide outlining seven research-backed principles for designing effective intelligent tutoring systems. The author synthesizes existing educational research on scaffolding, active recall, spaced repetition, interleaving, problem generation, error correction, and cognitive load management. The piece uses Third Space Learning's AI math tutor Skye as an illustrative example of how these principles can be implemented in practice. No original empirical data or experimental findings are reported in this article.",
        "measure": "not_reported",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 0
      },
      "error": null
    },
    {
      "index": 232,
      "paper_id": "paper_57004",
      "finding_id": "finding_57004",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K\u201312 Students' Mathematical Learning",
      "url": "https://www.academia.edu/72221760/A_meta_analysis_of_the_effectiveness_of_intelligent_tutoring_systems_on_K_12_students_mathematical_learning",
      "processed_at": "2026-01-08T13:51:04.209007",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, with some comparing ITS to human tutoring or homework. The study population included elementary through high school students across general and low-achieving populations. Overall findings indicated that ITS had no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effectiveness was greater for interventions lasting less than one school year and for general student populations compared to low achievers.",
        "measure": "Standardized test scores, modified standardized tests, course grades, course passing rates, and specifically designed tests",
        "study_size": 14321,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (elementary through high school)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 233,
      "paper_id": "paper_57004",
      "finding_id": "finding_37126",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K\u201312 Students' Mathematical Learning",
      "url": "https://www.academia.edu/72221760/A_meta_analysis_of_the_effectiveness_of_intelligent_tutoring_systems_on_K_12_students_mathematical_learning",
      "processed_at": "2026-01-08T13:51:20.436497",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, with some comparing ITS to human tutoring or homework. Overall, ITS showed no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effectiveness was greater for interventions lasting less than one school year and for general student populations compared to low achievers, raising concerns about whether computerized learning might contribute to achievement gaps.",
        "measure": "Standardized test scores, modified standardized tests, course grades, course passing rates, and specifically designed tests",
        "study_size": 14321,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (grades K-12)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 234,
      "paper_id": "paper_57004",
      "finding_id": "finding_55837",
      "title": "A Meta-Analysis of the Effectiveness of Intelligent Tutoring Systems on K\u201312 Students' Mathematical Learning",
      "url": "https://www.academia.edu/72221760/A_meta_analysis_of_the_effectiveness_of_intelligent_tutoring_systems_on_K_12_students_mathematical_learning",
      "processed_at": "2026-01-08T13:51:36.383636",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This meta-analysis examined 26 reports containing 34 independent samples published between 1997 and 2010 to evaluate the effectiveness of intelligent tutoring systems (ITS) on K-12 students' mathematical learning. The majority of studies compared ITS with regular classroom instruction, with a few comparing ITS to human tutoring or homework. Overall, ITS showed no negative and perhaps a small positive effect on mathematical learning, with average effect sizes ranging from g = 0.01 to g = 0.09. Moderator analyses revealed that ITS effectiveness was greater for interventions lasting less than one school year and for general student populations compared to low achievers, raising concerns about whether computerized learning might contribute to achievement gaps.",
        "measure": "Standardized test scores, modified standardized tests, course grades, course passing rates, and specifically designed tests",
        "study_size": 14321,
        "effect_size": 0.09,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students (grades K-12)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 235,
      "paper_id": "paper_68870",
      "finding_id": "finding_68870",
      "title": "A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education",
      "url": "https://www.nature.com/articles/s41539-025-00320-7",
      "processed_at": "2026-01-08T13:51:52.762867",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic review analyzed 28 studies involving 4,597 K-12 students to evaluate the effects of AI-driven intelligent tutoring systems (ITS) on learning and performance. The review found that when comparing ITS to traditional teacher-led instruction, seven of eight studies reported positive effects with medium to large effect sizes. However, when comparing ITS to non-intelligent tutoring systems, results were more contradictory with only one of four studies showing an advantage for ITS. Studies primarily used quasi-experimental designs with varying intervention durations, many lasting less than a week. The overall findings suggest that ITS effects on learning are generally positive but are mitigated when compared to non-intelligent tutoring systems, with personalization and adaptivity identified as core components influencing effectiveness.",
        "measure": "Pre-test and post-test learning gains, standardized test scores, locally developed assessments",
        "study_size": 4597,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "K-12 students, predominantly middle school (6th-8th) and high school (9th-12th)",
        "school_type": "K-12",
        "public_private_status": "mixed",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "no",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 236,
      "paper_id": "paper_86359",
      "finding_id": "finding_86359",
      "title": "A Comparative Study of Contextual and Traditional Teaching on General Mathematics Performance among Grade 11 EIM Students at Angelo L. Loyola Senior High School",
      "url": "https://www.allmultidisciplinaryjournal.com/uploads/archives/20250516115302_MGE-2025-3-121.1.pdf",
      "processed_at": "2026-01-08T13:52:09.111804",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study compared contextual teaching methods to traditional teaching methods for General Mathematics among 34 Grade 11 Electrical Installation and Maintenance (EIM) students at a senior high school in the Philippines. Using a non-equivalent control group pre-test and post-test design, the experimental group received contextual instruction connecting mathematical concepts to real-life applications while the control group received traditional lecture-based instruction. The contextual teaching group showed significant improvement from pre-test (mean 6.35) to post-test (mean 8.53) with a mean difference of 2.18 (p = 0.000), while the traditional group showed non-significant improvement (mean difference 0.47, p = 0.191). Statistical analysis using Two-Sample Independent T-Test confirmed that contextual teaching was significantly more effective (t = 2.365, p = 0.024) in enhancing student mathematics performance.",
        "measure": "Pre-test and post-test scores on General Mathematics assessment covering Algebra, Geometry, and Trigonometry",
        "study_size": 34,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Grade 11 students",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Southeast Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 237,
      "paper_id": "paper_62846",
      "finding_id": "finding_62846",
      "title": "Differentiated instruction: A systematic literature review on implementation guidelines in mathematics education",
      "url": "https://www.science-gate.com/IJAAS/Articles/2025/2025-12-03/1021833ijaas202503011.pdf",
      "processed_at": "2026-01-08T13:52:25.478552",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic literature review examined 13 empirical studies on differentiated instruction (DI) in mathematics education from 2014 to 2024, following the PRISMA protocol. The review synthesized findings across multiple countries, with the majority of studies from Australia and the Netherlands. Key implementation methods identified include collaborative learning, technology integration, and student-centered approaches such as problem-based learning and inquiry-based activities. The findings indicate that DI positively influences mathematics achievement, student motivation, and interest, with seven studies specifically demonstrating positive effects on mathematics achievement. The Tomlinson model emerged as the primary framework guiding DI implementation across eight of the reviewed studies.",
        "measure": "Mathematics achievement, motivation, interest, engagement",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 238,
      "paper_id": "paper_97221",
      "finding_id": "finding_97221",
      "title": "A Meta-Analysis of the Experimental Evidence Linking Mathematics and Science Professional Development Interventions to Teacher Knowledge, Classroom Instruction, and Student Achievement",
      "url": "https://edworkingpapers.com/sites/default/files/ai24-1023_v2.pdf",
      "processed_at": "2026-01-08T13:52:40.572798",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis synthesized 46 randomized controlled trials of PK-12 mathematics and science professional development interventions to examine impacts on teacher knowledge, classroom instruction, and student achievement. The study population included in-service teachers across elementary, middle, and high school grades, with most studies conducted in the United States. Using a correlated and hierarchical effects model with robust variance estimation, the authors found that treatment group teachers demonstrated significantly stronger performance on teacher-level outcomes compared to controls, with a pooled average impact of +0.52 SD. Programs with larger impacts on teacher-level outcomes also showed significantly larger mean impacts on student achievement, with a 1 SD improvement in classroom instruction associated with a 0.24 SD increase in student achievement. The findings support the logic model that professional development can improve teacher knowledge and instruction, which in turn relates to improved student learning outcomes.",
        "measure": "Teacher knowledge assessments, classroom observation indicators, self-report measures of instructional practice, and student achievement tests",
        "study_size": 46,
        "effect_size": 0.52,
        "student_racial_makeup": "60% students of color on average among studies reporting this information",
        "student_socioeconomic_makeup": "62% low income or free/reduced-price lunch eligible on average; 73% of studies conducted in majority low-income settings",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Preschool through high school (PK-12)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "low",
        "ses_numeric": "62% FRPL eligible on average",
        "special_education_services": "not_reported",
        "urban_type": "mixed",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 239,
      "paper_id": "paper_85204",
      "finding_id": "finding_85204",
      "title": "Implementation Factors and Their Influence on Student Mathematics Outcomes",
      "url": "https://files.eric.ed.gov/fulltext/ED627347.pdf",
      "processed_at": "2026-01-08T13:52:59.520298",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study examined the ROOTS kindergarten mathematics intervention delivered to students at risk for mathematics difficulties in a Tier 2 setting. Using a randomized control trial design with 880 kindergarten students across 23 Title I schools, the researchers investigated how treatment adherence and implementation quality related to student mathematics outcomes. Results showed that both implementation measures were significantly related to the proximal curricular-aligned measure (RAENS) but not to the distal general outcome measure (TEMA). Treatment adherence and implementation quality were highly correlated with each other (R\u00b2 = .60), with higher implementation scores corresponding to higher student outcomes on the proximal measure.",
        "measure": "Test of Early Mathematics Achievement (TEMA) and ROOTS Assessment of Early Numeracy Skills (RAENS)",
        "study_size": 880,
        "effect_size": 0.03,
        "student_racial_makeup": "64% White, 24% Hispanic, remaining 12% other races",
        "student_socioeconomic_makeup": "All 23 schools were Title I eligible",
        "student_gender_makeup": "51% female, 49% male",
        "student_age_distribution": "Kindergarten students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "title_i",
        "ses_indicator": "low",
        "ses_numeric": "100% Title I eligible schools",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "district",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 1,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 240,
      "paper_id": "paper_9518",
      "finding_id": "finding_9518",
      "title": "Factors Influencing Students' Performance in Mathematics for Better Teaching-Aids Design",
      "url": "https://www.academia.edu/90770977/Factors_Influencing_Students_Performance_in_Mathematics_for_Better_Teaching_Aids_Design",
      "processed_at": "2026-01-08T13:53:14.868421",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This study investigated factors affecting mathematics performance among 160 undergraduate students from five public universities in North Central Nigeria using a survey questionnaire. The study employed a descriptive survey design to examine demographic, teaching, and individual factors. Results revealed that gender was not a significant factor affecting mathematics performance, while parents' education level (27.5% rated effective) and socio-economic status (34.4% rated effective) were influential demographic factors. Teaching factors including teaching strategies/methods (40.6% very effective), teacher competency in mathematics education (43.7% very effective), and school context/facilities (37.5% very effective) were all found to positively influence performance. Individual factors such as motivation (50% very effective), arithmetic ability (46.8% very effective), and self-directed learning (41.8% very effective) were also identified as important contributors to mathematics achievement.",
        "measure": "Student perceptions of factor effectiveness using Likert-scale questionnaire responses (frequency counts and percentages)",
        "study_size": 160,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "males and females",
        "student_age_distribution": "undergraduate students",
        "school_type": "postsecondary",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 3,
        "evaluation_burden_cost": 1
      },
      "error": null
    },
    {
      "index": 241,
      "paper_id": "paper_42037",
      "finding_id": "finding_42037",
      "title": "Altering students' attitude towards learning mathematics through project-based learning: A mathematics project",
      "url": "https://files.eric.ed.gov/fulltext/EJ1465374.pdf",
      "processed_at": "2026-01-08T13:53:30.474085",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study examined the impact of project-based learning (PBL) on fifth-grade students' attitudes toward mathematics and academic achievement in a Pakistani public school. The experimental group (n=35) received PBL-based instruction while the control group (n=35) received traditional instruction over 6 weeks. Results showed a statistically significant improvement in the experimental group's attitudes toward mathematics (z = -4.570, p < .001) with a large effect size (r = -0.77). Achievement test scores also significantly improved in the experimental group (M = 25.54) compared to the control group (M = 16.94, p < .001), with 80% of experimental group students becoming high achievers versus 22.8% in the control group.",
        "measure": "Mathematics Attitude Scale and Mathematics Achievement Test",
        "study_size": 70,
        "effect_size": 0.77,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "100% female",
        "student_age_distribution": "5th grade (approximately 10-11 years old)",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "South Asia",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 242,
      "paper_id": "paper_77986",
      "finding_id": "finding_77986",
      "title": "The Relationship Between Engagement and Mathematics Achievement of Nontraditional Students: A Meta-Analysis",
      "url": "https://pubs.sciepub.com/jitl/5/1/4/index.html",
      "processed_at": "2026-01-08T13:53:44.952940",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the relationship between student engagement (behavioral, cognitive, and emotional dimensions) and mathematics or academic achievement among nontraditional students, defined as older learners balancing academic demands with work and family responsibilities. Using a random-effects model with Fisher r-to-z transformed correlation coefficients across four studies, the analysis found a statistically significant moderate positive association (r = 0.42, p = .007). The study population consisted primarily of community college and postsecondary nontraditional students. Substantial heterogeneity was detected (I\u00b2 = 92.86%), indicating meaningful variation across study contexts, engagement measures, and sample characteristics, though no publication bias or influential outliers were identified.",
        "measure": "Correlation coefficient (Pearson's r) between engagement and mathematics/academic achievement (GPA, math grades)",
        "study_size": "not_reported",
        "effect_size": 0.42,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "older than 24 years (nontraditional students)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "community_college",
        "region": "not_reported",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 243,
      "paper_id": "paper_19052",
      "finding_id": "finding_19052",
      "title": "Student engagement, conceptual-understanding, and problem-solving ability in learning plane geometry through an integrated instructional approach",
      "url": "https://www.ejmste.com/download/student-engagement-conceptual-understanding-and-problem-solving-ability-in-learning-plane-geometry-16391.pdf",
      "processed_at": "2026-01-08T13:53:59.102094",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study investigated the impact of the Van Hiele Group Guided Discovery Instructional Approach (VHGGDIA) on tenth-grade students' engagement, conceptual understanding, and problem-solving ability in plane geometry across three purposefully selected secondary schools in Ethiopia. The study involved 166 students divided into two experimental groups and one control group, with the intervention lasting six weeks. Results showed significant pre-post-test mean differences in experimental groups but not in the control group, with Experimental Group I (VHGGDIA) demonstrating superior improvement compared to Experimental Group II (GGDIA) and the control group. After controlling for pre-test scores, the integrated approach contributed 13.1%, 14.8%, and 28.24% of the variability in concept understanding, problem-solving ability, and engagement respectively, with effect sizes indicating larger than typical effects for VHGGDIA compared to traditional teaching methods.",
        "measure": "Pre-post tests for conceptual understanding (two-tier multiple choice) and problem-solving ability (open-ended questions), engagement Likert scale questionnaire",
        "study_size": 166,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "44.64% male, 55.36% female",
        "student_age_distribution": "10th grade students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 244,
      "paper_id": "paper_19052",
      "finding_id": "finding_99301",
      "title": "Student engagement, conceptual-understanding, and problem-solving ability in learning plane geometry through an integrated instructional approach",
      "url": "https://www.ejmste.com/download/student-engagement-conceptual-understanding-and-problem-solving-ability-in-learning-plane-geometry-16391.pdf",
      "processed_at": "2026-01-08T13:54:16.742712",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This quasi-experimental study investigated the impact of the Van Hiele Group Guided Discovery Instructional Approach (VHGGDIA) on tenth-grade students' engagement, conceptual understanding, and problem-solving ability in plane geometry across three purposefully selected secondary schools in Ethiopia. The study involved 166 students divided into two experimental groups and one control group, with the intervention lasting six weeks. Results showed significant pre-post-test mean differences in experimental groups but not in the control group, with Experimental Group I (VHGGDIA) demonstrating superior improvement compared to Experimental Group II (GGDIA) and the control group. After controlling for pre-test scores, the integrated approach contributed 13.1%, 14.8%, and 28.24% of the variability in concept understanding, problem-solving ability, and engagement respectively, with effect sizes indicating larger than typical effects for VHGGDIA compared to traditional teaching methods.",
        "measure": "Pre-post tests for conceptual understanding (two-tier multiple choice) and problem-solving ability (open-ended questions), engagement Likert scale questionnaire",
        "study_size": 166,
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "44.64% male, 55.36% female",
        "student_age_distribution": "10th grade students",
        "school_type": "K-12",
        "public_private_status": "public",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "urban",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Sub-Saharan Africa",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 245,
      "paper_id": "paper_0",
      "finding_id": "finding_0",
      "title": "",
      "url": "https://www.ida.org/-/media/feature/publications/w/we/welch-award-2017---effectiveness-of-intelligent-tutoring-systems-a-meta-analytic-review/1-effectivenessits.ashx",
      "processed_at": "2026-01-08T13:54:34.882889",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 246,
      "paper_id": "paper_81135",
      "finding_id": "finding_81135",
      "title": "A Systematic Literature Review Of Online Learning And Mathematics Achievement Among Students With Disabilities, English Language Learners, And Impoverished Students",
      "url": "https://scholarsarchive.library.albany.edu/cgi/viewcontent.cgi?article=4627&context=legacy-etd",
      "processed_at": "2026-01-08T13:54:39.611838",
      "status": "failed",
      "extracted_fields": {},
      "error": "extraction failed"
    },
    {
      "index": 247,
      "paper_id": "paper_82813",
      "finding_id": "finding_82813",
      "title": "Dosage Response in Intensive Mathematics Interventions for Early Elementary Students With or At-Risk for Mathematics Learning Disability",
      "url": "https://link.springer.com/article/10.1007/s10648-025-10070-y",
      "processed_at": "2026-01-08T13:54:45.244469",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This meta-analysis examined the effect of intervention dosage on mathematics outcomes for K-3 students with or at risk for mathematics learning disability, analyzing 164 effect sizes from 24 experimental and quasi-experimental studies. The study found a linear dose-response relationship with an overall pooled mean effect size of 0.61, indicating that intensive mathematics interventions have educationally meaningful effects. For every 1-hour increase in intervention dosage, effect sizes increased by 0.03 units, though this main effect was no longer significant after controlling for moderators. Group size significantly moderated effects, with 1:1 interventions showing higher effect sizes than small-group interventions, and outcome proximity interacted with dosage such that proximal outcomes showed greater gains at higher dosages.",
        "measure": "Mathematics achievement outcomes including proximal measures (skills directly taught) and distal measures (standardized tests like TEMA-3)",
        "study_size": 164,
        "effect_size": 0.61,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Kindergarten through third grade (ages approximately 5-9)",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "United States",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 248,
      "paper_id": "paper_28847",
      "finding_id": "finding_28847",
      "title": "Emotions in mathematics learning: a systematic review and meta-analysis",
      "url": "https://link.springer.com/article/10.1007/s11858-025-01651-w",
      "processed_at": "2026-01-08T13:55:01.987129",
      "status": "success",
      "extracted_fields": {
        "direction": "Mixed",
        "results_summary": "This systematic review and meta-analysis examined 112 studies on emotions in mathematics learning, identifying over 100 distinct emotions and synthesizing evidence on relationships between emotions, control-value antecedents, and mathematics achievement. The study population included students across all educational levels from primary through tertiary education. Using Pekrun's control-value theory framework, the meta-analysis of 57 independent studies found that positive activating emotions (enjoyment, hope, pride) were positively correlated with mathematics achievement (r = .247, .224, .344 respectively), while negative emotions (anger, boredom, frustration, hopelessness, shame) were negatively correlated with achievement (r = -.322, -.187, -.207, -.378, -.291 respectively). The findings support control-value theory predictions that perceived control and perceived positive value are significantly related to academic emotions in mathematics contexts.",
        "measure": "Mathematics achievement (test scores, grades, standardized tests), perceived control, perceived value, correlation coefficients",
        "study_size": "not_reported",
        "effect_size": 0.25,
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "secondary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 249,
      "paper_id": "paper_88277",
      "finding_id": "finding_88277",
      "title": "A systematic literature review of math interventions across educational settings from early childhood education to high school",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2023.1229849/full",
      "processed_at": "2026-01-08T13:55:17.844682",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined 75 randomized controlled math interventions conducted between 2001-2021 across educational settings from early childhood education to high school. The review found that 91% of interventions (68 of 75) showed positive main effects on at least one math-related outcome. The majority of interventions were conducted in elementary school settings (46%) and primarily targeted at-risk children (57%). The review identified significant knowledge gaps in early childhood education settings, particularly infant-toddler programs, and noted that most existing interventions focus on at-risk populations rather than universal approaches that could benefit all children.",
        "measure": "Math achievement/skills composite scores, number sense/numeracy and arithmetic measures",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "57% of interventions targeted at-risk children including those from low SES backgrounds",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "0-16 years old across daycare, preschool, kindergarten, elementary, middle, and high school",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 250,
      "paper_id": "paper_88277",
      "finding_id": "finding_52241",
      "title": "A systematic literature review of math interventions across educational settings from early childhood education to high school",
      "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2023.1229849/full",
      "processed_at": "2026-01-08T13:55:33.081300",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review examined 75 randomized controlled math interventions conducted between 2001-2021 across educational settings from early childhood education to high school. The review found that 91% of interventions (68 of 75) showed positive main effects on at least one math-related outcome. The majority of interventions were conducted in elementary school settings (46%) and primarily targeted at-risk children (57%). The review identified significant knowledge gaps in early childhood education settings, particularly infant-toddler programs, and noted that most existing interventions focus on at-risk populations rather than universal approaches that could benefit all children.",
        "measure": "Math achievement/skills composite scores, number sense/numeracy and arithmetic measures",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "57% of interventions targeted at-risk children including those from low SES backgrounds",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "0-16 years old across daycare, preschool, kindergarten, elementary, middle, and high school",
        "school_type": "K-12",
        "public_private_status": "not_reported",
        "title_i_status": "not_reported",
        "ses_indicator": "mixed",
        "ses_numeric": "not_reported",
        "special_education_services": "yes",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "elementary",
        "postsecondary_type": "not_applicable",
        "region": "Global",
        "system_impact_levels": 1,
        "decision_making_complexity": 2,
        "evidence_type_strength": 0,
        "evaluation_burden_cost": 3
      },
      "error": null
    },
    {
      "index": 251,
      "paper_id": "paper_52337",
      "finding_id": "finding_52337",
      "title": "Systematic Review: Trends in Intelligent Tutoring Systems in Mathematics Teaching and Learning",
      "url": "https://files.eric.ed.gov/fulltext/EJ1408642.pdf",
      "processed_at": "2026-01-08T13:55:47.800896",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review analyzed 43 documents from 2012-2022 examining intelligent tutoring systems (ITS) in mathematics education at secondary and higher education levels. The review found that ITS implementations primarily focused on personalization and adaptation of learning (41.86%), with key advantages including personalized learning (27.9%) and immediate feedback (23.25%). Studies reported improvements in academic performance (37.2%) and student learning (18.6%) as primary effectiveness indicators. The review identified expert systems as the most commonly used AI technique (32%) for adaptation processes, with ALEKS being the most frequently implemented ITS platform (18.6%).",
        "measure": "Academic performance, learning outcomes, student engagement, and system effectiveness metrics across multiple studies",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 252,
      "paper_id": "paper_52337",
      "finding_id": "finding_70770",
      "title": "Systematic Review: Trends in Intelligent Tutoring Systems in Mathematics Teaching and Learning",
      "url": "https://files.eric.ed.gov/fulltext/EJ1408642.pdf",
      "processed_at": "2026-01-08T13:56:03.899801",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review analyzed 43 documents from 2012-2022 examining intelligent tutoring systems (ITS) in mathematics education at secondary and higher education levels. The review found that ITS implementations primarily focused on personalization and adaptation of learning (41.86%), with key advantages including personalized learning (27.9%) and immediate feedback (23.25%). Studies reported improvements in academic performance (37.2%) and student learning (18.6%) as primary effectiveness indicators. The review identified expert systems as the most commonly used AI technique (32%) for adaptation processes, with ALEKS being the most frequently implemented ITS platform (18.6%).",
        "measure": "Academic performance, learning outcomes, student engagement, and system effectiveness metrics across multiple studies",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 253,
      "paper_id": "paper_52337",
      "finding_id": "finding_71984",
      "title": "Systematic Review: Trends in Intelligent Tutoring Systems in Mathematics Teaching and Learning",
      "url": "https://files.eric.ed.gov/fulltext/EJ1408642.pdf",
      "processed_at": "2026-01-08T13:56:18.769316",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review analyzed 43 documents from 2012-2022 examining intelligent tutoring systems (ITS) in mathematics education at secondary and higher education levels. The review found that ITS implementations primarily focused on personalization and adaptation of learning (41.86%), with key advantages including personalized learning (27.9%) and immediate feedback (23.25%). Studies reported improvements in academic performance (37.2%) and student learning (18.6%) as primary effectiveness indicators. The review identified expert systems as the most commonly used AI technique (32%) for adaptation processes, with ALEKS being the most frequently implemented ITS platform (18.6%).",
        "measure": "Academic performance, learning outcomes, student engagement, and system effectiveness metrics across multiple studies",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "Secondary and higher education students (first semesters of university)",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 2,
        "evaluation_burden_cost": 2
      },
      "error": null
    },
    {
      "index": 254,
      "paper_id": "paper_52337",
      "finding_id": "finding_81340",
      "title": "Systematic Review: Trends in Intelligent Tutoring Systems in Mathematics Teaching and Learning",
      "url": "https://files.eric.ed.gov/fulltext/EJ1408642.pdf",
      "processed_at": "2026-01-08T13:56:33.982955",
      "status": "success",
      "extracted_fields": {
        "direction": "Positive",
        "results_summary": "This systematic review analyzed 43 documents from 2012-2022 examining intelligent tutoring systems (ITS) in mathematics education at secondary and higher education levels. The review found that ITS implementations primarily focused on personalization and adaptation of learning (41.86%), with key advantages including personalized learning (27.9%) and immediate feedback (23.25%). Studies reported improvements in academic performance (37.2%) and student learning (18.6%) as primary effectiveness indicators. The review identified expert systems as the most commonly used AI technique (32%) for adaptation processes, with ALEKS being the most frequently implemented ITS platform (18.6%).",
        "measure": "Academic performance, learning outcomes, student engagement, and system effectiveness metrics across reviewed studies",
        "study_size": "not_reported",
        "effect_size": "not_reported",
        "student_racial_makeup": "not_reported",
        "student_socioeconomic_makeup": "not_reported",
        "student_gender_makeup": "not_reported",
        "student_age_distribution": "not_reported",
        "school_type": "postsecondary",
        "public_private_status": "not_reported",
        "title_i_status": "not_applicable",
        "ses_indicator": "not_reported",
        "ses_numeric": "not_reported",
        "special_education_services": "not_reported",
        "urban_type": "not_reported",
        "governance_type": "not_reported",
        "institutional_level": "postsecondary",
        "postsecondary_type": "four_year",
        "region": "Global",
        "system_impact_levels": 0,
        "decision_making_complexity": 1,
        "evidence_type_strength": 4,
        "evaluation_burden_cost": 2
      },
      "error": null
    }
  ],
  "completed_at": "2026-01-08T13:56:49.429905",
  "summary": {
    "success": 232,
    "skipped": 6,
    "failed": 16,
    "total": 254
  }
}